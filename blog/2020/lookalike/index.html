<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Celebrity Lookalike Project Writeup | Joe Dinius, Ph.D.</title> <meta name="author" content="Joe Dinius, Ph.D."> <meta name="description" content="OpenCV Computer Vision II Applications Project"> <meta name="keywords" content="robotics, autonomy, math, optimization, controltheory, planning, computervision"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?df44dccb15554b4d2d173cb203488555"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?53ca2be8c4ec0d533ef79017d1a2d734"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jwdinius.github.io/blog/2020/lookalike/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Joe </span>Dinius, Ph.D.</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">git</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resumeDiniusTargeted.pdf">resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Celebrity Lookalike Project Writeup</h1> <p class="post-meta">November 8, 2020</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>I am currently enrolled in the OpenCV course “Computer Vision II: Applications (C++)”. For the second project, I had to create an application that would detect faces in a test image and then find the celebrities (from a provided dataset) whose faces <em>most closely</em> resemble those found in the test image. I put the phrase “most closely” in italics because I will discuss a few different approaches to finding the best match. To give a pictorial expression of the project’s objective, the course moderators provided the following expected output for two provided test images:</p> <p><img src="/assets/img/lookalike/Kazam_screenshot_00000.png" alt="expected-output"></p> <p><em>Note: the celebrity lookalike found for the top test image is displayed as Selena, however the lookalike image actually displayed is Selena Gomez. In the provided dataset, there are folders for both Selena and Selena Gomez, who are in fact two different people, but all images in both folders are for Selena Gomez.</em></p> <p>In this blog post, I present a formal writeup of my solution addressing requirements of the project. Where appropriate, I will provide source code snippets highlighting important aspects of my approach.</p> <h1 id="writeup">Writeup</h1> <h2 id="objective">Objective</h2> <p>I will formally state the objective for the project here:</p> <blockquote> <p>Given a dataset of celebrity images, labeled by name, create a low-dimensional <a href="https://www.quora.com/What-is-descriptor-in-computer-vision#:~:text=In%20computer%20vision%2C%20visual%20descriptors,or%20the%20motion%2C%20among%20others." rel="external nofollow noopener" target="_blank">descriptor</a> representing the likeness of the face detected in each image. Using this low-dimensional descriptor, compute a similarity score between faces detected in test images and the celebrities in the dataset. The celebrity with the highest similarity score is declared the “lookalike” or “doppelganger” to an individual detected in a test image.</p> </blockquote> <h2 id="dataset">Dataset</h2> <p>The course moderators provided a dataset, dubbed “celeb_mini”, that contains ~5 images per celebrity for 1000+ celebrities. There is significant variation in the dataset across the following factors:</p> <ul> <li>Illumination</li> <li>Face pose</li> <li>Foreground clutter - <em>some images have copyright data overlaid</em> </li> <li>Sharpness/clarity of the image - <em>some images are quite blurry</em> </li> </ul> <h2 id="solution">Solution</h2> <p>Because I am provided with a dataset for this activity, my solution has two phases: <em>training</em> and <em>testing</em>. During the training phase, I will find representative and informative descriptors for each image in the training set (i.e. the celeb_mini dataset). During the testing phase, I will apply the learned descriptor model (a function of the input image) to a test image and then find the most similar images in the training set with respect to the learned descriptor.</p> <p>The solution is constructed in C++, and the primary APIs used in my solution are:</p> <ul> <li> <a href="https://opencv.org/opencv-4-1/" rel="external nofollow noopener" target="_blank">OpenCV</a> - used for basic image loading/saving and image processing</li> <li> <a href="http://dlib.net" rel="external nofollow noopener" target="_blank">dlib</a> - used for linear algebra operations (length, linear systems solvers, and matrix processing), face detection, and for deep neural network inference</li> <li> <a href="https://matplotlib-cpp.readthedocs.io/en/latest/index.html" rel="external nofollow noopener" target="_blank">matplotlibcpp</a> - for plotting data</li> </ul> <p>Before discussing each phase in greater detail, I will present my chosen descriptor model and justification.</p> <h3 id="descriptor">Descriptor</h3> <p>Considering the givens and assumptions for this project, I’d like a descriptor with the following qualities:</p> <ul> <li>Low dimensionality (makes comparison simpler and reduces redundancy across dataset)</li> <li>Descriptors for images with the same label (i.e. represent the same celebrity) are highly similar (close in some metric sense)</li> <li>Descriptors for images with different labels are highly dissimilar (far apart in some metric sense)</li> </ul> <p>In the course materials, a solution based on this <a href="http://dlib.net/dnn_metric_learning_on_images_ex.cpp.html" rel="external nofollow noopener" target="_blank">representative example</a> is presented that addresses all three points above using a deep learning-based approach. The solution uses a backbone architecture based on a <a href="https://arxiv.org/pdf/1512.03385.pdf" rel="external nofollow noopener" target="_blank">ResNet</a> pre-trained using <a href="https://towardsdatascience.com/metric-learning-loss-functions-5b67b3da99a5" rel="external nofollow noopener" target="_blank">metric loss</a> to create a 128-dimensional descriptor of each input image. To avoid unnecessary effort in retraining the backbone network, I first wanted to see the performance on the assigned task (i.e. finding the correct lookalike for each of the two test images discussed in the Introduction section of this page) using the pre-trained network.</p> <p>For the purpose of this project, this approach was found to be sufficient. In the Discussion section below, I will address deficiencies of using the pre-trained approach when considering use-cases outside of the defined boundaries for the project.</p> <h3 id="training">Training</h3> <p>This phase is not “training” in the typical sense, since a pre-trained network is used; rather it is more about generating descriptors for the images in the dataset using the pre-trained network. With this in mind, the training process is outlined as follows:</p> <ul> <li>Load training images</li> <li>Assign unique integral label to each subfolder in the dataset - <em>images in each subfolder represent the same celebrity</em> </li> <li>Map each folder to celebrity name - <em>this will be used to assign celebrity name at the end of the testing process</em> </li> <li>Load pre-trained model weights and biases for computing the descriptors</li> <li>for each image in the training image set <ul> <li>detect faces in image</li> <li>for each face in detected faces <ul> <li>detect facial landmarks</li> <li>use landmarks to crop facial region from image</li> <li>compute descriptor using cropped facial region</li> </ul> </li> </ul> </li> <li>write celebrity name-to-label map to csv file - <em>this will be used to match test image faces to celebrity likeness during the testing phase</em> </li> <li>write descriptors, along with labels, to csv file for use during testing phase</li> </ul> <p>The codebase for this step was built using materials provided by the course moderators, so I am not willing to share it here.</p> <h3 id="testing">Testing</h3> <p>This phase’s primary concern is finding the celebrity that most closely resembles individuals detected in a test image. The process is outlined as follows:</p> <ul> <li>Load pre-trained model weights and biases (the same as in Training phase)</li> <li>Load csv file with celebrity name-to-label mapping</li> <li>Load csv file with descriptors and associated labels</li> <li>Load test image</li> <li>Detect faces in test image</li> <li>for each face in detected faces <ul> <li>detect facial landmarks</li> <li>use landmarks to crop facial region from image</li> <li>compute descriptor using cropped facial region</li> <li><em>find most similar celebrity using loaded descriptors</em></li> </ul> </li> </ul> <p>The steps in the loop defined above should look familiar: <em>they are the same as those used in the Training phase, with the addition of the matching step.</em> The majority of original work that I did for this project was concerned with the calculation of a similarity metric, so I will focus the discussion around these points.</p> <p>There are two metrics I used for computing similarity. The first is a simple, nearest-neighbor approach based on the <a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,occasionally%20called%20the%20Pythagorean%20distance." rel="external nofollow noopener" target="_blank">Euclidean distance</a> between descriptor vectors. The second uses <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance" rel="external nofollow noopener" target="_blank">Mahalanobis distance</a>, which is a distance measure that is normalized by the covariance over samples from the training set with common label. I will now discuss these two approaches separately.</p> <h4 id="euclidean-distance">Euclidean distance</h4> <p>Euclidean distance is really easy to interpret: <em>if I look at the descriptor vectors as embeddings in a 128D vector space, then similar vectors are ones whose tails are close to one another in the normal linear sense</em>. In the context of the problem at-hand, the most similar celebrity to a person detected in a test image will have descriptor with shortest length to the descriptor representing the person detected in the test image.</p> <p>The code to identify the top matches using a Euclidean distance metric is:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * findKNearestNeighbors
 *
 * given an input descriptor and database of labeled descriptors, find the
 * top K best matches based using a Euclidean distance metric
 *
 */</span>
<span class="kt">bool</span> <span class="nf">findKNearestNeighbors</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptorQuery</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceLabels</span><span class="p">,</span> <span class="kt">int</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">k</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;&amp;</span> <span class="n">matches</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// loop over all descriptors and compute Euclidean distance with query descriptor</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">neighbors</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// compute distance between descriptors v1 and v2:</span>
    <span class="c1">// d(v1, v2) = std::sqrt((v1-v2)^T * (v1-v2));</span>
    <span class="c1">// - this is implemented in dlib with the `length` function</span>
    <span class="kt">double</span> <span class="n">distance</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">::</span><span class="n">length</span><span class="p">(</span><span class="n">faceDescriptorQuery</span> <span class="o">-</span> <span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="c1">// check if a distance for this label has already been determined</span>
    <span class="k">auto</span> <span class="n">it</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">find_if</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
          <span class="p">[</span><span class="o">&amp;</span><span class="p">](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">p</span><span class="p">.</span><span class="n">first</span> <span class="o">==</span> <span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="p">});</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">!=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
      <span class="c1">// if there has already been a distance found for this label, check if the current distance is less</span>
      <span class="c1">// than the one previously computed</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">distance</span> <span class="o">&lt;</span> <span class="n">it</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// if the current distance is less than the one previously recorded for the label, update it</span>
        <span class="n">it</span><span class="o">-&gt;</span><span class="n">second</span> <span class="o">=</span> <span class="n">distance</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// this is the first time encountering this label, so add the (label, distance) pair to neighbors</span>
      <span class="n">neighbors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">distance</span><span class="p">));</span>
    <span class="p">}</span>
  <span class="p">}</span>
  
  <span class="c1">// do the sort (closest to -&gt; furthest away)</span>
  <span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
      <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p1</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p2</span><span class="p">){</span> <span class="k">return</span> <span class="n">p1</span><span class="p">.</span><span class="n">second</span> <span class="o">&lt;</span> <span class="n">p2</span><span class="p">.</span><span class="n">second</span><span class="p">;</span> <span class="p">});</span>
    
  <span class="c1">// get k closest</span>
  <span class="n">matches</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">std</span><span class="o">::</span><span class="n">copy_n</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">back_inserter</span><span class="p">(</span><span class="n">matches</span><span class="p">));</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>This code is quite simple. I loop over all of the descriptors in the database and evaluate the closest distance per-label for all descriptors. I then sort the output from this stage, with the closest matches first, and return a user-specified number of the best matches (see <code class="language-plaintext highlighter-rouge">k</code> in the function signature for <code class="language-plaintext highlighter-rouge">findKNearestNeighbors</code> above).</p> <h4 id="mahalanobis-distance">Mahalanobis distance</h4> <p>Because we have a few representative samples for each label, the Mahalanobis distance metric provides a way evaluating a statistically-relevant measure of closeness conditioned on the available data. The process for computing the Mahalanobis distance for a test image is as follows:</p> <ul> <li>Compute mean and variance of descriptor vectors over each label - <em>one time, during initialization</em> </li> <li>Use mean and variance over label descriptor vectors to find the label with smallest Mahalanobis distance to the test image descriptor</li> </ul> <p><em>Note: the fundamental assumption of this approach is that the training images for each celebrity are sampled from a normal distribution. Whether or not this is a valid assumption across the entirety of the dataset was not evaluated as part of this project. I just wanted to try out this approach and see how it compares to the Euclidean distance approach.</em></p> <p>During initialization, the mean and variance of the set of descriptors for each label is computed using the code snippet below:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * computeStatsPerLabel
 *
 * given a set of labels and associated descriptors, FOR EACH LABEL i: compute the mean and covariance of descriptor vectors that have
 * label i
 */</span>
<span class="kt">bool</span> <span class="nf">computeStatsPerLabel</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceLabels</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;&amp;</span> <span class="n">meanLabeledDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;&amp;</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// empty containers</span>
  <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>

  <span class="c1">// setup associative container for labeled descriptors and populate it</span>
  <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;&gt;</span> <span class="n">labeledDescriptors</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// if we haven't seen any descriptors for the present label, initialize</span>
    <span class="c1">// the vector for this label</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">labeledDescriptors</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="n">labeledDescriptors</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">labeledDescriptors</span><span class="p">[</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span> <span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">};</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// if we have already have descriptors for this label, append the current descriptor</span>
      <span class="n">labeledDescriptors</span><span class="p">[</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]].</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// for each key-value pair in the labeledDescriptors container</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">pr</span> <span class="o">:</span> <span class="n">labeledDescriptors</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// compute mean and covariance</span>
    <span class="k">auto</span> <span class="o">&amp;</span><span class="n">descriptors</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">second</span><span class="p">;</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="n">mean</span><span class="p">;</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">covariance</span><span class="p">;</span>
    <span class="n">computeNormalParameters</span><span class="p">(</span><span class="n">descriptors</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">label</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">first</span><span class="p">;</span>
    <span class="c1">// add to output data containers</span>
    <span class="n">meanLabeledDescriptors</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">;</span>
    <span class="n">covarianceLabeledDescriptors</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">covariance</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// mark successful execution</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>with the relevant mean and variance computations being done by the <code class="language-plaintext highlighter-rouge">computeNormalParameters</code> function:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * computeNormalParameters
 *
 * given a set of input descriptor vectors, compute the mean and covariance of that set
 *
 */</span>
<span class="kt">void</span> <span class="nf">computeNormalParameters</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">vecs</span><span class="p">,</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&amp;</span> <span class="n">covariance</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// if the input vector is empty, just exit</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">vecs</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Nothing to do"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// shorthand for vector size</span>
  <span class="k">auto</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">N</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>

  <span class="c1">// compute the mean = sum(v in vecs) / N</span>
  <span class="n">mean</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">nr</span><span class="p">());</span>
  <span class="n">dlib</span><span class="o">::</span><span class="n">set_all_elements</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">v</span> <span class="o">:</span> <span class="n">vecs</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">mean</span> <span class="o">+=</span> <span class="n">v</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">mean</span> <span class="o">/=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>

  <span class="c1">// compute the covariance = sum( (v-mean)*(v-mean)^T ) / N</span>
  <span class="n">covariance</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">nr</span><span class="p">(),</span> <span class="n">mean</span><span class="p">.</span><span class="n">nr</span><span class="p">());</span>
  <span class="n">dlib</span><span class="o">::</span><span class="n">set_all_elements</span><span class="p">(</span><span class="n">covariance</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">v</span> <span class="o">:</span> <span class="n">vecs</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">covariance</span> <span class="o">+=</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">dlib</span><span class="o">::</span><span class="n">trans</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">mean</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">covariance</span> <span class="o">/=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>With the mean and variance for each set of descriptors available, I can find the Mahalanobis distance between a test image’s descriptor and that set’s mean descriptor; see <code class="language-plaintext highlighter-rouge">findKMostLikely</code> below:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define REGULARIZATION 1e-8  // covariance += REGULARIZATION*Identity - this is necessary to stabilize the matrix decomposition used for the Mahalanobis distance calculation
</span><span class="cm">/**!
 * findKMostLikely
 *
 * given an input descriptor and mean and covariance for each label's descriptor vectors, find the
 * top K best matches based using a Mahalanobis distance metric
 *
 */</span>
<span class="kt">bool</span> <span class="nf">findKMostLikely</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptorQuery</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">meanLabeledDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">,</span>
    <span class="k">const</span> <span class="kt">size_t</span><span class="o">&amp;</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;&amp;</span> <span class="n">matches</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting."</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// loop over all sets of mean/covariance pairs</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">mahalanobisVec</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">auto</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>

    <span class="c1">// add some noise to the primary diagonal of the covariance matrix to regularize it</span>
    <span class="c1">// and improve the numerical stability of the subsequent solver</span>
    <span class="k">auto</span> <span class="n">transCov</span> <span class="o">=</span> <span class="n">covariance</span> <span class="o">+</span> <span class="n">REGULARIZATION</span> <span class="o">*</span> <span class="n">dlib</span><span class="o">::</span><span class="n">identity_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">covariance</span><span class="p">.</span><span class="n">nr</span><span class="p">());</span>
    <span class="k">auto</span> <span class="n">luDecomp</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">::</span><span class="n">lu_decomposition</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">transCov</span><span class="p">);</span>
    
    <span class="c1">// check if the object indicates a system that is not full-rank</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">luDecomp</span><span class="p">.</span><span class="n">is_singular</span><span class="p">())</span> <span class="p">{</span>
      <span class="c1">// there's nothing further to be done if the starting problem is singular, so go</span>
      <span class="c1">// to the next loop iteration</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Starting matrix is singular"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
      <span class="k">continue</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// compute residual of query descriptor with the current mean</span>
    <span class="k">auto</span> <span class="n">residual</span> <span class="o">=</span> <span class="n">faceDescriptorQuery</span> <span class="o">-</span> <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
    
    <span class="c1">// solve the linear system residual = S*y to get a more numerically-stable</span>
    <span class="c1">// representation of S^{-1}*residual in the Mahalanobis calculation </span>
    <span class="k">auto</span> <span class="n">y</span> <span class="o">=</span> <span class="n">luDecomp</span><span class="p">.</span><span class="n">solve</span><span class="p">(</span><span class="n">residual</span><span class="p">);</span>

    <span class="c1">// compute Mahalanobis distance given mean, m, and covariance, S:</span>
    <span class="c1">// d(v1, m, S) = std::sqrt((v1-m)^T * S^{-1} * (v1-m));</span>
    <span class="kt">double</span> <span class="n">mahalanobisDistance</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">trans</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span><span class="p">);</span>

    <span class="c1">// add result to full vector</span>
    <span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mahalanobisDistance</span><span class="p">));</span>
  <span class="p">}</span>
  
  <span class="c1">// do the sort (smallest mahalanobis distance -&gt; largest)</span>
  <span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
      <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p1</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p2</span><span class="p">){</span> <span class="k">return</span> <span class="n">p1</span><span class="p">.</span><span class="n">second</span> <span class="o">&lt;</span> <span class="n">p2</span><span class="p">.</span><span class="n">second</span><span class="p">;</span> <span class="p">});</span>
  
  <span class="c1">// get k matches that have smallest mahalanobis distance</span>
  <span class="n">matches</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">std</span><span class="o">::</span><span class="n">copy_n</span><span class="p">(</span><span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">back_inserter</span><span class="p">(</span><span class="n">matches</span><span class="p">));</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="results">Results</h2> <p>Because I was curious about not just the best identified match, I used my approach to find the best 5 matches for both of the two test images referenced in the Introduction section above. Without further ado, the results are presented below.</p> <h3 id="image-1">Image 1:</h3> <h4 id="euclidean-distance-1">Euclidean distance</h4> <p><img src="/assets/img/lookalike/sofia-solares_fid0_ed.jpg" alt="ed-sofia"></p> <h4 id="mahalanobis-distance-1">Mahalanobis distance</h4> <p><img src="/assets/img/lookalike/sofia-solares_fid0_md.jpg" alt="md-sofia"></p> <h3 id="image-2">Image 2:</h3> <h4 id="euclidean-distance-2">Euclidean distance</h4> <p><img src="/assets/img/lookalike/shashikant-pedwal_fid0_ed.jpg" alt="ed-shashikant"></p> <h4 id="mahalanobis-distance-2">Mahalanobis distance</h4> <p><img src="/assets/img/lookalike/shashikant-pedwal_fid0_md.jpg" alt="md-shashikant"></p> <h2 id="discussion">Discussion</h2> <h3 id="performance-on-test-images">Performance on test images</h3> <p>The discussion here will be brief, since the expected outcome of the project has been successfully demonstrated in the plots from the Results section above; <em>the best match identified for each test image provided matches expectation</em>. What I would like to highlight is the fact that the two approaches lead to similar results for the top, i.e. best, matches. In fact, based on similarity of results achieved for both methods, and the fact that the Euclidean distance approach was much easier to implement, I would focus further efforts with this particular method towards using the Euclidean distance for means of evaluating similarity.</p> <p>One thing of note is that Matches 1 and 2 for Image 1 claim to represent two different celebrities, Selena and Selena Gomez, however the images representing Selena are, in fact, pictures of Selena Gomez. Since I didn’t have to train the model, this inconsistency in labeling isn’t a big deal, but if I were to refine the model by retraining on the celeb_mini dataset provided, I would merge the two separate folders into one. Moreover, I’d do a deeper dive into the dataset itself to make sure there were no other inconsistencies present.</p> <h3 id="performance-on-other-images">Performance on other images</h3> <p>I was curious about what the approach would say about who the celebrity doppelgangers are for my wife and I and, as a follow-up, find out whether or not such predictions be common across different images (with different lighting, background, glasses/no-glasses, etc…). The results are shown below.</p> <h4 id="image-3-my-wife-and-i-at-a-restaurant">Image 3: My wife and I at a restaurant</h4> <p><img src="/assets/img/lookalike/IMG-0580_fid0_ed.jpg" alt="ed-joe-rest"></p> <p><img src="/assets/img/lookalike/IMG-0580_fid0_md.jpg" alt="md-joe-rest"></p> <p><img src="/assets/img/lookalike/IMG-0580_fid1_ed.jpg" alt="ed-jess-rest"></p> <p><img src="/assets/img/lookalike/IMG-0580_fid1_md.jpg" alt="md-jess-rest"></p> <p><em>Note: to poke at the issue of data labeling yet again: the image shown for Match 4 is, in fact, an image of Kathy Bates,</em> not <em>Mary Kay Place.</em></p> <h4 id="image-4-my-wife-and-i-near-a-lake-at-dusk">Image 4: My wife and I near a lake at dusk</h4> <p><img src="/assets/img/lookalike/20190615-190740_fid0_ed.jpg" alt="ed-joe-lake"></p> <p><img src="/assets/img/lookalike/20190615-190740_fid0_md.jpg" alt="md-joe-lake"></p> <p><img src="/assets/img/lookalike/20190615-190740_fid1_ed.jpg" alt="ed-jess-lake"></p> <p><img src="/assets/img/lookalike/20190615-190740_fid1_md.jpg" alt="md-jess-lake"></p> <h2 id="final-remarks">Final Remarks</h2> <p>Although there are some common matches between the two images for both my wife and myself, the top matches are different. Therefore it is expected that this approach would need considerable work to generalize to new images. To increase generalizability of the approach, I would try out the following approaches:</p> <ul> <li> <em>Gather additional data</em>. This is always the best approach if data is not difficult to gather (in this case, it wouldn’t be)</li> <li> <em>Scrub the data and clean labels</em>. In my limited investigations with the data, I found a few bogus examples (in terms of incorrect labeling), as well as some blurry, low-quality images.</li> <li> <em>Retrain the model</em>. This will definitely improve inter-class separation (w.r.t the metric loss function) among the classes present in the input dataset</li> </ul> <p>I had a lot of fun working this project. After finishing, I have come to really appreciate the dlib C++ API; it provides <em>so</em> much functionality in one project: linear algebra, machine learning, multithreading, optimization, … the list goes on-and-on. I am really looking forward to working more with this library in future projects.</p> <p>I know that I’ve only been able to highlight portions of the project above, but I’m happy to discuss the other aspects of the project over email or whatever (see contact info at the bottom of <a href="https://jwdinius.github.io">here</a>).</p> <p>I hope that you got something out of this post. Thanks for reading!</p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Joe Dinius, Ph.D.. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>