<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://jwdinius.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jwdinius.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-12-19T15:17:53+00:00</updated><id>https://jwdinius.github.io/feed.xml</id><title type="html">blank</title><subtitle>Personal webpage of Joe Dinius, Ph.D. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">State estimation for fixed-wing UAV</title><link href="https://jwdinius.github.io/blog/2023/sim-observer/" rel="alternate" type="text/html" title="State estimation for fixed-wing UAV"/><published>2023-10-22T07:00:00+00:00</published><updated>2023-10-22T07:00:00+00:00</updated><id>https://jwdinius.github.io/blog/2023/sim-observer</id><content type="html" xml:base="https://jwdinius.github.io/blog/2023/sim-observer/"><![CDATA[<p>As mentioned in a <a href="/blog/2023/sim-autopilot">previous post</a>, I have been working through the <a href="https://press.princeton.edu/books/hardcover/9780691149219/small-unmanned-aircraft">Small Unmanned Aircraft</a> book by Beard and McLain. In the aforementioned post, I presented implementations for fixed-wing UAV flight controllers. For the state feedback, the true states from the simulation are used. True state information is not available in actual UAV applications so estimates must be made using onboard sensor measurements; e.g., from GPS, altimeters, airspeed sensors, magnetometers, and accelerometers. In this post</p> <p>In working through the estimation techniques of Chapter 8, I applied additional techniques to improve the state estimate. After discussing these techniques, I will present my implementation of the estimator.</p> <p>Before reading this post, I suggest reviewing chapters 7 and 8 of the book or the corresponding <a href="https://github.com/randybeard/mavsim_public#lecture-material">lecture slides</a>. You should also understand the wind triangle relationships from Chapter 2 (pg. 22).</p> <h2 id="additional-techniques">Additional techniques</h2> <h3 id="add-magnetometer-measurements">Add magnetometer measurements</h3> <p>Magnetometer models for measuring heading are presented in Chapter 7 of the book and <a href="https://drive.google.com/file/d/1BMceIPDGzBda9w5R5LrNnouabS8lQ9s_/view">lecture slides</a>. I found the derivation of these models to be unclear and incomplete so I decided to work out the details of the model for myself.</p> <p>Let \(B\) be the magnetic field strength at the vehicle’s location. The vector for magnetic north with origin at the vehicle center, \(\mathbf{m}^m\), can be expressed as \(\mathbf{m}^m = [B, 0, 0]^T\). The magnetic inclination, \(\iota\), and declination, \(\delta\), can be used to find the relationship between magnetic and true (geographic) north:</p> \[\begin{aligned} \mathbf{m}^i &amp;\triangleq R(0, -\iota, \delta) \mathbf{m}^m \\ &amp;= \begin{bmatrix} \cos \delta &amp; -\sin \delta &amp; 0 \\ \sin \delta &amp; \cos \delta &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix} \ \begin{bmatrix} \cos \iota &amp; 0 &amp; -\sin \iota \\ 0 &amp; 1 &amp; 0 \\ \sin \iota &amp; 0 &amp; \cos \iota \end{bmatrix} \mathbf{m}^m \\ &amp;= B \begin{bmatrix} \cos \delta \cos \iota \\ \sin \delta \cos \iota \\ \sin \iota \end{bmatrix} \end{aligned}\] <p>where, \(\mathbf{m}^i\), is magnetic north expressed in a local NED coordinate frame. Declination, inclination, and field strength are functions of latitude and longitude on the Earth’s surface; see <a href="https://en.wikipedia.org/wiki/Earth%27s_magnetic_field">here</a> for more information on these quantities. Practically speaking, values for these quantities can be found using a table lookup. For this post, I assume the values from the book: \(\delta = 12.5^{\circ}\), \(\iota = 66^{\circ}\) (near Provo, UT).</p> <p>The magnetometer is composed of three orthogonal sensors designed to measure magnetic field strength along each body axis: \(b_x\), \(b_y\), and \(b_z\). Let \(\mathbf{m}^b \triangleq [b_x, b_y, b_z]^T\) be the measurement vector. It follows that:</p> \[\begin{aligned} R_b^i \mathbf{m}^b &amp;= \mathbf{m}^i \\ R_{v_2}^{v_1} (\theta) R_{b}^{v_1}(\phi) \mathbf{m}^b &amp;= R_i^{v_1} (\psi) \mathbf{m}^i \end{aligned}\] <p>where \(\theta\) and \(\phi\) are the estimated pitch and roll angles from the attitude filter described in the book. The intermediate coordinate frames, \(v_1\) and \(v_2\), are as defined in the book. To solve for \(\psi\), look at the three equalities derived from the expression above:</p> \[\begin{aligned} B \begin{bmatrix} \cos \psi \cos \iota \cos \delta + \sin \psi \cos \iota \sin \delta \\ -\sin \psi \cos \iota \cos \delta + \cos \psi \cos \iota \sin \delta \\ \sin \iota \\ \end{bmatrix} &amp;= \begin{bmatrix} b_x \cos \theta + b_y \sin \phi \sin \theta + b_z \cos \phi \sin \theta \\ b_y \cos \phi - b_z \sin \phi \\ -b_x \sin \theta + b_y \sin \phi \cos \theta + b_z \cos \phi \cos \theta \end{bmatrix} \end{aligned}\] <p>Note that when declination is negligible, as assumed in Peter Corke’s <a href="https://robotacademy.net.au/lesson/using-magnetometers/">video</a>, the expression for \(\psi\) is simply:</p> \[\psi = \tan^{-1} \frac{\cos \theta ( b_z \sin \phi - b_y \cos \phi)}{b_x + B \sin \iota \sin \theta}\] <p>To estimate \(\psi\) without assuming declination is zero, either the root of one of the first two elements of the vector equality must be evaluated, or the minimum of a convex error function involving both terms must be found. The second approach worked better for me in practice:</p> \[\begin{aligned} e_1(\psi) &amp;\triangleq B (\cos \psi \cos \iota \cos \delta + \sin \psi \cos \iota \sin \delta) \\ &amp;- b_x \cos \theta - b_y \sin \phi \sin \theta - b_z \cos \phi \sin \theta \\ e_2(\psi) &amp;\triangleq B (-\sin \psi \cos \iota \cos \delta + \cos \psi \cos \iota \sin \delta) \\ &amp;- b_y \cos \phi + b_z \sin \phi \\ \psi &amp;= \arg \min \bigl ( e_1^2 + e_2^2 \bigr ) \end{aligned}\] <h3 id="add-altitude-and-flight-path-angle-to-gps-model-while-removing-heading-angle">Add altitude and flight path angle to GPS model while removing heading angle</h3> <p>Incorporating the magnetometer measurement in the attitude estimation makes heading directly observable. This is an improvement over the GPS model wherein heading is inferred from a dynamics model. The value from the attitude estimator is used for heading in the GPS model.</p> <p>The GPS model presented in the book is planar: no consideration of change along the \(z\)-axis is considered. Adding altitude, \(h\), and flight path angle, \(\gamma\), makes motion in the vertical plane observable. Except for the following updates, all quantities in the GPS measurement model remain the same:</p> \[\begin{aligned} V_g &amp;= \sqrt{\bigl( V_a \cos \psi \cos \gamma_a + w_n \bigr)^2 + \bigl( V_a \sin \psi \cos \gamma_a + w_e \bigr)^2 + \bigl( -V_a \sin \gamma_a + w_d \bigr)^2} \\ &amp;\triangleq \sqrt{V_n^2 + V_e^2 + V_d^2} \\ \chi &amp;= \tan^{-1} \frac{V_a \sin \psi \cos \gamma_a + w_e}{V_a \cos \psi \cos \gamma_a + w_n} \\ &amp;\triangleq \tan^{-1}\frac{V_e}{V_d} \\ \gamma &amp;= \sin^{-1} \frac{-(-V_a \sin \gamma_a + w_d)}{V_g} \\ &amp;\triangleq - \sin^{-1}\frac{V_d}{V_g} \end{aligned}\] <p>Level flight \((\gamma = 0)\) is no longer assumed, so the pseudo measurement model becomes:</p> \[\begin{aligned} y_{\text{wind},n} &amp;= V_a \cos \psi + w_n - V_g \cos \chi \cos \gamma \\ &amp;\triangleq V_n - V_n' \\ y_{\text{wind},e} &amp;= V_a \sin \psi + w_e - V_g \sin \chi \cos \gamma \\ &amp;\triangleq V_e - V_e' \\ y_{\text{wind},d} &amp;= w_d + V_g \sin \gamma \\ &amp;\triangleq V_d - V_d' \end{aligned}\] <p>It is assumed that \(\gamma_a \triangleq \theta - \alpha = 0\).</p> <p>The GPS process model becomes:</p> \[\begin{aligned} \begin{bmatrix} \dot p_n \\ \dot p_e \\ \dot p_d \\ \dot V_g \\ \dot \chi \\ \dot \gamma \\ \dot w_n \\ \dot w_e \\ \dot w_d \end{bmatrix} = \begin{bmatrix} V_n' \\ V_e' \\ V_d' \\ \frac{V_n \dot V_n + V_e \dot V_e + V_d \dot V_d}{V_g} \\ \frac{\dot V_e V_n - \dot V_n V_e}{V_e^2 + V_n^2} \\ -\Bigl ( \frac{1}{\sqrt{V_n^2 + V_e^2}} \Bigr ) \frac{\dot V_d V_g - \dot V_g V_d}{V_g} \\ 0 \\ 0 \\ 0 \end{bmatrix} \end{aligned}\] <p>Note the difference in the expression for \(\dot \chi\); the book uses a coordinated turn model for the expression whereas my approach uses the derivative of the exact expression directly.</p> <h3 id="quantify-variances-explicitly">Quantify variances explicitly</h3> <p>Before reading through this section, I encourage you to review how <a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty">variance propagates</a> when there is a functional relationship with quantities whose variance is known.</p> <h4 id="process">Process</h4> <p>The book doesn’t specify how to set the \(Q\) matrices for the two EKFs presented. For the attitude EKF, the equations-of-motion for the model are exact (i.e., they match the true dynamics) so the process model only needs to account for errors in the inputs to the model: \(p, q,\) and \(r\). These parameters come from a low-pass filter applied to gyro measurements.</p> <p>For the GPS EKF, the process model assumes zero acceleration, so any acceleration of the actual vehicle needs to be accounted for as noise in the model. Assuming that \(\sigma_{\text{accel}}\) is the standard deviation of the acceleration per channel, the process noise \(Q\) becomes:</p> \[Q = \text{diag} \begin{bmatrix} (\sigma_{\text{accel}} \Delta t)^2 \\ (\sigma_{\text{accel}} \Delta t)^2 \\ (\sigma_{\text{accel}} \Delta t)^2 \\ 3 \sigma_{\text{accel}}^2 \\ 2 \frac{\sigma_{\text{accel}}^2}{V_g} \\ 2 \frac{\sigma_{\text{accel}}^2}{V_g} \\ \sigma_{\text{wind}}^2 \\ \sigma_{\text{wind}}^2 \\ \sigma_{\text{wind}}^2 \end{bmatrix}\] <p>The wind velocity is assumed to be in steady state, so any change is modeled as noise (with standard deviation \(\sigma_{\text{wind}}\)).</p> <h4 id="measurements">Measurements</h4> <p>The low-pass filter and GPS measurement models presented provide a means of calculating expected (mean) values for directly observable states, but no such method is provided for expressing the uncertainty (variance) of those estimates.</p> <p>Recall the recursive low-pass filter presented in Chapter 8:</p> \[y_{n+1} = \alpha y_n + (1 - \alpha) u_n\] <p>where \(y_n\) and \(u_n\) are the state estimate and measurement at time \(n\), respectively. Using induction, the contribution of every prior measurement to the current estimate is written as:</p> \[y_{n} = \alpha^n u_0 + (1-\alpha) \sum_{i=1}^n \alpha^{n-i} u_i\] <p>Assuming that the measurement variance, \(\sigma_{uu}\), is constant at each measurement step, the expression for the estimate variance, \(\sigma_{y_{n}y_{n}}\), is found inductively to be:</p> \[\begin{aligned} \sigma_{y_{n}y_{n}} &amp;= \biggl [ \Bigl(\frac{\partial y_n}{\partial u_0} \Bigr )^2 + \dots + \Bigl(\frac{\partial y_n}{\partial u_{n-1}} \Bigr)^2 \biggr ] \sigma_{uu} \\ &amp;= \Bigl [\alpha^{2n} + (1-\alpha)^2 \sum_{i=0}^{n-1} \alpha^{2i} \Bigr ] \sigma_{uu}. \end{aligned}\] <p>The sum in the expression above is a <a href="https://en.wikipedia.org/wiki/Geometric_series">geometric series</a>, so it follows that:</p> \[\begin{aligned} \sigma_{y_{n}y_{n}} &amp;= \biggl [\alpha^{2n} + (1-\alpha)^2 \frac{1-\alpha^{2n}}{1-\alpha^2} \biggr ] \sigma_{uu} \end{aligned}\] <p>Using the same methodology, the recursive relationship for the GPS error is found to be:</p> \[\begin{aligned} \sigma_{\nu_{n}\nu_{n}} &amp;= \Bigl ( \sum_{i=0}^n a^{n - i} \Bigr ) \sigma_{\eta_{\text{GPS}} \eta_{\text{GPS}}} \\ &amp;= \frac{1 - a^{n+1}}{1-a} \sigma_{\eta_{\text{GPS}} \eta_{\text{GPS}}} \end{aligned}\] <p>where \(a \triangleq e^{-k_{\text{GPS}} T_s}\). Refer to Section 7.5 in the book for more details.</p> <p>These expressions are derived using the <a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty#Simplification">univariate form</a> of the propagation of uncertainty method. There is a <a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty#Non-linear_combinations">multivariate form</a> of this method:</p> \[\begin{aligned} \Sigma_{\mathbf{y}} &amp;= J \Sigma_{\mathbf{x}} J^T \end{aligned}\] <p>where \(\mathbf{y} = \mathbf{f}(\mathbf{x})\) and \(J\) is the Jacobian of \(\mathbf{f}\) with respect to (wrt) \(\mathbf{x}\): \(\Bigl [ \frac{\partial f_i}{\partial x_j} \Bigr ]_{ij}\).</p> <p>The uni- and multivariate forms of uncertainty propagation are used in my implementation to provide well-reasoned, quantifiably correct estimates of process and measurement noise in the Kalman filter equations.</p> <h4 id="error-in-the-accelerometer-measurement-model">Error in the accelerometer measurement model</h4> <p>The accelerometer measurement model assumes the vehicle is in equilibrium, so this needs to be accounted for in the measurement noise. To quantify the error, I generated the following chart showing the difference between the actual acceleration and the output of the measurement model:</p> <p><img src="/assets/img/sim_observer/Figure_1.png" alt="model-error"/></p> <p>A conservative variance estimate based on these data is added to the accelerometer measurement noise to handle measurement updates for the model. The dashed lines represent the 3-\(\sigma\) bounds. The data is well-approximated by a zero mean Gaussian distribution.</p> <h3 id="fuse-independent-estimates">Fuse independent estimates</h3> <p>Altitude is directly observable from two independent measurement sources: the GPS and the altimeter. The GPS measurement is incorporated into a position estimator (using a Kalman filter), whereas the altimeter measurements are fed into a low-pass filter. Both of these approaches, after using the uncertainty quantification method from the previous section, have well-defined mean and variance. These quantities can be fused to provide a better (i.e., smaller variance) estimate for altitude:</p> \[\begin{aligned} h &amp;= h_{\text{alt}} + K \bigl (h_{\text{GPS}} - h_{\text{alt}} \bigr ) \\ \sigma_{hh} &amp;= (1 - K) \sigma_{h_{\text{alt}} h_{\text{alt}}} \\ K &amp;= \frac{\sigma_{h_{\text{alt}} h_{\text{alt}}}}{\sigma_{h_{\text{alt}} h_{\text{alt}}} + \sigma_{h_{\text{GPS}} h_{\text{GPS}}}} \end{aligned}\] <p>Note that the relationship above looks a lot like the Kalman filter update equations; the “prior” (\(h_{\text{alt}}\) in this context) and its variance (\(\sigma_{h_{\text{alt}} h_{\text{alt}}}\)) are combined with a “measurement” update (\(h_{\text{GPS}}\)) and its variance (\(\sigma_{h_{\text{GPS}} h_{\text{GPS}}}\)) optimally assuming that the prior and measurement models are Gaussian distributed about the true altitude.</p> <h2 id="implementation">Implementation</h2> <p><img src="/assets/img/sim_observer/estimation.gif" alt="estimation"/></p> <p><a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/estimation/observer.py">GitHub</a></p> <p>My implementation uses the successive loop closure flight controller described <a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/estimation/observer.py">here</a>. You can see from the video above that the estimator works pretty well:</p> <ul> <li>Heading, pitch, roll, and course angle estimates are never more than a few degrees from the actual values</li> <li>Position errors are considerably less than 1m; most often times the errors are only a few centimeters.</li> <li>Velocity errors are very small</li> <li>Wind estimates converge quickly when the vehicle is not maneuvering. When the vehicle maneuvers, the estimator has difficulty rejecting the hypothesis that the wind is what’s causing the maneuver. This could be addressed by trying either (or both): <ul> <li>reducing \(\sigma_{\text{wind}}\), <em>or</em></li> <li>increasing \(\sigma_{\text{accel}}\).</li> </ul> </li> </ul> <p>The best words of advice/caution I can give to would-be implementors are:</p> <ul> <li>Start by getting the attitude estimator working properly. This estimator is less complex because it has fewer dimensions and there are no process model assumptions that need to be accounted for.</li> <li>Set a reasonable gating threshold for the GPS measurement updates. I couldn’t get the estimator to work properly when gating aggressively, but I think that a balance needs to be struck that still throws out outliers.</li> <li>Use <a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/14-Adaptive-Filtering.ipynb">Zarchan’s method</a> to inflate the process noise covariance to aid the estimator in better balancing the incorporation of the prior into the posterior estimate.</li> <li>Lower the controller gains considerably (~30-50%) from the Chapter 6 implementation of flight controllers. Otherwise, your vehicle will have low amplitude, high frequency oscillations throughout flight; particularly so in the pitch channel.</li> </ul> <h2 id="summary">Summary</h2> <p>I presented my additions to the observer model presented in the Small Unmanned Aircraft book, as well as a functional implementation. I learned a lot about how finnicky estimators can be and I hope this post helps the person who reads it avoid some of the pitfalls I encountered while working through this part of the book. At some point in the future (definitely not anytime soon), I would like to implement a complete state estimator that includes biases, wind angles \(\alpha\) and \(\beta\), and drag force. Having an estimate for drag will allow me to use the nonlinear TECS flight controller I wrote about last <a href="/blog/2023/sim-autopilot">time</a>.</p> <p>Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Implementing low-pass and extended Kalman filters to observe fixed-wing UAV state.]]></summary></entry><entry><title type="html">Implementation of different fixed-wing flight controllers</title><link href="https://jwdinius.github.io/blog/2023/sim-autopilot/" rel="alternate" type="text/html" title="Implementation of different fixed-wing flight controllers"/><published>2023-10-13T10:00:00+00:00</published><updated>2023-10-13T10:00:00+00:00</updated><id>https://jwdinius.github.io/blog/2023/sim-autopilot</id><content type="html" xml:base="https://jwdinius.github.io/blog/2023/sim-autopilot/"><![CDATA[<p>I have been working through the <a href="https://press.princeton.edu/books/hardcover/9780691149219/small-unmanned-aircraft">Small Unmanned Aircraft</a> book by Beard and McLain this year and I want to write about some of the interesting concepts I have been exploring, some of which are covered in the book and some of which are not. The book does an excellent job of presenting the basics of small fixed-wing aircraft, including</p> <ul> <li>Vehicle modeling</li> <li>Flight dynamics</li> <li>Controller design</li> </ul> <p>There is a <a href="https://drive.google.com/file/d/1I3dwUmBBzwT_A1MlBk2XRl4clZ7RHuOQ/view">draft update</a> to the first edition of the book in the works that further develops additional concepts but I have found that some of the updated sections, particularly those concerning flight controls, have insufficient information to implement functional controllers. This post is my attempt to provide sufficient information to implement and test the LQR and nonlinear total energy control system (TECS) controllers described <a href="http://staff.uz.zgora.pl/wpaszke/materialy/spc/Lec18.pdf">here</a> and <a href="https://drive.google.com/file/d/1ByPPrxSrBNcFMv35rYhIezPpBGP_h_ic/view">here</a>, respectively.</p> <p>Before reading through this post, it would help to review the first six chapters of the book or the corresponding <a href="https://github.com/randybeard/mavsim_public#lecture-material">lecture slides</a>. In this post, I assume the reader is familiar with the following material from the book:</p> <ul> <li>fixed-wing vehicle model (Chapters 1-4)</li> <li>reduced linear models for lateral and longitudinal dynamics (Chapter 5)</li> <li>the main control objectives for a fixed-wing flight controller; namely, achieving desired <ul> <li>course angle</li> <li>altitude, and</li> <li>airspeed</li> </ul> </li> </ul> <p>This post is broken up into three sections:</p> <ul> <li>Implementing successive loop closure</li> <li>Linear Quadratic Regulator (LQR) control</li> <li>Nonlinear TECS control</li> </ul> <p>In the first section, I will present information that I found useful while implementing the controller described in the book. The second and third sections will present more details for the other approaches, including</p> <ul> <li>Background; i.e., the <em>why</em></li> <li>Derivation; i.e., the <em>what</em></li> <li>Implementation; i.e., the <em>how</em></li> </ul> <p>To ensure a fair comparison between the controllers, a common reference flight path that introduces step responses in all three control objectives, sometimes concurrently, is chosen. For each controller test scenario, the true vehicle state is used for feedback.</p> <h2 id="implementing-successive-loop-closure">Implementing successive loop closure</h2> <p>This controller is described in Chapter 6 of the book. Read the book or the corresponding <a href="https://drive.google.com/file/d/1BfLD2KDyalXuANrA14RC29EWIw3xF4fU/view">lecture slides</a> for the derivation and relevant details. This controller’s design assumes that the dynamics between course, altitude, and airspeed are decoupled, which allows the three control objectives to be achieved with two independent controllers: one for lateral control (course) and one for longitudinal control (altitude and airspeed). Both controllers use PID - proportional, integral, derivative - to drive errors between the objective (reference) and system state to zero using state feedback.</p> <p>The lateral controller consists of two main control loops, a higher-rate inner loop for roll control (implemented as a PD controller) and a lower-rate outer loop for course angle control (implemented as a PI controller). Less critical, but still important, is a low-pass filter to hold the sideslip angle at zero; i.e., counteract high-frequency disturbances to yaw/heading angle.</p> <p>The longitudinal controller consists of two (outer) control loops. The first loop is for altitude control, which is achieved with an inner, high-rate loop for pitch angle (a PD controller) and a lower-rate outer loop for altitude control (a PI controller). The second control loop is for airspeed and is implemented as a PI controller.</p> <p>The main idea with successive loop closure is to design inner loops so that they can be reasonably approximated by a DC gain in the next loop to close. Each loop is modeled as a second-order linear system with control damping and bandwidth as design parameters. One drawback of this approach is when there are multiple loops to close whereby modeling errors in innermost loops will greatly constrain stability margins and control bandwidth for outer loops. Despite this drawback, this controller is quite useful when for fixed-wing flight control.</p> <p>The guidance for implementing and tuning this controller is summarized as follows:</p> <ul> <li>Integrals add delay and instability to control loops, so avoid them in high-rate roll and pitch loops</li> <li>Integrals are appropriate for correcting steady-state errors in low-rate outer loops on course, altitude, and airspeed</li> <li>Starting from the innermost control loop in each channel and working outward, choose the next loop’s bandwidth to be a multiple (&gt;5) of the previous loop’s bandwidth.</li> </ul> <p>Following the guidance, I was able to implement and test the successive loop closure controller.</p> <p><img src="/assets/img/sim_controller/pid-ch6.gif" alt="piddemo"/></p> <p><a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/control/autopilot.py">GitHub</a></p> <p>The controller works well with only a moderate amount of tuning. I found that a bandwidth multiplier factor greater than 10, substantially greater for the altitude outer loop, worked well to handle step responses without ringing or instability.</p> <p>Here are some of the salient points I discovered while tuning this controller:</p> <ul> <li>Selecting damping ratios greater than 1 for all loops, except roll, helped to avoid overshoot and ringing in observed system response to step input changes.</li> <li>A very responsive (i.e., high bandwidth) control loop is required for the innermost longitudinal control loop (on pitch angle from elevator command) to counteract the pull of gravity on the vehicle.</li> <li>Relative to the book’s recommendation of bandwidth multiplier of 5-10 between inner and outer loops, a <em>significantly</em> larger multiplier (=50) was selected for the pitch angle to altitude outer loop controller. This large multiplier was selected to eliminate ringing in altitude.</li> </ul> <h3 id="pros-and-cons">Pros and cons</h3> <h4 id="pros">Pros</h4> <ul> <li>Simple design. The control problem is decomposed into smaller, manageable decoupled objectives.</li> <li>Few control knobs to tune. This makes optimal gain selection using <a href="https://www.cs.ubc.ca/labs/lci/mlrg/slides/mlrg_CD.pdf">coordinate-ascent</a> or similar approach simpler.</li> <li>Control margins (gain and phase) are quantifiable using methods from linear systems analysis (i.e., using Bode or Nyquist plots).</li> </ul> <h4 id="cons">Cons</h4> <ul> <li>The actual system response to step input changes shows that the dynamics are not decoupled, as assumed. Step changes in altitude (controlled by the longitudinal controller) are shown to affect system response in course angle (controlled by the lateral controller).</li> <li>The system is slow to drive out errors because of the low bandwidth on outer control loops.</li> </ul> <h2 id="lqr-control">LQR control</h2> <h3 id="background">Background</h3> <p align="center" width="100%"> <img width="66%" src="/assets/img/sim_controller/LQRff.drawio.png"/> </p> <p>The goal of LQR is to design a controller for a linear system like the one above that minimizes an objective function, \(J\), of two inputs:</p> <ul> <li>\(\mathbf{x}\) is system error</li> <li>\(\mathbf{u}\) is control effort</li> </ul> <p>LQR is an example of an <a href="https://www.mathworks.com/discovery/optimal-control.html#:~:text=Optimal%20control%20is%20a%20condition,Linear%20Quadratic%20Gaussian%20(LQG)%20control">optimal control law</a> with two important constraints: both the objective function and the feedback take particular forms. The objective function is the integral:</p> \[J = \int_0^\infty \Bigl ( \mathbf{x}^T Q \mathbf{x} + \mathbf{u}^T R \mathbf{u} \Bigr ) dt\] <p>where the matrices \(Q\) and \(R\) are design parameters that provide the designer flexibility in weighting system errors relative to control effort. The second constraint is that the feedback is linearly proportional to the system error; i.e., \(\mathbf{u} = -K \mathbf{x}\).</p> <p>After selecting \(Q\) and \(R\), the gain \(K\) is computed such that the resulting feedback, \(\mathbf{u}\), minimizes the objective function defined for the system.</p> <p>The feedback is only one part of the controller design though. There is a reference command, \(\mathbf{y}_d\) that we want the system to continuously follow. This input could be a step change in control objective or a trajectory. The reference could be tracked with feedback alone, however the addition of a feedforward term, \(K_r \mathbf{y}_d\), improves tracking performance when properly designed.</p> <h3 id="derivation">Derivation</h3> <h4 id="modeling-the-system">Modeling the system</h4> <p>As in the successive loop closure control scheme described in the previous section, the vehicle controller is separated into two decoupled controllers for lateral and longitudinal dynamics. Each controller is designed around a common, fixed <em>trim point</em>; where the vehicle is in force- and moment-free equilibrium.</p> <h5 id="finding-a-trim-point">Finding a trim point</h5> <p>The book describes an optimization technique for finding the desired trim flight condition in <a href="https://drive.google.com/file/d/1BRS8PaOMrFdotGgb7oXOZloANh3fzUAo/view">Chapter 5</a>. The inputs to the optimization are the following three quantities:</p> <ul> <li>The desired airspeed, \(V_a^*\)</li> <li>The desired flight path angle, \(\gamma^*\)</li> <li>The desired orbit radius, \(R^*\)</li> </ul> <p>If the desired flight condition is level flight along a straight-line path, which is assumed for the LQR controller design, then \(\gamma^*=0\) and \(R^*=\infty\).</p> <h5 id="linearization">Linearization</h5> <p>The full system dynamics, as described in <a href="">Chapter 3</a>, are nonlinear. The LQR controller can only be applied to such systems after linearizing about a trim point. The controller that is designed will generate the control input to apply <em>as a correction to</em> the trim control input. For example, if the trim flight condition has throttle command, \(\delta_t^*\), and the LQR controller for the linearized system generates a throttle correction, \(u_{\delta_t}\), the total system throttle command would be \(\delta_t^* + u_{\delta_t}\).</p> <p>Recall, both the lateral and longitudinal dynamics will take the form:</p> \[\begin{aligned} \dot{\mathbf{x}} &amp;= A \mathbf{x} + B \mathbf{u} \\ \mathbf{y} &amp;= C \mathbf{x} \end{aligned}\] <p>The linearized dynamics for both the lateral and longitudinal systems are described in <a href="">Chapter 5</a> of the book.</p> <p>The feedback control input is: \(\mathbf{u}_{fb} = -K \mathbf{x}\). The feedforward control input is a linear combination of reference commands: \(\mathbf{u}_{ff} = K_r \mathbf{y}_d\). The total control input is the sum of these two terms:</p> \[\mathbf{u} = K_r \mathbf{y}_d - K \mathbf{x}\] <p>The resulting controlled system dynamics are:</p> \[\begin{aligned} \dot{\mathbf{x}} &amp;= (A - BK) \mathbf{x} + B K_r \mathbf{y}_d \\ \mathbf{y} &amp;= C \mathbf{x} \end{aligned}\] <h4 id="selecting-the-feedforward-gain-k_r">Selecting the feedforward gain, \(K_r\)</h4> <p>The gain \(K_r\) is selected so that the steady-state output, \(\mathbf{y}_e\), equals the desired reference input, \(\mathbf{y}_d\). “Steady-state” means that the system is in equilibrium; i.e., \(\dot{\mathbf{x}} = \mathbf{0}\). It follows that:</p> \[\begin{aligned} \mathbf{0} &amp;= (A - BK) \mathbf{x}_e + B K_r \mathbf{y}_d \\ \mathbf{y}_e &amp;= C \mathbf{x}_e = \mathbf{y}_d \\ \mathbf{x}_e &amp;= -(A - BK)^{-1} B K_r \mathbf{y}_d \end{aligned}\] <p>These conditions lead to the following equality:</p> \[\begin{aligned} \mathbf{y}_d &amp;= C \mathbf{x}_e = -C (A - BK)^{-1} B K_r \mathbf{y}_d \end{aligned}\] <p>which implies that:</p> \[\begin{aligned} I &amp;= -C (A - BK)^{-1} B K_r \\ \implies K_r &amp;= -\bigl ( C (A - BK)^{-1} B \bigr )^{-1} \end{aligned}\] <h4 id="feedback-with-integral-action-added">Feedback with integral action added</h4> <p>There will be modeling errors due to linearization and disturbances. A standard approach for dealing with such errors is to add an integral term by augmenting the state vector, \(\mathbf{x}\), with the vector \(\mathbf{z}\):</p> \[\begin{aligned} \mathbf{z}(t) &amp;= \int_0^t (\mathbf{y}_d - C \mathbf{x}) dt \\ \dot{\mathbf{z}} &amp;= \mathbf{y}_d -C \mathbf{x} \end{aligned}\] <p>The resulting augmented system dynamics are:</p> \[\begin{aligned} \begin{bmatrix} \dot{\mathbf{x}} \\ \dot{\mathbf{z}} \end{bmatrix} &amp;= \begin{bmatrix} A &amp; \mathbf{0} \\ -C &amp; \mathbf{0} \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ \mathbf{z} \end{bmatrix} + \begin{bmatrix} B \\ \mathbf{0} \end{bmatrix} \mathbf{u} + \begin{bmatrix} \mathbf{0} \\ 1 \end{bmatrix} \mathbf{y}_d \\ \mathbf{y} &amp;= \begin{bmatrix} C &amp; \mathbf{0} \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ \mathbf{z} \end{bmatrix} \end{aligned}\] <p>Applying the LQR design process (see Chapter 9 of <a href="https://www.amazon.com/Control-System-Design-Introduction-State-Space/dp/0486442780">Friedland’s Control System Design book</a> for details) to these augmented dynamics leads to the optimal linear feedback law:</p> \[\begin{aligned} \mathbf{u}_{fb} &amp;= K_+ \mathbf{x}_+\\ &amp;\triangleq - \begin{bmatrix} K &amp; K_i \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ \mathbf{z} \end{bmatrix} \end{aligned}\] <p>The reason for breaking the augmented gain, \(K_+\) into two components, \(K\) and \(K_i\), is so that <a href=""><em>integrator windup</em></a> can be mitigated. The consequence of integrator windup is that large integrated errors can force control inputs to saturate over time. Saturated control can drive the system unstable if applied for any appreciably long period of time.</p> <p>Integrator anti-windup for scalar integral terms is described in <a href="">Chapter 6</a> of the book. One of the proposed schemes for addressing windup can be modified to apply to the multivariate case. Let \(\Delta \mathbf{z}\) be the correction to apply to the integral term, \(\mathbf{z}\), so that the control input \(\mathbf{u}\) is no greater than its saturated value. In the equations that follow, the superscript \(.^-\) means the value before the correction \(\mathbf{z}\) has been applied. The correction is computed by solving the linear system:</p> \[\begin{aligned} K_i \Delta \mathbf{z} = \mathbf{u}^- - \mathbf{u}. \end{aligned}\] <p>An important note here: <em>the control vectors,</em> \(\mathbf{u}^-\) and \(\mathbf{u}\) <em>are representative of the sum of the trim control, the feedforward term,</em> and <em>the feedback term</em>; i.e., the saturation is to be applied to the full control input, not just the feedforward and feedback terms derived in this section.</p> <p>After computing the correction \(\Delta \mathbf{z}\), the stored value for the integral term \(\mathbf{z}\) is updated as \(\mathbf{z} = \mathbf{z}^- + \Delta \mathbf{z}\). From the form of the linear equation to solve, it is clear that, when the control vector has not saturated, the correction \(\Delta \mathbf{z}\) will be zero.</p> <p>Following on the discussion from earlier in this section: if the augmented system dynamics are <a href="http://staff.uz.zgora.pl/wpaszke/materialy/spc/Lec18.pdf">Hurwitz</a>, then there is a theoretical guarantee that the system will reach \(\mathbf{y}_d\) in steady-state; i.e., as \(t \to \infty\) without feedforward. The inclusion of the feedforward term, \(K_r \mathbf{y}\), is therefore still not necessary to achieve the control objective \(\mathbf{y}_d\).</p> <h3 id="implementation">Implementation</h3> <p><img src="/assets/img/sim_controller/lqr-ch6.gif" alt="lqrdemo"/></p> <p><a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/control/autopilot_lqr.py">GitHub</a></p> <p>The <a href="">implementation</a> of this controller is straightforward when following the material from Chapter 9 of Friedland’s book. The main consideration for controller performance is selection of the design parameters, \(Q\) and \(R\). <a href="https://www.sciencedirect.com/science/article/pii/S1110016821007900#:~:text=According%20to%20this%20rule%2C%20Q,concerned%20with%20disturbances%20and%20uncertainty.">Bryson and Ho</a> provide the following guidance:</p> <ul> <li>Set the off-diagonal terms of both \(Q\) and \(R\) to \(0\).</li> <li>Set the diagonal terms of \(Q\) to the recriprocal of the <em>expected</em> squared error of the state.</li> <li>Set the diagonal terms of \(R\) to the reciprocal of the squared maximum control input.</li> </ul> <p>Choosing the expected maximum errors for the elements of \(\mathbf{x}\) is straightforward, since the maximum expected step responses can be quantified. For the integral terms, the maximum expected error assumes linear decay of the error integrand over a desired decay time.</p> <p align="center" width="100%"> <img width="33%" src="/assets/img/sim_controller/triangle-error.jpg"/> </p> <p>The maximum error chosen for the integral error is the same as for the corresponding element of \(\mathbf{x}\). The desired decay time is an additional design parameter. Choosing a shorter decay time means the controller will prioritize (relatively speaking) keeping the integrated error small.</p> <p>Bryson’s rule is great as a general rule of thumb, but is not generally robust to unmodeled effects like disturbances or errors with the model. In this case, with the inclusion of moderate wind, the parameters selected using the rule provide good performance. In fact, the performance looks better than that of the successive loop closure approach with regards to the following:</p> <ul> <li>The output rings less in response to step input changes.</li> <li>Errors converge to 0 faster.</li> <li>There is less coupling between the different channels in response to step input changes.</li> </ul> <h3 id="pros-and-cons-1">Pros and cons</h3> <h4 id="pros-1">Pros</h4> <ul> <li>The approach is mathematically rigorous; under certain assumptions, there is provable optimality of the control input computed.</li> <li>The coupling between states is accounted for directly in the model; at least to a first-order approximation.</li> <li>The controller is easy to implement, requiring only standard techniques from linear algebra.</li> </ul> <h4 id="cons-1">Cons</h4> <ul> <li>The controller is more complex than successive loop closure.</li> <li>The controller requires that the system be linearized about a trim point. In general, the further the state gets from the trim point, the less stable the system becomes.</li> <li>The selection of the design parameters, \(Q\) and \(R\), is non-trivial. Errors with the model, including disturbances, can be difficult to account for.</li> <li>There are no stability margin or robustness guarantees like there are when using frequency domain methods for linear systems.</li> </ul> <h2 id="nonlinear-tecs-control">Nonlinear TECS control</h2> <h3 id="background-1">Background</h3> <p>The LQR longitudinal controller is one way of dealing with the dynamic coupling between airspeed and pitch angle. As shown in the previous section, the approach works well for the test case considered, where the vehicle remains acceptably close to the trim point throughout operation. The linearity of LQR is an issue for large deviations from the trim point; e.g., when the vehicle is initially ascending to a cruising altitude.</p> <p><em>Total Energy Control System</em> (TECS) is a control methodology that recognizes that commanding airspeed, \(V_a\), and (airmass adjusted) flight path angle, \(\gamma_a\), can be used to drive the total energy of the aircraft to a desired state. As opposed to the other controllers discussed, where the primary control objective is to drive system errors to zero, the objective of TECS-based controllers is to drive the system’s kinetic and potential energies to desired values. Kinetic energy is proportional to airspeed (squared) and potential energy is proportional to elevation. Airspeed, \(V_a\), is adjusted most directly through commanding throttle, and elevation is affected most directly by commanding flight path angle, \(\gamma_a\).</p> <p>There are several approaches to implement a TECS-based controller. I will present a Lyapunov-based controller. This approach requires no trim point, so concerns about linearization present in LQR are not an issue.</p> <h3 id="derivation-1">Derivation</h3> <p>A more detailed derivation of the nonlinear TECS controller can be found Section IV of <a href="https://drive.google.com/file/d/1ByPPrxSrBNcFMv35rYhIezPpBGP_h_ic/view">this paper</a>. I will only discuss an outline of the approach, including whatever key assumptions are made along the way.</p> <p>Recall the equations of kinetic and potential energies, \(E_K\) and \(E_P\), respectively:</p> \[\begin{aligned} E_K &amp;= \frac{1}{2} m V_g^2 \\ E_P &amp;= m g h \\ \end{aligned}\] <p>where \(m, g, V_g\) and \(h\) are vehicle mass, gravitational acceleration at sea-level, ground speed, and altitude, respectively. The total energy, \(E_T\), is the sum of these two terms, whereas the energy difference, \(E_D\), is the difference, \(E_P - E_K\). If wind is assumed to be negligible, \(V_a = V_g\). <em>This assumption is important: since the vehicle only commands and measures airspeed directly.</em> The airspeed and altitude commands, \(V_a^d\) and \(h^d\), correspond directly to the desired energy of the system:</p> \[\begin{aligned} E_K^d &amp;= \frac{1}{2} m \bigl( V_a^d \bigr )^2 \\ E_P^d &amp;= m g h^d \\ E_T^d &amp;\triangleq E_P^d + E_K^d \\ E_D^d &amp;\triangleq E_P^d - E_K^d \end{aligned}\] <p>The control objective is to drive the kinetic and potential energies to the desired values. A <a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov function</a> in terms of the total energy and energy difference errors is chosen:</p> \[\begin{aligned} \tilde{E}_T &amp;\triangleq E_T^d - E_T \\ \tilde{E}_D &amp;\triangleq E_D^d - E_D \\ V &amp;= \frac{1}{2} k_T \tilde{E}_T^2 + \frac{1}{2} k_D \tilde{E}_D^2. \end{aligned}\] <p>Since \(V(t)\) must be positive semi-definite, i.e., \(V(t) \ge 0 \ \forall t\), the gains \(k_T\) and \(k_D\) must both be greater than or equal to 0. If a control input can be found such that \(\dot V &lt; 0 \ \forall t\), then it is true that the control input drives the system energies to the desired values.</p> <p>To find a control law that proves \(\dot V\) is strictly negative, \(V\) must be first written out in terms of the state variables \(V_a\) and \(h\) and differentiated. The result contains state derivatives for which a dynamics model must be assumed. A suitable and simple model is to assume that:</p> <ul> <li>The propeller thrust, \(T\), acts purely in the opposite direction as the aerodynamic drag, \(D\), and</li> <li>The climb rate of the aircraft is proportional to the airspeed and the airmass referenced flight path angle, \(\gamma_a\), which is the difference of the pitch angle, \(\theta\), and the angle-of-attack, \(\alpha\)</li> </ul> <p>or, in mathematical notation:</p> \[\begin{aligned} \dot V_a &amp;= \frac{T-D}{m} - g \sin \theta \\ \dot h &amp;= V_a \sin \gamma_a \end{aligned}\] <p>Differentiating \(V\) and applying the model described above leads to the following control law:</p> \[\begin{aligned} T &amp;= D + \frac{\dot E_T^d}{V_a} + k_T \frac{\tilde{E}_T}{V_a} \\ \theta &amp;= \alpha + \sin^{-1} \biggl [ \frac{\dot h^d}{V_a} + \frac{1}{2mgV_a} \bigl( k_T \tilde{E}_T + k_D \tilde{E}_D \bigr ) \biggr ] \end{aligned}\] <p>All that remains is to choose a model for the desired airspeed and climb rates that are used in the thrust command, \(T\). The simplest such model is first-order and proportional to the error between the desired and current states:</p> \[\begin{aligned} \dot V_a^d &amp;= k_{V_a} (V_a^d - V_a) \\ \dot h^d &amp;= k_h (h^d -h) \end{aligned}\] <h3 id="implementation-1">Implementation</h3> <p><img src="/assets/img/sim_controller/tecs-pid.gif" alt="tecsdemo"/></p> <p><a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/control/autopilot_tecs.py">GitHub</a></p> <p>The TECS approach applies only to the longitudinal channel so a lateral controller must be implemented separately. I chose to take the successive loop closure PID-based controller, but the LQR controller could have been chosen. Notice that the control law from the previous section defines commanded thrust and flight path angle. The expected control inputs are throttle and elevator, so a conversion between derived and actual controls is needed.</p> <p>Thrust is a nonlinear function of throttle and airspeed. I used this relationship to build a lookup table from thrust and airspeed to commanded throttle. The alternative is to do a computationally expensive root finding operation each control iteration, which works fine for simulation but would likely be too slow in an actual flight controller to meet real-time requirements. The elevator command comes from a PD controller on pitch error; the same as in the successive loop closure case but with different gains.</p> <p>The <a href="https://drive.google.com/file/d/1ByPPrxSrBNcFMv35rYhIezPpBGP_h_ic/view?usp=sharing">paper</a> shows that \(k_D\) should be greater than or equal to \(k_T\) and provides reference values for them. In practice, I found setting these terms (about 2 times) larger made the controller more responsive without negatively affecting performance. I found that the choice of gains \(k_{V_a}\) and \(k_h\) had significant impact on the overall responsiveness of the controller: setting the gains higher (&gt;1) led to fast response but with a lot of ringing, whereas gains near 1 provided a good balance between response and settling times.</p> <p>While implementing this controller, I observed steady-state errors on airspeed and/or altitude. These errors are likely caused by the ground speed not being equal to the airspeed when wind is present. To remove these steady state errors I added a simple PI controller on each channel with small gains, which provides a slight correction to remove any steady-state errors. I didn’t spend a significant amount of time in tuning these corrective controllers; choosing small gains between 0.1 and 0.3 seemed to work well enough without additional consideration.</p> <h3 id="pros-and-cons-2">Pros and cons</h3> <h4 id="pros-2">Pros</h4> <ul> <li>The controller is mathematically rigorous.</li> <li>The coupling between airspeed and altitude is accounted for.</li> <li>System errors are driven down much faster by this controller.</li> <li>No linearization is required.</li> <li>There are fewer control parameters than any of the other controllers considered.</li> </ul> <h4 id="cons-2">Cons</h4> <ul> <li>The controller only applies to the longitudinal channel.</li> <li>The assumption that ground speed and airspeed are the same leads to steady-state errors that must be handled independently.</li> <li>The controller is the most complex of the controllers considered.</li> </ul> <h2 id="summary">Summary</h2> <p>Three flight control schemes for a simulated fixed-wing aircraft were presented and applied to a common test case with step disturbances on feedforward reference commands and moderate wind effects. The successive loop closure controller was the simplest and easiest to implement, however it was difficult to tune and did not properly account for coupling between the different state terms. The LQR controller performed well, but it required finding a trim point and linearizing about it. To account for large deviations from the trim point; e.g., when a large step response in input command is requested, the control design parameter \(Q\) must be selected to lower the control bandwidth, which will affect how responsive the controller is. The TECS-based controller performed the best of all controllers, but it only works on the longitudinal channel and is very complex.</p> <p>Based on these observations, I think that the best flight controller that can be built from the options presented combines the lateral channel of the LQR controller with the TECS longitudinal controller; see <a href="https://github.com/jwdinius/uavbook/blob/jwd_solns/mavsim_python/control/autopilot_hybrid.py">GitHub</a> for the implementation.</p> <p>Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A comparison of three different flight controllers for a simulated fixed-wing aircraft.]]></summary></entry><entry><title type="html">Building the F1TENTH Racecar</title><link href="https://jwdinius.github.io/blog/2023/f110-buildout/" rel="alternate" type="text/html" title="Building the F1TENTH Racecar"/><published>2023-05-01T12:00:00+00:00</published><updated>2023-05-01T12:00:00+00:00</updated><id>https://jwdinius.github.io/blog/2023/f110-buildout</id><content type="html" xml:base="https://jwdinius.github.io/blog/2023/f110-buildout/"><![CDATA[<p>I feel like I have been putting together my Traxxas RC car <em>forever</em>. When I started back in 2017, the <a href="https://f1tenth.readthedocs.io/en/stable/getting_started/intro.html#doc-build-intro">F1TENTH project</a> wasn’t even a thing yet. Luckily for me, the documentation in this project is pretty easy to follow. I highlight some notable exceptions below.</p> <h2 id="bill-of-materials-bom">Bill-of-Materials (BoM)</h2> <p>For the most part, the <a href="https://docs.google.com/spreadsheets/d/1WT-UdjLTnyrb7CvHcuCxKLnRIN8DWroQ/edit#gid=606618920">Master BoM</a> is pretty good. There were two areas that required additional research on my part though:</p> <ol> <li>Which material to choose for the laser-cut platform deck?</li> <li>Which materials to choose for the power distribution module (PDM)?</li> </ol> <p>For the first item, it took some iteration. I started by ordering two black matte acrylic platform decks from <a href="https://www.ponoko.com/">Ponoko</a> but I snapped both of them when assembling the car. For the next order, I tried two stronger (and more expensive) materials - Black Melamine and Black Delrin. I installed the Black Delrin deck and it worked out fine.</p> <p>The second item required me to do some digging in the <a href="https://groups.google.com/g/f1_10/c/GGuCTB-l78Y">f1tenth forums</a>. Thankfully, I was able to find an <a href="https://docs.google.com/spreadsheets/d/1tbXGLgL5GAHyR6L9F-SnwSzdjveUt-EyJ4-mb8ZAkkw/edit#gid=718958730">updated BoM</a> there.</p> <p>Though it is not called out directly in the BoM, a valuable piece of test equipment to have is a digital power supply like <a href="https://www.amazon.com/Siglent-Technologies-SPD3303X-Triple-Output/dp/B01410O424/ref=sr_1_3_pp?crid=1784OTMM5TCAP&amp;keywords=siglent+power+supply&amp;qid=1702946599&amp;sprefix=siglent+%2Caps%2C156&amp;sr=8-3">this one</a>. Although it can’t be used to power the VESC when it is driving the motors (more on this in the <a href="#setting-up-the-vesc">VESC</a> section below), it can be used while setting up the rest of the physical setup, including the Jetson computer.</p> <p>The primary reason it took me so long to put this kit together is the all-in price tag: <em>about $3k</em>. This is pretty steep for a hobbyist like me, but I finally was able to pull everything together earlier this year.</p> <h2 id="traxxas-modifications">Traxxas modifications</h2> <p>The steps <a href="https://f1tenth.org/build.html">here</a> were performed with no modifications required. As I mentioned previously, I had some issues with the platform deck material having insufficient integrity to be properly installed.</p> <p>I added the foam front fender from the <a href="https://racecarj.com/collections/mit-racecar-build-series/products/racecar-j-robot-base-kit">RACECAR/J kit</a> to lessen the impact of any collisions.</p> <h2 id="building-the-power-distribution-module-pdm">Building the Power Distribution Module (PDM)</h2> <p>The PDM takes in a variable voltage and outputs regulated voltage on 12 and 8V output buses. The 12V output is primarily to power the Jetson NX companion computer. The 8V output is for powering the Hokuyo lidar sensor.</p> <p>I am not an electrical engineer nor am I an electronics technician. It has been several years since I have had to solder anything, so I had to proceed more carefully through this step.</p> <h3 id="soldering-the-pdm">Soldering the PDM</h3> <p>The first consideration in soldering was <a href="https://oshpark.com/shared_projects/qvIKu3aY">ordering</a> the printed circuit board (PCB) to add the electronic components to. The vendor (Oshpark) requires a minimum of three PCBs per order for fabrication, so I decided to build three full PDM assemblies. This would provide adequate backup should I blow up any of them along the way.</p> <p>I remembered from my introductory electronics lab in college that certain electronic components, like diodes, have polarity; that is, there are preferred mounting orientations of components relative to current flow through a circuit. I did not recall that capacitors had polarity, so it was a good thing I found <a href="https://www.yamanelectronics.com/capacitor-anode-cathode-identification/">this diagram</a>:</p> <p><img src="/assets/img/capacitor-polarity.jpg" alt="test-image"/></p> <p>Some capacitors do have polarity - there is an anode (+) and a cathode (-) and you need to make sure to install these components correctly. Polarized capacitors are noted in schematics differently than non-polarized ones; see picture above.</p> <p>Specific to the printed PDM PCB: <em>the anode has a longer lead than the cathode and should be installed in the hole nearest the printed component id</em>. Below is a picture of the assembled PDM showing the correct orientations of the polarized electrolytic capacitors.</p> <p><img src="/assets/img/pdm-closeup.jpg" alt="pdm-closeup"/></p> <p>The only word of advice I can give would-be builders here is this: <em>get a really fine tip for your soldering iron</em>. Some of the work is rather delicate. You will want some means (like <a href="https://www.amazon.com/Soldering-Flexible-Flashlight-Magnifying-Aluminum/dp/B085958VNK/ref=asc_df_B085958VNK/?tag=&amp;linkCode=df0&amp;hvadid=416720562944&amp;hvpos=&amp;hvnetw=g&amp;hvrand=54914317156848057&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9031172&amp;hvtargid=pla-909563369713&amp;mcid=60085f6ba32334598761ffc8385d6d82&amp;ref=&amp;adgrpid=95471657178&amp;gclid=CjwKCAiA-P-rBhBEEiwAQEXhH-rqM7q51hxpmGqH7QWW_CrC0ReTt-2zarHQYwnELQpLTs_ckqdYRxoCWXMQAvD_BwE&amp;th=1">this</a>) of keeping the board fixed without having to hold it with a free hand.</p> <h3 id="testing">Testing</h3> <p>Testing is actually pretty straightforward: get a <a href="https://www.adafruit.com/product/2034?gad_source=1&amp;gclid=CjwKCAiA-P-rBhBEEiwAQEXhH2qsnGjb8U37sZ3gdhta1t6iTGKZmXSWB3hyjtttOUlLtYb52cwPRhoCRtUQAvD_BwE">hand-held multimeter</a> and put some voltage (10-24V) across one of the output channels on your power supply. Toggle the on/off switch on each PDM and then check the voltage across each pair in your output bus to make sure the correct voltage - either 12 or 8V - is indicated.</p> <p float="left"> <img src="/assets/img/pdm-8V.jpg" width="320"/> <img src="/assets/img/pdm-12V.jpg" width="320"/> </p> <h2 id="setting-up-the-jetson">Setting up the Jetson</h2> <p>As indicated in the Master BoM spreadsheet, Nvidia no longer produces the Xavier NX developer kits. The recommended alternative is the Seeed Studio <a href="https://www.seeedstudio.com/reComputer-J2021-p-5438.html">reComputer J2021</a> system-on-module (SoM). This SoM doesn’t have a Wi-Fi card installed, so I had to buy one. Nvidia lags pretty far with respect to releases of their Linux kernel and, as such, the Jetson is limited in terms of what wireless cards it can support. I tried a few Intel cards, but only the <a href="https://www.amazon.com/Intel-Dual-Band-Wireless-Ac-8265/dp/B01MZA1AB2/ref=sr_1_3?crid=1YDDJON2VFI4G&amp;keywords=intel+8265&amp;qid=1702996569&amp;sprefix=intel+8265%2Caps%2C177&amp;sr=8-3">Intel 8265NGW</a> was recognized by the kernel.</p> <p>I also added an <a href="https://www.amazon.com/gp/product/B09DVQQL9G/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;th=1">M2 SSD</a> to add storage capacity to the device.</p> <h2 id="adding-a-camera">Adding a camera</h2> <p>The front fender addition from the RACECAR/J came with a mounting plate that can support a <a href="https://store.stereolabs.com/products/zed-2">ZED 2 stereo camera</a>. I had a ZED 2 from a prior project, so I added it using glue. The connection feels solid, but I have my concerns that it won’t survive racing conditions.</p> <h2 id="putting-it-all-together">Putting it all together</h2> <p>Here’s a picture of the finished build:</p> <p><img src="/assets/img/f1tenth-build.jpg" alt="f1tenth-build"/></p> <h2 id="whats-next">What’s next?</h2> <p>Now I need to get all of the electronic peripherals - the sensors, the motor controller, and the Jetson - setup properly. I’ll let you know how it goes.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Walkthrough of my build of the F1TENTH autonomous RC racecar.]]></summary></entry><entry><title type="html">So long, 2021</title><link href="https://jwdinius.github.io/blog/2021/goodbye-2021/" rel="alternate" type="text/html" title="So long, 2021"/><published>2021-12-30T07:30:00+00:00</published><updated>2021-12-30T07:30:00+00:00</updated><id>https://jwdinius.github.io/blog/2021/goodbye-2021</id><content type="html" xml:base="https://jwdinius.github.io/blog/2021/goodbye-2021/"><![CDATA[<p>Well, 2021 is nearly completed and I wanted to get a post in before that happened. While looking at my blog, I realized that the last <a href="https://jwdinius.github.io/blog/2021/max-clique/">post</a> was over 10 months ago, which is simply too long between posts. A lot happened this year, so I wanted to take the time to write about it as a stream-of-consciousness. Before diving into the numbers that made 2021 significant for me, I wanted to take a moment to a bit about my mental health and its impact on my physical health over the past year.</p> <p>I struggled for much of the year: I worked too much, I socialized too little, I ate poorly, and I got little exercise. These factors combined to put me in a poor state for much of the first half of the year. My physical health deteriorated: my Crohn’s disease became unmanaged, I became lethargic, and I periodically came to feel depressed about my physical condition. These factors led a to spiraling effect, one where negative emotions manifested as negative physical sensations which led to negative emotions. Around the middle of the summer, I got sick and tired of being sick and tired. I decided that I had had enough and that I needed to find a way to improve my situation.</p> <p>In the past, I have had little success in taking big shots with regards to my health. Therefore, I decided that I needed to start small. I needed to find something that would allow me to make incremental, measurable progress. The measurable bit is key; I needed quick checks to reinforce (or redirect) my efforts quickly to keep me motivated.</p> <p>It was a stroke of luck that, when my wife and I were looking at a bookstore in San Luis Obispo, CA, I came across the book <a href="https://www.amazon.com/Authentic-Happiness-Psychology-Potential-Fulfillment/dp/0743222989/ref=asc_df_0743222989/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=270645996404&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15315181597611501769&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9031178&amp;hvtargid=pla-434087462631&amp;psc=1"><em>Authentic Happiness</em></a> by Martin Seligmann. This book opened my eyes to the field of Positive Psychology, which helped me to realize that how I responded to setbacks (incl. physical and mental health issues) could be modified so as to lessen, and in some cases remove, the negative emotional and physical consequences of those setbacks. The insights I gained from this book helped me to realize the power of the mind in overcoming obstacles. Fast-forward 5 months: I am seeing a psychologist regularly to build upon the skills presented in the book and I have seen <em>significant</em> improvement in my emotional, mental, and physical health.</p> <p>I will close out this introduction with what I hope will be an inspiring statement: <em>If you are suffering with mental, emotional, and/or physical health issues, I honestly believe that there is a way for you to resolve them.</em> After years of struggling, watching my health deteriorate, I have found strategies to improve my outlook on life. These strategies did not require a huge shift in perspective. Rather, I have made multiple small course corrections and was able to modify along the way towards improvement.</p> <p>Now, onto my 2021 retrospective:</p> <h1 id="2021-from-greatest-to-least-numerically-speaking">2021, from greatest to least (numerically speaking)</h1> <h2 id="30-books-read"><a href="https://www.goodreads.com/user_challenges/26171485">30 books read</a></h2> <p>The link above will take you to my 2021 challenge on <em>goodreads</em>. Here are some highlights:</p> <h3 id="most-inspiring---learned-optimism-how-to-change-your-mind-and-your-life-by-martin-seligmann">Most inspiring - <a href="https://www.amazon.com/Learned-Optimism-Change-Your-Mind/dp/1400078393/ref=asc_df_1400078393/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312154644197&amp;hvpos=&amp;hvnetw=g&amp;hvrand=7170066860797823307&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9031178&amp;hvtargid=pla-404766126159&amp;psc=1"><em>Learned Optimism: How to Change Your Mind and Your Life</em></a>, by Martin Seligmann</h3> <p>Though I previously called out <em>Authentic Happiness</em> by the same author, I found the strategies discussed in <em>Learned Optimism</em> had more evidentiary basis and were, in general, more straightforward to adopt in everyday scenarios. I really liked the fact that this is book you can work through: there were frequent “tests” you could take, and how to evaluate your results was made explicitly clear. For example, through my test scores regarding negative and positive events and my responses to them, I realized I have a very pessimistic explanatory style. The book helped me to recognize this, and also to identify how I can shift my perspective to not see setbacks so negatively.</p> <h3 id="favorite-fiction---xenogenesis-trilogy-by-octavia-e-butler">Favorite fiction - <a href="https://www.amazon.com/Liliths-Brood-Complete-Xenogenesis-Trilogy-ebook/dp/B008HALOMI/ref=sr_1_1?keywords=xenogenesis+trilogy+octavia+butler&amp;qid=1641052722&amp;s=books&amp;sprefix=xenogenesis%2Cstripbooks%2C125&amp;sr=1-1"><em>Xenogenesis trilogy</em></a>, by Octavia E. Butler</h3> <p>These books were spectacularly imaginative. I love Octavia E. Butler’s perspective on Sci-Fi; the themes of reproductive rights and sexual violence demonstrated throughout the post-fallout interactions of human society with extraterrestrial creatures were so fun to explore. The extraterrestrial civilization, the <em>Oankali</em>, were so interesting. Their ships were living sentient beings!</p> <h3 id="favorite-nonfiction-non-technical---the-man-who-solved-the-market-how-jim-simons-launched-the-quant-revolution-by-gregory-zuckerman">Favorite nonfiction (non-technical) - <a href="https://www.amazon.com/Man-Who-Solved-Market-Revolution/dp/073521798X/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=1641052983&amp;sr=1-1"><em>The Man Who Solved the Market: How Jim Simons Launched the Quant Revolution</em></a>, by Gregory Zuckerman</h3> <p>Jim Simons is such an interesting figure in American finance. He was an academic mathematician who saw opportunity and order where others see chaotic fluctuations. This book expounds on his and his collaborators’ journey to build the most successful hedge fund ever, the <a href="https://en.wikipedia.org/wiki/Renaissance_Technologies#Medallion_Fund">Medallion Fund</a>. I also appreciate that the Medallion Fund is run for the benefit of employees of Renaissance Technologies (the firm that manages the Medallion Fund). Dr. Simons has left an incredible legacy, all while flying under-the-radar for much of his professional life. This is probably due mostly to his shying away from the spotlight. One glaring hole in this book is the lack of participation by its subject; Jim Simons does not give public interviews, even for this book apparently.</p> <h3 id="favorite-technical---visual-differential-geometry-and-forms-a-mathematical-drama-in-five-acts-by-tristan-needham">Favorite technical - <a href="https://www.amazon.com/Visual-Differential-Geometry-Forms-Mathematical/dp/0691203709/ref=sr_1_1?keywords=visual+differential+geometry+and+forms&amp;qid=1641054085&amp;s=books&amp;sprefix=visual%2Cstripbooks%2C131&amp;sr=1-1"><em>Visual Differential Geometry and Forms: A Mathematical Drama in Five Acts</em></a>, by Tristan Needham</h3> <p>I can’t say enough about this book. I <em>loved</em> it. I’m counting it as a complete read, though I’ve yet to tackle the fifth “act”. The first four acts of the book are self-contained. I was able to gain significant insights about the fundamental concepts of differential geometry: <em>metrics</em>, <em>curvature</em>, and <em>parallelism</em>. I struggled with the concepts of differential geometry in all other settings. In graduate school, I failed to grasp the fundamental concepts through all of the terminology and formality of the material being presented. Dr. Needham’s book is the first time I have every really understood the material through the historical progression of its application to relevant problems in physics. This is not a mathematically rigorous book; many of the proofs are “hand-wavy”, at best. This lack of rigor is part of what I find so excellent about the book as it makes the material more accessible to a broader audience. I feel like I know have the requisite background to take a deeper dive into the more mathematically precise material or, more likely, more physics-focused presentations of the material (like Schutz’s <a href="https://www.amazon.com/Geometrical-Methods-Mathematical-Physics-Bernard/dp/0521298873/ref=sr_1_1?keywords=geometric+methods+of+mathematical+physics&amp;qid=1641053933&amp;sprefix=geometric+methods+of+%2Caps%2C124&amp;sr=8-1"><em>Geometrical Methods of Mathematical Physics</em></a>).</p> <h2 id="10-years-of-marriage">10 years of marriage</h2> <p>My wife, Jessica, and I celebrated 10 years of marriage this past June/July. Our marriage story is somewhat unique in that we have two anniversaries: we were legally married in Pima County Superior Court on June 24, 2011 in a small, family-only ceremony while the one we actually celebrate is one week later (July 2nd) when we were informally wed on the beach in Los Cabos, Mexico whilst among our family and friends. We made a trip up the coast to Arroyo Grande in this <a href="https://www.airbnb.com/rooms/11459246?source_impression_id=p3_1641054433_kq%2BkSX0Oc5NFqvrg">absolutely beautiful suite</a> adjoining the owner’s own home. Arroyo Grande is such an idyllic place for us. It is close to beaches (Morro Bay and Pismo Beach), there is a college town nearby (San Luis Obispo), and there are lots of interesting and fun things to do. We tried goat yoga for the first time, and it was an interesting experience.</p> <p>Despite all the negative physical stuff I was going through at the time, I’m really glad that we ended up going. This trip provided the time and space for us to get out and celebrate what is, in my mind, a very remarkable milestone in our relationship. I love my wife very much and look forward to every day we get to spend together, whether it is a milestone or not.</p> <h2 id="5-completed-coursera-courses">5 completed Coursera courses</h2> <p>Coming from a mathematical background, as opposed to a more traditional computer science background, has put me at a disadvantage in some software engineering concepts. This year, I decided to gain more familiarity with the basics of algorithm design and data structures for computer programming by taking 5 (out of the 6) courses in the <a href="https://www.coursera.org/specializations/data-structures-algorithms">Data Structures and Algorithms Specialization</a> on Coursera. The quality of the material relative to the cost of completion is considerably higher than other alternatives that I evaluated (e.g. similar courses on Udemy). There was a nice balance of theory and practice, and I particularly liked that a lot of consideration for corner-cases was made. My favority course in the sequence was <a href="https://www.coursera.org/learn/algorithms-on-graphs?specialization=data-structures-algorithms"><em>Algorithms on Graphs</em></a>. As a roboticist, these algorithms dealt most closely with planning problems that I encounter frequently. I opted not to take the capstone course to complete the full specialization, as the material based on genetics was not particularly compelling for me.</p> <h2 id="3-covid-shots">3 COVID shots</h2> <p>What would a retrospective on 2021 be without a mention of the COVID shots? I received my first dose around the end of April, which was right around when shots were made available for adults in California. With the rise of the Omicron variant of the virus and the fact that we planned to visit family over the holidays, I opted to get the Moderna booster (having previously gotten two doses of the Pfizer vaccine) in early December. Fun sidenote: I had a shingles breakout after getting my COVID booster. I had not previously ever had a shingles episode, so I didn’t know what it was until I went to the Minute Clinic and got a diagnosis. After my experience with shingles, I will be telling everyone I know to get the shingles vaccine. Shingles, at least in my case, was quite painful and took a few weeks to clear up. If you are able to, I highly recommend getting the vaccine.</p> <p>One final note on the COVID vaccine: I had to say goodbye to a few coworkers that were unable to comply with my company’s vaccine mandate for employees. While I was quite sad at this, I understand why my company had to draw such a hard line. In no small sense, I admire the conviction it takes in one’s own values to sacrifice your job and livelihood when policies are put in place that are not reflective of those values. I hope that these former colleagues find new opportunities consistent with their beliefs and values in 2022.</p> <h1 id="1-new-house">1 new house</h1> <p>The real estate market in southern California is non-sensical during the best of times; 2021 was an unmitigated feeding frenzy! In our area, <a href="https://www.redfin.com/city/19798/CA/Thousand-Oaks/housing-market">home prices climbed almost 14%</a> over the past year! Despite concerns about limited availability and soaring prices, we decided to take the plunge and purchase a home (our third such purchase since 2009). There were several factors that impacted our decision, but the major ones were:</p> <ul> <li>Interest rates would likely go up (from historic lows around 3%)</li> <li>Home prices would likely continue to rise, even if at lower rates than they are currently going up</li> <li>Paying rent is paying someone else’s mortgage - <em>In the 4 years we have rented our current place, we have paid close to $150K in rent!!!</em></li> </ul> <p>We were starting to get discouraged after about a month of searching when we came across a <a href="https://www.zillow.com/homedetails/2959-Dogwood-Cir-Thousand-Oaks-CA-91360/16479186_zpid/">lovely townhome in Thousand Oaks</a>. We put in a solid offer (about 4% above asking) and it was accepted above the nine other offers considered. Buying a home in southern California has been an experience, but it has taught me that there are some serious real estate professionals here, and we were lucky enough to work with them during our home buying experience. We are set to close escrow in January 3, 2022, however I wanted to highlight this good news in my 2021 recap.</p> <h2 id="-4-net-headcount-on-my-team">-4 net headcount on my team</h2> <p>All of the numbers mentioned above were, quite literally, positive. I’d be remiss if I didn’t mention that there were some negative numbers that came out of 2021. I’ll focus this final section on one such measure: <em>the headcount of the team of engineers that I manage</em>.</p> <p>I had worked diligently with my boss to rebrand/reorganize my department around core robotics competencies; namely, perception, planning, and control. I felt like we made some very purposeful strategic moves to find better functional departments for some of our staff, while also moving some staff into the department. Such moves can be challenging in companies such as mine, where organizational inertia makes any forward motion significantly taxing. I feel that we did really well, though. At the beginning of the year, I was managing about 15 full-time engineers and 1 technician, which was far too many. By May, through strategic moves we got the team to a svelte 9 total heads; all of whom were robotics specialists. My rosy outlook on the future of the group was short lived.</p> <p>Calendar year 2021 presented many significant challenges to keeping staff, particularly high performers. Some of these challenges included:</p> <ul> <li>External challenges <ul> <li>White-hot labor market</li> <li>Employers offering greater flexibility and remote work</li> <li>Employers paying higher salaries</li> </ul> </li> <li>Internal challenges <ul> <li>Slow strategy rollout for new projects</li> <li>Poor alignment between functional areas following acquisitions</li> </ul> </li> </ul> <p>These (and other) external challenges led to a rather large exodus from the group. Everyone has to take ownership over their own career, and I make that clear to everyone on my team. I even go so far as providing flex-time to the group to pursue personal projects to develop their skills in their particular areas-of-interest. This whole experience has led me on a search to answer the following questions:</p> <ul> <li><em>How do I identify flight risks?</em></li> <li><em>How do I provide the space for employees to pursue personal growth objectives?</em></li> <li><em>How do I keep employees engaged and invigorated with the department’s mission?</em></li> </ul> <p>These questions will drive my growth plan for team leadership in 2022. Perhaps I’ll even write a blog post (or several) on what I find out along these lines.</p> <h1 id="quick-wrap-up">Quick wrap-up</h1> <p>This year was strange and, in some ways, really wonderful, as all years tend to be. We are nearing the end of our second year in lockdown and I sincerely hope that 2022 will see us edge our way out of these restrictive measures (but only when it is demonstrably safe to do so). I’m going to make it my goal to write at least one post per month in the coming year. I have lots of ideas of things I’d like to do and I’m looking forward to writing about my journey along the way.</p> <p>Thanks for reading, and Happy New Year!!!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Yep, you happened, but let's not make a big deal about it]]></summary></entry><entry><title type="html">Finding Point Cloud Correspondences Using Undirected Graphs</title><link href="https://jwdinius.github.io/blog/2021/max-clique/" rel="alternate" type="text/html" title="Finding Point Cloud Correspondences Using Undirected Graphs"/><published>2021-02-20T07:30:00+00:00</published><updated>2021-02-20T07:30:00+00:00</updated><id>https://jwdinius.github.io/blog/2021/max-clique</id><content type="html" xml:base="https://jwdinius.github.io/blog/2021/max-clique/"><![CDATA[<p>In this post, I will discuss an alternate approach to the <a href="http://jwdinius.github.io/blog/2019/point-match/">point cloud correspondences problem</a> using graph-based methods. This post is meant to be interactive and those who wish to run the code for yourselves, check out the <a href="https://github.com/jwdinius/practical-maximum-clique-repro/blob/master/MaximumClique.ipynb">jupyter notebook</a> from which this post was derived.</p> <p>Let’s start with some dependencies:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="n">time</span>
</code></pre></div></div> <p>I want to create a set of points randomly sampled from a square. These points will be used as the basis for subsequent demos. First, let’s set the random seed for repeatability of experiments.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">11011</span><span class="p">)</span>
</code></pre></div></div> <p>To setup the data for the experiments, we will define values for the following parameters:</p> <ul> <li><code class="language-plaintext highlighter-rouge">m</code> is number of points in source cloud</li> <li><code class="language-plaintext highlighter-rouge">n</code> is number of points in target cloud</li> <li><code class="language-plaintext highlighter-rouge">noise_val</code> is the 1-sigma value for applying noise (per channel $x,y$)</li> <li><code class="language-plaintext highlighter-rouge">ang</code> is the rotation angle (ccw is positive) to apply</li> <li><code class="language-plaintext highlighter-rouge">xt</code> is the $x$ translation to apply</li> <li><code class="language-plaintext highlighter-rouge">yt</code> is the $y$ translation to apply</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">25</span>
<span class="n">noise_val</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">ang</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mf">4.</span>
<span class="n">xt</span><span class="p">,</span> <span class="n">yt</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">15.0</span>
<span class="n">side_length</span> <span class="o">=</span> <span class="mi">20</span>
</code></pre></div></div> <p>Let’s sample some points and apply a transformation to get two point sets for comparison:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># uniformly sample on square with dimensions side_length x side_length
# use homogeneous coordinates
</span><span class="n">target_pts</span> <span class="o">=</span> <span class="n">side_length</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">side_length</span>
<span class="n">target_pts</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">target_pts</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="c1"># transform
</span><span class="n">ca</span><span class="p">,</span> <span class="n">sa</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">ang</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">ang</span><span class="p">)</span>
<span class="n">tgt_to_src</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="n">ca</span><span class="p">,</span> <span class="n">sa</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">xt</span><span class="p">],</span>
                       <span class="p">[</span><span class="o">-</span><span class="n">sa</span><span class="p">,</span> <span class="n">ca</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">yt</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="n">target_pts_xform</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">tgt_to_src</span><span class="p">,</span> <span class="n">target_pts</span><span class="p">)</span>
<span class="n">correspondences</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># subsample and reorder target points
</span><span class="n">source_pts</span> <span class="o">=</span> <span class="n">target_pts_xform</span><span class="p">[:,</span> <span class="n">correspondences</span><span class="p">]</span> <span class="o">+</span> <span class="n">noise_val</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">source_pts</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">source_pts</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.</span>
</code></pre></div></div> <p>Recall: A <em>correspondence</em> is encoded by two points: one from the source point cloud and the other from the target point cloud. Such correspondences can be encoded as vertices in an undirected graph enumerated as $i’ \equiv i n + j$, with source point $i$ and corresponding target point $j$. For more details, check out the following <a href="https://arxiv.org/abs/1902.01534">paper</a>. For comparison of methods below, let’s start by identifying the true correspondences between the source and target point sets and plot the data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">correspondenceVertices</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># for comparison below
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">correspondences</span><span class="p">):</span>
    <span class="n">correspondenceVertices</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Correspondence vertices list is {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">correspondenceVertices</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Correspondence vertices list is [23, 41, 72, 88, 105, 137, 165, 189, 219, 234, 267, 283, 301, 328, 374]
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">target_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="sh">'</span><span class="s">r.</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Original Alignment</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">target_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">target</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">source_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="sh">'</span><span class="s">r.</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">source</span><span class="sh">"</span><span class="p">)</span>
<span class="n">legend_made</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">correspondences</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">legend_made</span><span class="p">:</span>
        <span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]],</span> <span class="p">[</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]],</span> <span class="sh">'</span><span class="s">b--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">correspondence</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">legend_made</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]],</span> <span class="p">[</span><span class="n">target_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">source_pts</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]],</span> <span class="sh">'</span><span class="s">b--</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">True Correspondences</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="/assets/img/output_9_0.png" alt="expected-output"/></p> <p>You’re probably asking at this point: <em>How do we go about actually finding the true correspondences?</em> We need the notion of <em>pairwise consistency</em>:</p> <p>Two correspondences are pairwise consistent <em>iff</em>:</p> <ul> <li>The source points from each correspondence are a minimum of <code class="language-plaintext highlighter-rouge">pairwiseThreshold</code> distance apart; call this distance <code class="language-plaintext highlighter-rouge">d1</code></li> <li>The target points from each correspondence are a minimum of <code class="language-plaintext highlighter-rouge">pairwiseThreshold</code> distance apart; call this distance <code class="language-plaintext highlighter-rouge">d2</code></li> <li>The absolute value of the difference between <code class="language-plaintext highlighter-rouge">d1</code> and <code class="language-plaintext highlighter-rouge">d2</code> is <em>at maximum</em> <code class="language-plaintext highlighter-rouge">epsilon</code> distance apart.</li> </ul> <p>for some <code class="language-plaintext highlighter-rouge">epsilon</code>, <code class="language-plaintext highlighter-rouge">d1</code>, and <code class="language-plaintext highlighter-rouge">d2</code> greater than 0. This provides a significant restriction/constraint for our problem, as it allows us to discard unreasonable correspondence edges based on a simple consistency check based on distance.</p> <p>We can create a pairwise-consistency check as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">isPairwiseConsistent</span><span class="p">(</span><span class="n">ci</span><span class="p">,</span> <span class="n">cj</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">pwThresh</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="c1"># ci - i*n + i', i \in source, i' \in target
</span>    <span class="c1"># cj - j*n + j', j \in source, j' \in target
</span>    <span class="c1"># ci.x is 3x1 numpy array
</span>    <span class="c1"># ci.y is 3x1 numpy array
</span>    <span class="c1"># cj.x is 3x1 numpy array
</span>    <span class="c1"># cj.y is 3x1 numpy array
</span>    <span class="n">d1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">cj</span><span class="p">[</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">])</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">cj</span><span class="p">[</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">])</span>
    <span class="n">d3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">d1</span> <span class="o">-</span> <span class="n">d2</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">d1</span> <span class="o">&gt;=</span> <span class="n">pwThresh</span> \
        <span class="ow">and</span> <span class="n">d2</span> <span class="o">&gt;=</span> <span class="n">pwThresh</span> \
        <span class="ow">and</span> <span class="n">d3</span> <span class="o">&lt;=</span> <span class="n">epsilon</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">isPairwiseConsistent</code> returns true when two correspondences, <code class="language-plaintext highlighter-rouge">ci</code> and <code class="language-plaintext highlighter-rouge">cj</code>, are pairwise consistent. <em><code class="language-plaintext highlighter-rouge">isPairwiseConsistent</code> returning True means that we need to create and edge between the two input correspondence vertices.</em> The graph structure should now be becoming clear in your mind: <em>possible correspondences are encoded as vertices of an undirected graph with edges between correspondences determined by the pairwise consistency check.</em> To find the best possible set of correspondences, we can compute the <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/2003-04/dna-computing/clique.htm"><em>maximum clique</em></a> of the graph, which represents the subgraph of largest size where all correspondence vertices are pairwise consistent with each other (i.e. have edges connecting each correspondence to every other correspondence in the subgraph).</p> <p>Before getting to a couple of approaches for computing the maximum clique, I’ll define a few helper functions for comparison of algorithm output to ground truth</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cliquesAreEquivalent</span><span class="p">(</span><span class="n">cliqueOne</span><span class="p">,</span> <span class="n">cliqueTwo</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cliqueOne</span><span class="p">.</span><span class="nf">sort</span><span class="p">()</span> <span class="o">==</span> <span class="n">cliqueTwo</span><span class="p">.</span><span class="nf">sort</span><span class="p">()</span>
</code></pre></div></div> <p>User-defined constants:</p> <ul> <li><code class="language-plaintext highlighter-rouge">epsilon</code> above $\to$ <code class="language-plaintext highlighter-rouge">eps</code></li> <li><code class="language-plaintext highlighter-rouge">pairwiseThreshold</code> above $\to$ <code class="language-plaintext highlighter-rouge">pwThr</code></li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">pwThr</span> <span class="o">=</span> <span class="mf">1e-1</span>
</code></pre></div></div> <p>Construct vertices and edges for maximum clique calculation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">E</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">V</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">k</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">l</span><span class="p">:</span>
                    <span class="n">ci</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">j</span><span class="p">]}</span>
                    <span class="n">cj</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">l</span><span class="p">]}</span>
                    <span class="n">consis</span> <span class="o">=</span> <span class="nf">isPairwiseConsistent</span><span class="p">(</span><span class="n">ci</span><span class="p">,</span> <span class="n">cj</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="n">eps</span><span class="p">,</span> <span class="n">pwThresh</span> <span class="o">=</span> <span class="n">pwThr</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">consis</span><span class="p">:</span>
                        <span class="n">V1</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">j</span>
                        <span class="n">V2</span> <span class="o">=</span> <span class="n">k</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">l</span>
                        <span class="n">E</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">V1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">V2</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V2</span><span class="p">)</span>
</code></pre></div></div> <p>Python has a useful library for graph processing called <code class="language-plaintext highlighter-rouge">networkx</code>. As a baseline, let’s setup a workflow using <code class="language-plaintext highlighter-rouge">networkx</code> to compute the maximum clique.</p> <h2 id="maximum-clique-identification-using-networkx">Maximum Clique Identification using <code class="language-plaintext highlighter-rouge">networkx</code></h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">E</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cliques</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="nf">find_cliques_recursive</span><span class="p">(</span><span class="n">G</span><span class="p">))</span>
<span class="c1">#plt.figure()
#nx.draw(G, with_labels=True)
</span><span class="n">maxClique</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">maxCliqueSize</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tBegin</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cliques</span><span class="p">:</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">maxCliqueSize</span><span class="p">:</span>
        <span class="n">maxClique</span> <span class="o">=</span> <span class="n">c</span>
        <span class="n">maxCliqueSize</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="n">timeElapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tBegin</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max clique was found in {}sec</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">timeElapsed</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max clique has size {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">maxCliqueSize</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max clique is {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">maxClique</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max clique was found in 0.000392913818359375sec
Max clique has size 15
Max clique is [105, 234, 165, 72, 328, 41, 137, 267, 301, 219, 374, 88, 283, 189, 23]
</code></pre></div></div> <p>Check that <code class="language-plaintext highlighter-rouge">maxClique</code> is equivalent to the true correspondences.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Is the correspondence list equivalent to the max clique?  {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">cliquesAreEquivalent</span><span class="p">(</span><span class="n">correspondenceVertices</span><span class="p">,</span> <span class="n">maxClique</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Is the correspondence list equivalent to the max clique?  True
</code></pre></div></div> <p>The approach above shows that the max clique of the graph does, indeed, identify the true correspondences. The approach above is useful if you are developing under a native Python environment. Unfortunately, no equivalent library for C++ is available. We can use branch-and-bound based algorithms for computing the max cliques in a purely algorithmic way; such approaches can be implemented easily in other languages.</p> <h2 id="practical-maximum-clique-algorithms">Practical Maximum Clique Algorithms</h2> <p>The first two max clique algorithms from <a href="https://arxiv.org/abs/1902.01534">here</a> are implemented below. First, let’s define a few routines for computing needed quantities</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">adjacency</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">vertex</span><span class="p">):</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">vertex</span> <span class="ow">in</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">adj</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">vertex</span> <span class="o">!=</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">else</span> <span class="n">adj</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">adj</span>
</code></pre></div></div> <p>As a quick check, reproduce the simple example from the paper:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># unit test for adjacency using graph from paper (Figure 2)
</span><span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">E</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">v: {}, adj(V): {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nf">adjacency</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="n">v</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>v: 1, adj(V): [2, 5, 6]
v: 2, adj(V): [1, 3, 4, 5]
v: 3, adj(V): [2, 4, 5]
v: 4, adj(V): [2, 3, 5]
v: 5, adj(V): [1, 2, 3, 4, 6]
v: 6, adj(V): [1, 5]
</code></pre></div></div> <h3 id="basic-bnb-algorithm-1">Basic BnB (Algorithm 1)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mcBasicBnB</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span>
    <span class="sh">"""</span><span class="s">
    Algorithm 1 from paper </span><span class="sh">"</span><span class="s">A Practical Maximal Clique for Matching with Pairwise Constraints</span><span class="sh">"</span><span class="s"> by
    Bustos et.al
    
    args:
    S - candidate vertices for expansion
    edges - edges of (undirected) graph
    </span><span class="sh">"""</span>
    <span class="k">while</span> <span class="n">S</span><span class="p">:</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="nf">len</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nf">len</span><span class="p">(</span><span class="n">Rbest</span><span class="p">):</span>
            <span class="k">return</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">R</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">Sprime</span> <span class="o">=</span> <span class="p">[</span><span class="n">vert</span> <span class="k">for</span> <span class="n">vert</span> <span class="ow">in</span> <span class="n">S</span> <span class="k">if</span> <span class="n">vert</span> <span class="ow">in</span> <span class="nf">adjacency</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">v</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">Sprime</span><span class="p">:</span>
            <span class="nf">mcBasicBnB</span><span class="p">(</span><span class="n">Sprime</span><span class="p">,</span> <span class="n">edges</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">Rbest</span><span class="p">):</span>
            <span class="n">Rbest</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
        <span class="n">R</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">S</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">E</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>
<span class="nf">mcBasicBnB</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Rbest is: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">Rbest</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Rbest is: [2, 3, 4, 5]
</code></pre></div></div> <p>Which matches the article’s result.</p> <p>Quick check: <em>Does</em> <code class="language-plaintext highlighter-rouge">mcqBasicBnB</code> <em>find the correspondences like the previous method tried (i.e. the one using</em> <code class="language-plaintext highlighter-rouge">networkx</code> <em>)?</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">E</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">V</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">k</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">l</span><span class="p">:</span>
                    <span class="n">ci</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">j</span><span class="p">]}</span>
                    <span class="n">cj</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">l</span><span class="p">]}</span>
                    <span class="n">consis</span> <span class="o">=</span> <span class="nf">isPairwiseConsistent</span><span class="p">(</span><span class="n">ci</span><span class="p">,</span> <span class="n">cj</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="n">eps</span><span class="p">,</span> <span class="n">pwThresh</span> <span class="o">=</span> <span class="n">pwThr</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">consis</span><span class="p">:</span>
                        <span class="n">V1</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">j</span>
                        <span class="n">V2</span> <span class="o">=</span> <span class="n">k</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">l</span>
                        <span class="n">E</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">V1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">V2</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V2</span><span class="p">)</span>
<span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">tBegin</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="nf">mcBasicBnB</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span>
<span class="n">timeElapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tBegin</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max clique was found in {}sec</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">timeElapsed</span><span class="p">))</span>
<span class="n">maxCliqueBasicBnB</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">Rbest</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Is the correspondence list equivalent to the mcBasicBnB maximum clique?  {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">cliquesAreEquivalent</span><span class="p">(</span><span class="n">correspondenceVertices</span><span class="p">,</span> <span class="n">maxCliqueBasicBnB</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max clique was found in 4.391311883926392sec
Is the correspondence list equivalent to the mcBasicBnB maximum clique?  True
</code></pre></div></div> <p>Cool. <code class="language-plaintext highlighter-rouge">maxCliqueBasicBnB</code> works but is pretty slow (though it is faster than the <a href="https://jwdinius.github.io/blog/2020/point-match-cont/">quadratic assignment approach</a>. Let’s try Algorithm 2.</p> <h3 id="mcq-algorithm-2">MCQ (Algorithm 2)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">first_available</span><span class="p">(</span><span class="n">colors</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Return smallest integer not in the given list of colors.</span><span class="sh">"""</span>
    <span class="n">count</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>       <span class="c1"># Allocate long-enough array of zeros
</span>    <span class="k">for</span> <span class="n">color</span> <span class="ow">in</span> <span class="n">colors</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">color</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
            <span class="n">count</span><span class="p">[</span><span class="n">color</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">color</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">count</span><span class="p">[</span><span class="n">color</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">color</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">greedy_color</span><span class="p">(</span><span class="n">vertices</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Find the greedy coloring of graph defined by edges in the given vertices.
    </span><span class="sh">"""</span>
    <span class="n">color</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vertices</span><span class="p">:</span>
        <span class="n">color</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="nf">first_available</span><span class="p">([</span><span class="n">color</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nf">adjacency</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">color</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">color</span><span class="p">:</span>
        <span class="n">color</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># make sure to start coloring from 1
</span>    <span class="k">return</span> <span class="n">color</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mcMCQ</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span>
    <span class="sh">"""</span><span class="s">
    Algorithm 2 from paper </span><span class="sh">"</span><span class="s">A Practical Maximal Clique for Matching with Pairwise Constraints</span><span class="sh">"</span><span class="s"> by
    Bustos et.al
    
    args:
    S - candidate vertices for expansion
    edges - edges of (undirected) graph
    f - coloring of vertices for expansion (len(f) == len(S), by necessity)
    </span><span class="sh">"""</span>
    <span class="c1"># reorder vertices in S by adjacency
</span>    <span class="c1">#Ssrt = sorted(S, key=lambda x: len(adjacency(edges, x)), reverse=True)  # this does not work
</span>    <span class="n">Ssrt</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="nf">adjacency</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">x</span><span class="p">)),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># this works, want to expand about vertex of largest degree first
</span>    <span class="c1">#Ssrt = S  # this also works
</span>    <span class="k">while</span> <span class="n">Ssrt</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">Ssrt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="n">f</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="nf">len</span><span class="p">(</span><span class="n">Rbest</span><span class="p">):</span>
            <span class="k">return</span>
        <span class="n">R</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">Sprime</span> <span class="o">=</span> <span class="p">[</span><span class="n">vert</span> <span class="k">for</span> <span class="n">vert</span> <span class="ow">in</span> <span class="n">Ssrt</span> <span class="k">if</span> <span class="n">vert</span> <span class="ow">in</span> <span class="nf">adjacency</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">v</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">Sprime</span><span class="p">:</span>
            <span class="n">fprime</span> <span class="o">=</span> <span class="nf">greedy_color</span><span class="p">(</span><span class="n">Sprime</span><span class="p">,</span> <span class="n">edges</span><span class="p">)</span>
            <span class="nf">mcMCQ</span><span class="p">(</span><span class="n">Sprime</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">fprime</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">Rbest</span><span class="p">):</span>
            <span class="n">Rbest</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
        <span class="n">R</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">Ssrt</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">E</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>
<span class="n">f</span> <span class="o">=</span> <span class="nf">greedy_color</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span>
<span class="c1">#print(f)
</span><span class="nf">mcMCQ</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Rbest is: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">Rbest</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Rbest is: [5, 2, 4, 3]
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">E</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">V</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">source_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">target_pts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">k</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">l</span><span class="p">:</span>
                    <span class="n">ci</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">j</span><span class="p">]}</span>
                    <span class="n">cj</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">source_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">target_pts</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="n">l</span><span class="p">]}</span>
                    <span class="n">consis</span> <span class="o">=</span> <span class="nf">isPairwiseConsistent</span><span class="p">(</span><span class="n">ci</span><span class="p">,</span> <span class="n">cj</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="n">eps</span><span class="p">,</span> <span class="n">pwThresh</span> <span class="o">=</span> <span class="n">pwThr</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">consis</span><span class="p">:</span>
                        <span class="n">V1</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">j</span>
                        <span class="n">V2</span> <span class="o">=</span> <span class="n">k</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">l</span>
                        <span class="n">E</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">V1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">V2</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">V</span><span class="p">:</span>
                            <span class="n">V</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">V2</span><span class="p">)</span>
<span class="n">R</span><span class="p">,</span> <span class="n">Rbest</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">f</span> <span class="o">=</span> <span class="nf">greedy_color</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span>
<span class="n">tBegin</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="nf">mcMCQ</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="n">timeElapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tBegin</span>
<span class="n">maxCliqueMCQ</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">Rbest</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max clique was found in {}sec</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">timeElapsed</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Is the correspondence list equivalent to the mcMCQ maximum clique?  {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">cliquesAreEquivalent</span><span class="p">(</span><span class="n">correspondenceVertices</span><span class="p">,</span> <span class="n">maxCliqueBasicBnB</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max clique was found in 0.07146430015563965sec
Is the correspondence list equivalent to the mcMCQ maximum clique?  True
</code></pre></div></div> <p>This algorithm is significantly faster than the basic BnB with the same result. You should take care to analyze runtime performance for your particular <code class="language-plaintext highlighter-rouge">m</code>, <code class="language-plaintext highlighter-rouge">n</code>: <em>for smaller <code class="language-plaintext highlighter-rouge">m</code>, <code class="language-plaintext highlighter-rouge">n</code>, you should use the basic BnB</em>.</p> <h2 id="conclusion">Conclusion</h2> <p>The work described in this post was used as the basis for the <code class="language-plaintext highlighter-rouge">mc</code> algorithm in my project <a href="https://github.com/jwdinius/nmsac"><code class="language-plaintext highlighter-rouge">nmsac</code></a>. The graph-based methods provide a faster, simpler way of identifying point-to-point correspondences between two point clouds. I wanted to write up this post as a primer similar to the posts done for the <a href="https://jwdinius.github.io/blog/2020/point-match-sol/"><code class="language-plaintext highlighter-rouge">qap</code></a> algorithm, which solves the correspondence problem using optimization-based methods. This is the last post relating to <code class="language-plaintext highlighter-rouge">nmsac</code> before the final project write-up, which should be completed in the next few weeks.</p> <p><em>Thanks for reading!</em></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Using graph-based methods to identify correspondences between point clouds]]></summary></entry><entry><title type="html">Celebrity Lookalike Project Writeup</title><link href="https://jwdinius.github.io/blog/2020/lookalike/" rel="alternate" type="text/html" title="Celebrity Lookalike Project Writeup"/><published>2020-11-08T08:30:00+00:00</published><updated>2020-11-08T08:30:00+00:00</updated><id>https://jwdinius.github.io/blog/2020/lookalike</id><content type="html" xml:base="https://jwdinius.github.io/blog/2020/lookalike/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>I am currently enrolled in the OpenCV course “Computer Vision II: Applications (C++)”. For the second project, I had to create an application that would detect faces in a test image and then find the celebrities (from a provided dataset) whose faces <em>most closely</em> resemble those found in the test image. I put the phrase “most closely” in italics because I will discuss a few different approaches to finding the best match. To give a pictorial expression of the project’s objective, the course moderators provided the following expected output for two provided test images:</p> <p><img src="/assets/img/lookalike/Kazam_screenshot_00000.png" alt="expected-output"/></p> <p><em>Note: the celebrity lookalike found for the top test image is displayed as Selena, however the lookalike image actually displayed is Selena Gomez. In the provided dataset, there are folders for both Selena and Selena Gomez, who are in fact two different people, but all images in both folders are for Selena Gomez.</em></p> <p>In this blog post, I present a formal writeup of my solution addressing requirements of the project. Where appropriate, I will provide source code snippets highlighting important aspects of my approach.</p> <h1 id="writeup">Writeup</h1> <h2 id="objective">Objective</h2> <p>I will formally state the objective for the project here:</p> <blockquote> <p>Given a dataset of celebrity images, labeled by name, create a low-dimensional <a href="https://www.quora.com/What-is-descriptor-in-computer-vision#:~:text=In%20computer%20vision%2C%20visual%20descriptors,or%20the%20motion%2C%20among%20others.">descriptor</a> representing the likeness of the face detected in each image. Using this low-dimensional descriptor, compute a similarity score between faces detected in test images and the celebrities in the dataset. The celebrity with the highest similarity score is declared the “lookalike” or “doppelganger” to an individual detected in a test image.</p> </blockquote> <h2 id="dataset">Dataset</h2> <p>The course moderators provided a dataset, dubbed “celeb_mini”, that contains ~5 images per celebrity for 1000+ celebrities. There is significant variation in the dataset across the following factors:</p> <ul> <li>Illumination</li> <li>Face pose</li> <li>Foreground clutter - <em>some images have copyright data overlaid</em></li> <li>Sharpness/clarity of the image - <em>some images are quite blurry</em></li> </ul> <h2 id="solution">Solution</h2> <p>Because I am provided with a dataset for this activity, my solution has two phases: <em>training</em> and <em>testing</em>. During the training phase, I will find representative and informative descriptors for each image in the training set (i.e. the celeb_mini dataset). During the testing phase, I will apply the learned descriptor model (a function of the input image) to a test image and then find the most similar images in the training set with respect to the learned descriptor.</p> <p>The solution is constructed in C++, and the primary APIs used in my solution are:</p> <ul> <li><a href="https://opencv.org/opencv-4-1/">OpenCV</a> - used for basic image loading/saving and image processing</li> <li><a href="http://dlib.net">dlib</a> - used for linear algebra operations (length, linear systems solvers, and matrix processing), face detection, and for deep neural network inference</li> <li><a href="https://matplotlib-cpp.readthedocs.io/en/latest/index.html">matplotlibcpp</a> - for plotting data</li> </ul> <p>Before discussing each phase in greater detail, I will present my chosen descriptor model and justification.</p> <h3 id="descriptor">Descriptor</h3> <p>Considering the givens and assumptions for this project, I’d like a descriptor with the following qualities:</p> <ul> <li>Low dimensionality (makes comparison simpler and reduces redundancy across dataset)</li> <li>Descriptors for images with the same label (i.e. represent the same celebrity) are highly similar (close in some metric sense)</li> <li>Descriptors for images with different labels are highly dissimilar (far apart in some metric sense)</li> </ul> <p>In the course materials, a solution based on this <a href="http://dlib.net/dnn_metric_learning_on_images_ex.cpp.html">representative example</a> is presented that addresses all three points above using a deep learning-based approach. The solution uses a backbone architecture based on a <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a> pre-trained using <a href="https://towardsdatascience.com/metric-learning-loss-functions-5b67b3da99a5">metric loss</a> to create a 128-dimensional descriptor of each input image. To avoid unnecessary effort in retraining the backbone network, I first wanted to see the performance on the assigned task (i.e. finding the correct lookalike for each of the two test images discussed in the Introduction section of this page) using the pre-trained network.</p> <p>For the purpose of this project, this approach was found to be sufficient. In the Discussion section below, I will address deficiencies of using the pre-trained approach when considering use-cases outside of the defined boundaries for the project.</p> <h3 id="training">Training</h3> <p>This phase is not “training” in the typical sense, since a pre-trained network is used; rather it is more about generating descriptors for the images in the dataset using the pre-trained network. With this in mind, the training process is outlined as follows:</p> <ul> <li>Load training images</li> <li>Assign unique integral label to each subfolder in the dataset - <em>images in each subfolder represent the same celebrity</em></li> <li>Map each folder to celebrity name - <em>this will be used to assign celebrity name at the end of the testing process</em></li> <li>Load pre-trained model weights and biases for computing the descriptors</li> <li>for each image in the training image set <ul> <li>detect faces in image</li> <li>for each face in detected faces <ul> <li>detect facial landmarks</li> <li>use landmarks to crop facial region from image</li> <li>compute descriptor using cropped facial region</li> </ul> </li> </ul> </li> <li>write celebrity name-to-label map to csv file - <em>this will be used to match test image faces to celebrity likeness during the testing phase</em></li> <li>write descriptors, along with labels, to csv file for use during testing phase</li> </ul> <p>The codebase for this step was built using materials provided by the course moderators, so I am not willing to share it here.</p> <h3 id="testing">Testing</h3> <p>This phase’s primary concern is finding the celebrity that most closely resembles individuals detected in a test image. The process is outlined as follows:</p> <ul> <li>Load pre-trained model weights and biases (the same as in Training phase)</li> <li>Load csv file with celebrity name-to-label mapping</li> <li>Load csv file with descriptors and associated labels</li> <li>Load test image</li> <li>Detect faces in test image</li> <li>for each face in detected faces <ul> <li>detect facial landmarks</li> <li>use landmarks to crop facial region from image</li> <li>compute descriptor using cropped facial region</li> <li><em>find most similar celebrity using loaded descriptors</em></li> </ul> </li> </ul> <p>The steps in the loop defined above should look familiar: <em>they are the same as those used in the Training phase, with the addition of the matching step.</em> The majority of original work that I did for this project was concerned with the calculation of a similarity metric, so I will focus the discussion around these points.</p> <p>There are two metrics I used for computing similarity. The first is a simple, nearest-neighbor approach based on the <a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,occasionally%20called%20the%20Pythagorean%20distance.">Euclidean distance</a> between descriptor vectors. The second uses <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Mahalanobis distance</a>, which is a distance measure that is normalized by the covariance over samples from the training set with common label. I will now discuss these two approaches separately.</p> <h4 id="euclidean-distance">Euclidean distance</h4> <p>Euclidean distance is really easy to interpret: <em>if I look at the descriptor vectors as embeddings in a 128D vector space, then similar vectors are ones whose tails are close to one another in the normal linear sense</em>. In the context of the problem at-hand, the most similar celebrity to a person detected in a test image will have descriptor with shortest length to the descriptor representing the person detected in the test image.</p> <p>The code to identify the top matches using a Euclidean distance metric is:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * findKNearestNeighbors
 *
 * given an input descriptor and database of labeled descriptors, find the
 * top K best matches based using a Euclidean distance metric
 *
 */</span>
<span class="kt">bool</span> <span class="nf">findKNearestNeighbors</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptorQuery</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceLabels</span><span class="p">,</span> <span class="kt">int</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">k</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;&amp;</span> <span class="n">matches</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// loop over all descriptors and compute Euclidean distance with query descriptor</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">neighbors</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// compute distance between descriptors v1 and v2:</span>
    <span class="c1">// d(v1, v2) = std::sqrt((v1-v2)^T * (v1-v2));</span>
    <span class="c1">// - this is implemented in dlib with the `length` function</span>
    <span class="kt">double</span> <span class="n">distance</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">::</span><span class="n">length</span><span class="p">(</span><span class="n">faceDescriptorQuery</span> <span class="o">-</span> <span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="c1">// check if a distance for this label has already been determined</span>
    <span class="k">auto</span> <span class="n">it</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">find_if</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
          <span class="p">[</span><span class="o">&amp;</span><span class="p">](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">p</span><span class="p">.</span><span class="n">first</span> <span class="o">==</span> <span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="p">});</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">!=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
      <span class="c1">// if there has already been a distance found for this label, check if the current distance is less</span>
      <span class="c1">// than the one previously computed</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">distance</span> <span class="o">&lt;</span> <span class="n">it</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// if the current distance is less than the one previously recorded for the label, update it</span>
        <span class="n">it</span><span class="o">-&gt;</span><span class="n">second</span> <span class="o">=</span> <span class="n">distance</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// this is the first time encountering this label, so add the (label, distance) pair to neighbors</span>
      <span class="n">neighbors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">distance</span><span class="p">));</span>
    <span class="p">}</span>
  <span class="p">}</span>
  
  <span class="c1">// do the sort (closest to -&gt; furthest away)</span>
  <span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
      <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p1</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p2</span><span class="p">){</span> <span class="k">return</span> <span class="n">p1</span><span class="p">.</span><span class="n">second</span> <span class="o">&lt;</span> <span class="n">p2</span><span class="p">.</span><span class="n">second</span><span class="p">;</span> <span class="p">});</span>
    
  <span class="c1">// get k closest</span>
  <span class="n">matches</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">std</span><span class="o">::</span><span class="n">copy_n</span><span class="p">(</span><span class="n">neighbors</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">back_inserter</span><span class="p">(</span><span class="n">matches</span><span class="p">));</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>This code is quite simple. I loop over all of the descriptors in the database and evaluate the closest distance per-label for all descriptors. I then sort the output from this stage, with the closest matches first, and return a user-specified number of the best matches (see <code class="language-plaintext highlighter-rouge">k</code> in the function signature for <code class="language-plaintext highlighter-rouge">findKNearestNeighbors</code> above).</p> <h4 id="mahalanobis-distance">Mahalanobis distance</h4> <p>Because we have a few representative samples for each label, the Mahalanobis distance metric provides a way evaluating a statistically-relevant measure of closeness conditioned on the available data. The process for computing the Mahalanobis distance for a test image is as follows:</p> <ul> <li>Compute mean and variance of descriptor vectors over each label - <em>one time, during initialization</em></li> <li>Use mean and variance over label descriptor vectors to find the label with smallest Mahalanobis distance to the test image descriptor</li> </ul> <p><em>Note: the fundamental assumption of this approach is that the training images for each celebrity are sampled from a normal distribution. Whether or not this is a valid assumption across the entirety of the dataset was not evaluated as part of this project. I just wanted to try out this approach and see how it compares to the Euclidean distance approach.</em></p> <p>During initialization, the mean and variance of the set of descriptors for each label is computed using the code snippet below:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * computeStatsPerLabel
 *
 * given a set of labels and associated descriptors, FOR EACH LABEL i: compute the mean and covariance of descriptor vectors that have
 * label i
 */</span>
<span class="kt">bool</span> <span class="nf">computeStatsPerLabel</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceLabels</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;&amp;</span> <span class="n">meanLabeledDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;&amp;</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">faceDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// empty containers</span>
  <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>

  <span class="c1">// setup associative container for labeled descriptors and populate it</span>
  <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;&gt;</span> <span class="n">labeledDescriptors</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">faceLabels</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// if we haven't seen any descriptors for the present label, initialize</span>
    <span class="c1">// the vector for this label</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">labeledDescriptors</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="n">labeledDescriptors</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">labeledDescriptors</span><span class="p">[</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span> <span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">};</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// if we have already have descriptors for this label, append the current descriptor</span>
      <span class="n">labeledDescriptors</span><span class="p">[</span><span class="n">faceLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]].</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">faceDescriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// for each key-value pair in the labeledDescriptors container</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">pr</span> <span class="o">:</span> <span class="n">labeledDescriptors</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// compute mean and covariance</span>
    <span class="k">auto</span> <span class="o">&amp;</span><span class="n">descriptors</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">second</span><span class="p">;</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="n">mean</span><span class="p">;</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">covariance</span><span class="p">;</span>
    <span class="n">computeNormalParameters</span><span class="p">(</span><span class="n">descriptors</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">label</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">first</span><span class="p">;</span>
    <span class="c1">// add to output data containers</span>
    <span class="n">meanLabeledDescriptors</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">;</span>
    <span class="n">covarianceLabeledDescriptors</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">covariance</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// mark successful execution</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>with the relevant mean and variance computations being done by the <code class="language-plaintext highlighter-rouge">computeNormalParameters</code> function:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**!
 * computeNormalParameters
 *
 * given a set of input descriptor vectors, compute the mean and covariance of that set
 *
 */</span>
<span class="kt">void</span> <span class="nf">computeNormalParameters</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">vecs</span><span class="p">,</span>
    <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&amp;</span> <span class="n">covariance</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// if the input vector is empty, just exit</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">vecs</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Nothing to do"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// shorthand for vector size</span>
  <span class="k">auto</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">N</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>

  <span class="c1">// compute the mean = sum(v in vecs) / N</span>
  <span class="n">mean</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">nr</span><span class="p">());</span>
  <span class="n">dlib</span><span class="o">::</span><span class="n">set_all_elements</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">v</span> <span class="o">:</span> <span class="n">vecs</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">mean</span> <span class="o">+=</span> <span class="n">v</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">mean</span> <span class="o">/=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>

  <span class="c1">// compute the covariance = sum( (v-mean)*(v-mean)^T ) / N</span>
  <span class="n">covariance</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">nr</span><span class="p">(),</span> <span class="n">mean</span><span class="p">.</span><span class="n">nr</span><span class="p">());</span>
  <span class="n">dlib</span><span class="o">::</span><span class="n">set_all_elements</span><span class="p">(</span><span class="n">covariance</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">v</span> <span class="o">:</span> <span class="n">vecs</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">covariance</span> <span class="o">+=</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">dlib</span><span class="o">::</span><span class="n">trans</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">mean</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">covariance</span> <span class="o">/=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>With the mean and variance for each set of descriptors available, I can find the Mahalanobis distance between a test image’s descriptor and that set’s mean descriptor; see <code class="language-plaintext highlighter-rouge">findKMostLikely</code> below:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define REGULARIZATION 1e-8  // covariance += REGULARIZATION*Identity - this is necessary to stabilize the matrix decomposition used for the Mahalanobis distance calculation
</span><span class="cm">/**!
 * findKMostLikely
 *
 * given an input descriptor and mean and covariance for each label's descriptor vectors, find the
 * top K best matches based using a Mahalanobis distance metric
 *
 */</span>
<span class="kt">bool</span> <span class="nf">findKMostLikely</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">faceDescriptorQuery</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">meanLabeledDescriptors</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">,</span>
    <span class="k">const</span> <span class="kt">size_t</span><span class="o">&amp;</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;&amp;</span> <span class="n">matches</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// check that input vector sizes match, mark failure and exit if they don't</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Size mismatch.  Exiting."</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// loop over all sets of mean/covariance pairs</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">mahalanobisVec</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">auto</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">covarianceLabeledDescriptors</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>

    <span class="c1">// add some noise to the primary diagonal of the covariance matrix to regularize it</span>
    <span class="c1">// and improve the numerical stability of the subsequent solver</span>
    <span class="k">auto</span> <span class="n">transCov</span> <span class="o">=</span> <span class="n">covariance</span> <span class="o">+</span> <span class="n">REGULARIZATION</span> <span class="o">*</span> <span class="n">dlib</span><span class="o">::</span><span class="n">identity_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">covariance</span><span class="p">.</span><span class="n">nr</span><span class="p">());</span>
    <span class="k">auto</span> <span class="n">luDecomp</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">::</span><span class="n">lu_decomposition</span><span class="o">&lt;</span><span class="n">dlib</span><span class="o">::</span><span class="n">matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">transCov</span><span class="p">);</span>
    
    <span class="c1">// check if the object indicates a system that is not full-rank</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">luDecomp</span><span class="p">.</span><span class="n">is_singular</span><span class="p">())</span> <span class="p">{</span>
      <span class="c1">// there's nothing further to be done if the starting problem is singular, so go</span>
      <span class="c1">// to the next loop iteration</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Starting matrix is singular"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
      <span class="k">continue</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// compute residual of query descriptor with the current mean</span>
    <span class="k">auto</span> <span class="n">residual</span> <span class="o">=</span> <span class="n">faceDescriptorQuery</span> <span class="o">-</span> <span class="n">meanLabeledDescriptors</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
    
    <span class="c1">// solve the linear system residual = S*y to get a more numerically-stable</span>
    <span class="c1">// representation of S^{-1}*residual in the Mahalanobis calculation </span>
    <span class="k">auto</span> <span class="n">y</span> <span class="o">=</span> <span class="n">luDecomp</span><span class="p">.</span><span class="n">solve</span><span class="p">(</span><span class="n">residual</span><span class="p">);</span>

    <span class="c1">// compute Mahalanobis distance given mean, m, and covariance, S:</span>
    <span class="c1">// d(v1, m, S) = std::sqrt((v1-m)^T * S^{-1} * (v1-m));</span>
    <span class="kt">double</span> <span class="n">mahalanobisDistance</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dlib</span><span class="o">::</span><span class="n">trans</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span><span class="p">);</span>

    <span class="c1">// add result to full vector</span>
    <span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mahalanobisDistance</span><span class="p">));</span>
  <span class="p">}</span>
  
  <span class="c1">// do the sort (smallest mahalanobis distance -&gt; largest)</span>
  <span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
      <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p1</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">p2</span><span class="p">){</span> <span class="k">return</span> <span class="n">p1</span><span class="p">.</span><span class="n">second</span> <span class="o">&lt;</span> <span class="n">p2</span><span class="p">.</span><span class="n">second</span><span class="p">;</span> <span class="p">});</span>
  
  <span class="c1">// get k matches that have smallest mahalanobis distance</span>
  <span class="n">matches</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
  <span class="n">std</span><span class="o">::</span><span class="n">copy_n</span><span class="p">(</span><span class="n">mahalanobisVec</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">k</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">back_inserter</span><span class="p">(</span><span class="n">matches</span><span class="p">));</span>
  <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="results">Results</h2> <p>Because I was curious about not just the best identified match, I used my approach to find the best 5 matches for both of the two test images referenced in the Introduction section above. Without further ado, the results are presented below.</p> <h3 id="image-1">Image 1:</h3> <h4 id="euclidean-distance-1">Euclidean distance</h4> <p><img src="/assets/img/lookalike/sofia-solares_fid0_ed.jpg" alt="ed-sofia"/></p> <h4 id="mahalanobis-distance-1">Mahalanobis distance</h4> <p><img src="/assets/img/lookalike/sofia-solares_fid0_md.jpg" alt="md-sofia"/></p> <h3 id="image-2">Image 2:</h3> <h4 id="euclidean-distance-2">Euclidean distance</h4> <p><img src="/assets/img/lookalike/shashikant-pedwal_fid0_ed.jpg" alt="ed-shashikant"/></p> <h4 id="mahalanobis-distance-2">Mahalanobis distance</h4> <p><img src="/assets/img/lookalike/shashikant-pedwal_fid0_md.jpg" alt="md-shashikant"/></p> <h2 id="discussion">Discussion</h2> <h3 id="performance-on-test-images">Performance on test images</h3> <p>The discussion here will be brief, since the expected outcome of the project has been successfully demonstrated in the plots from the Results section above; <em>the best match identified for each test image provided matches expectation</em>. What I would like to highlight is the fact that the two approaches lead to similar results for the top, i.e. best, matches. In fact, based on similarity of results achieved for both methods, and the fact that the Euclidean distance approach was much easier to implement, I would focus further efforts with this particular method towards using the Euclidean distance for means of evaluating similarity.</p> <p>One thing of note is that Matches 1 and 2 for Image 1 claim to represent two different celebrities, Selena and Selena Gomez, however the images representing Selena are, in fact, pictures of Selena Gomez. Since I didn’t have to train the model, this inconsistency in labeling isn’t a big deal, but if I were to refine the model by retraining on the celeb_mini dataset provided, I would merge the two separate folders into one. Moreover, I’d do a deeper dive into the dataset itself to make sure there were no other inconsistencies present.</p> <h3 id="performance-on-other-images">Performance on other images</h3> <p>I was curious about what the approach would say about who the celebrity doppelgangers are for my wife and I and, as a follow-up, find out whether or not such predictions be common across different images (with different lighting, background, glasses/no-glasses, etc…). The results are shown below.</p> <h4 id="image-3-my-wife-and-i-at-a-restaurant">Image 3: My wife and I at a restaurant</h4> <p><img src="/assets/img/lookalike/IMG-0580_fid0_ed.jpg" alt="ed-joe-rest"/></p> <p><img src="/assets/img/lookalike/IMG-0580_fid0_md.jpg" alt="md-joe-rest"/></p> <p><img src="/assets/img/lookalike/IMG-0580_fid1_ed.jpg" alt="ed-jess-rest"/></p> <p><img src="/assets/img/lookalike/IMG-0580_fid1_md.jpg" alt="md-jess-rest"/></p> <p><em>Note: to poke at the issue of data labeling yet again: the image shown for Match 4 is, in fact, an image of Kathy Bates,</em> not <em>Mary Kay Place.</em></p> <h4 id="image-4-my-wife-and-i-near-a-lake-at-dusk">Image 4: My wife and I near a lake at dusk</h4> <p><img src="/assets/img/lookalike/20190615-190740_fid0_ed.jpg" alt="ed-joe-lake"/></p> <p><img src="/assets/img/lookalike/20190615-190740_fid0_md.jpg" alt="md-joe-lake"/></p> <p><img src="/assets/img/lookalike/20190615-190740_fid1_ed.jpg" alt="ed-jess-lake"/></p> <p><img src="/assets/img/lookalike/20190615-190740_fid1_md.jpg" alt="md-jess-lake"/></p> <h2 id="final-remarks">Final Remarks</h2> <p>Although there are some common matches between the two images for both my wife and myself, the top matches are different. Therefore it is expected that this approach would need considerable work to generalize to new images. To increase generalizability of the approach, I would try out the following approaches:</p> <ul> <li><em>Gather additional data</em>. This is always the best approach if data is not difficult to gather (in this case, it wouldn’t be)</li> <li><em>Scrub the data and clean labels</em>. In my limited investigations with the data, I found a few bogus examples (in terms of incorrect labeling), as well as some blurry, low-quality images.</li> <li><em>Retrain the model</em>. This will definitely improve inter-class separation (w.r.t the metric loss function) among the classes present in the input dataset</li> </ul> <p>I had a lot of fun working this project. After finishing, I have come to really appreciate the dlib C++ API; it provides <em>so</em> much functionality in one project: linear algebra, machine learning, multithreading, optimization, … the list goes on-and-on. I am really looking forward to working more with this library in future projects.</p> <p>I know that I’ve only been able to highlight portions of the project above, but I’m happy to discuss the other aspects of the project over email or whatever (see contact info at the bottom of <a href="https://jwdinius.github.io">here</a>).</p> <p>I hope that you got something out of this post. Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[OpenCV Computer Vision II Applications Project]]></summary></entry><entry><title type="html">Virtual Makeup Project Writeup</title><link href="https://jwdinius.github.io/blog/2020/virtualmakeup/" rel="alternate" type="text/html" title="Virtual Makeup Project Writeup"/><published>2020-10-11T08:30:00+00:00</published><updated>2020-10-11T08:30:00+00:00</updated><id>https://jwdinius.github.io/blog/2020/virtualmakeup</id><content type="html" xml:base="https://jwdinius.github.io/blog/2020/virtualmakeup/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>I am currently enrolled in the OpenCV course “Computer Vision II: Applications (C++)”. For the first project, I had to implement two personal “improvement” features to be applied to a test image (shown below):</p> <p><img src="/assets/img/girl-no-makeup.jpg" alt="test-image"/></p> <p>In this blog post, I present the writeup for the project.</p> <h1 id="writeup">Writeup</h1> <p>For my two features, I chose to implement virtual lipstick application and virtual blush application. I will present a walkthrough of the rationale and solution for each feature in subsections below. In each subsection, I will discuss the problem statement, background research I conducted before attempting a solution, and the final solution.</p> <h2 id="feature-1-virtual-lipstick">Feature 1: Virtual Lipstick</h2> <p>The point of this feature is to implement a <em>natural-looking</em> overlay of a user-defined lip color applied to the test image shown above. “Natural-looking” is the important part of the previous sentence: the variation in luminance in the new image with lipstick applied should be consistent with the original image.</p> <p>Before beginning, I did a bit of research to find starting reference material to help me think about the problem. The first reference I found was <a href="https://www.learnopencv.com/cv4faces-best-project-award-2018/">this</a>. In this post, I found a brief description of a competition-winning project, <em>AutoRetouch</em>, which introduced a lipstick application approach with a very good example of the application showing a near-seamless application of a different shade of lipstick applied to a test image, with both before and after photos for comparison. The description of the application stated:</p> <blockquote> <p>This algorithm automatically created a lip mask based on the facial landmark detected using Dlib’s model. Naively blending color on top of the lips does not produce good results, and so he manipulated the chroma components of color while keeping luminance constant.</p> </blockquote> <p>So, the key takeaways from this for me were:</p> <ul> <li>Use Dlib’s facial landmark model to build a lip mask</li> <li>Use colorspace conversion to transform the problem to a colorspace where luminance and chroma components of color can be manipulated instead of BGR colors</li> </ul> <p>Next, I thought about what the right rule for transforming lip pixels from the test image would be to ensure that the transformation looked natural. In other words, I wanted to find a reference that could help to explain to me how to preserve the underlying variation in the original test image despite doing color modifications in the output image. While searching, I found this <a href="https://www.pyimagesearch.com/2014/06/30/super-fast-color-transfer-images/">article</a> from PyImageSearch about color transfer between images. This article is great because it outlines a sequence of steps for doing the color conversion (to the L*a*b* colorspace). Particularly useful were Steps 6 and 7:</p> <blockquote> <p>Step 6: Scale the <code class="language-plaintext highlighter-rouge">target</code> channels by the ratio of the standard deviation of the <code class="language-plaintext highlighter-rouge">target</code> divided by the standard deviation of the <code class="language-plaintext highlighter-rouge">source</code>, multiplied by the <code class="language-plaintext highlighter-rouge">target</code> channels.</p> <p>Step 7: Add in the means of the L*a*b* channels for the <code class="language-plaintext highlighter-rouge">source</code>.</p> </blockquote> <p>I found this approach to be really interesting and useful in the current context because it discusses an approach for taking the desired target channel intensities at each pixel and scaling/translating them to better match the source channel intensities. The application described is different than my desired application, however I was able to pull out the following for my solution:</p> <ul> <li>I only care about changing the pixel values corresponding to the lips in the target image, so after creating a lip mask, I will compute the statistics (mean and standard deviation) on only the lip pixels in the test image (converted to an alternate colorspace with luminance channel)</li> <li>The color I want to apply is constant (just some BGR value corresponding to lipstick color) - so the standard deviation in my target will be 0. <em>I only need to consider variation in the test image, not in the shade of lipstick applied over the lip mask.</em></li> </ul> <p>From these takeaways, I was able to put together a solution that created the following output image (from the initial test image shown above):</p> <p><img src="/assets/img/girl-lipstick.jpg" alt="test-image"/></p> <p>I’ll now discuss the solution in more detail.</p> <h3 id="solution">Solution</h3> <p>The process flow I followed was quite simple:</p> <ul> <li>Construct a binary image mask using Dlib’s facial landmark detector and the <code class="language-plaintext highlighter-rouge">fillPoly</code> method from OpenCV</li> <li>Blur the mask to soften the transition from pixels adjacent to the lips to the lips, themselves</li> <li>Convert test image to alternate colorspace, compute statistics on lip pixels, and then use those statistics to transform the desired lipstick color to a natural embedding for the test image</li> </ul> <p>I’ll discuss each of these approaches in more detail:</p> <h4 id="identify-lip-pixels">Identify lip pixels</h4> <p>There were several examples in the first two weeks of the course that showed how to setup a Dlib facial landmark detector, so I reused some of that code as a starting point. After running the facial landmark detector on the test image, I was able to pass those landmark points, along with the original image, to create a mask denoting the lip pixels in the target image with the following source code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">computeLipMask</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">im</span><span class="p">,</span> <span class="n">full_object_detection</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">landmarks</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span> <span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="n">points</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">landmarks</span><span class="p">.</span><span class="n">num_parts</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="p">{</span>
      <span class="n">points</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="p">(</span><span class="n">landmarks</span><span class="p">.</span><span class="n">part</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">x</span><span class="p">(),</span> <span class="n">landmarks</span><span class="p">.</span><span class="n">part</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">y</span><span class="p">()));</span>
  <span class="p">}</span>
  <span class="c1">// top</span>
  <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span> <span class="n">indicesTop</span> <span class="o">=</span> <span class="p">{</span><span class="mi">64</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">54</span><span class="p">};</span> 
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="n">pointsTop</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">i</span> <span class="o">:</span> <span class="n">indicesTop</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">pointsTop</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
  <span class="p">}</span>

  <span class="c1">// bottom</span>
  <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span> <span class="n">indicesBottom</span> <span class="o">=</span> <span class="p">{</span><span class="mi">54</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">64</span><span class="p">};</span> 
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="n">pointsBottom</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">i</span> <span class="o">:</span> <span class="n">indicesBottom</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">pointsBottom</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
  <span class="p">}</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="n">polys</span> <span class="o">=</span> <span class="p">{</span> <span class="n">pointsTop</span><span class="p">,</span> <span class="n">pointsBottom</span> <span class="p">};</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">fillPoly</span><span class="p">(</span> <span class="n">mask</span><span class="p">,</span> <span class="n">polys</span><span class="p">,</span> <span class="mi">255</span><span class="p">);</span>
  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>In the source code above, I created two masks: one for the top lip and one for the bottom. These two polygons were created by tracing the points <em>clockwise</em> around each lip contour. <code class="language-plaintext highlighter-rouge">fillPoly</code> takes in a <code class="language-plaintext highlighter-rouge">std::vector</code> of a <code class="language-plaintext highlighter-rouge">std::vector</code> of <code class="language-plaintext highlighter-rouge">cv::Point</code> objects and the resulting output is the desired mask.</p> <h4 id="soften-the-transition-from-lip-to-non-lip-and-vice-versa">Soften the transition from lip to non-lip (and vice-versa)</h4> <p>The binary mask created in the last step will most likely lead to a very dramatic transition around the lip boundary. Because a major goal of this application is natural-looking output, I want to blur the mask to allow non-zero contribution of the desired lip color to pixels just outside the lip boundary. Moreover, I would like to have the transition to inside the lip region from outside to be smooth across the boundary. I decided the best way to achieve this would be to apply a Gaussian blur to the binary mask found in the previous step. Here’s the code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">blurLipMask</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">mask</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Size</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">size</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Size</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">size</span><span class="p">.</span><span class="n">height</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">||</span> <span class="n">size</span><span class="p">.</span><span class="n">width</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
  <span class="k">auto</span> <span class="n">maskCopy</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">blurMask</span><span class="p">;</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">blurMask</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="n">blurMask</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">CV_32F</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>This code is <em>very</em> simple. The default value for the blur kernel size is <code class="language-plaintext highlighter-rouge">(0, 0)</code>, which means that no blur will be applied; i.e. the “blurred” mask will be the same as the original binary mask. However, if the user passes a non-trivial kernel size, a blurred mask, scaled to a floating point value in the interval <code class="language-plaintext highlighter-rouge">[0, 1]</code>, is returned by reference via the <code class="language-plaintext highlighter-rouge">mask</code> variable. Now, we have a non-binary mask that can be used to smooth the transitions.</p> <h4 id="apply-lipstick">Apply lipstick</h4> <p>There are a few steps that I followed for applying the lipstick. I will present the source code implementation, which has these steps outlined in commented blocks. I will explain each step block-by-block.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">applyLipstick</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">im</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">mask</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Scalar</span> <span class="k">const</span> <span class="o">&amp;</span> <span class="n">color</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// "color" is the BGR value of the desired lipstick shade</span>
  <span class="c1">// STEP 1: get YCrCb decomposition of input image and desired lip color</span>
  <span class="c1">// STEP 1.1: input image</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imClr</span><span class="p">;</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">imClr</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">COLOR_BGR2YCrCb</span><span class="p">);</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imClrFlt</span><span class="p">;</span>
  <span class="n">imClr</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">CV_32FC3</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">255</span><span class="p">);</span>

  <span class="c1">// STEP 1.2: desired lip color</span>
  <span class="k">auto</span> <span class="n">convertColor</span> <span class="o">=</span> <span class="p">[</span><span class="o">&amp;</span><span class="p">]()</span> <span class="p">{</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">YCrCb</span><span class="p">;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">BGR</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">,</span> <span class="n">color</span><span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">BGR</span><span class="p">,</span> <span class="n">YCrCb</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">COLOR_BGR2YCrCb</span><span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">YCrCbflt</span><span class="p">;</span>
    <span class="n">YCrCb</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">YCrCbflt</span><span class="p">,</span> <span class="n">CV_32FC3</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">YCrCbflt</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="p">};</span>
  <span class="k">auto</span> <span class="n">lipstickYCrCb</span> <span class="o">=</span> <span class="n">convertColor</span><span class="p">();</span>

  <span class="c1">// STEP 2: compute weighted mean of lip pixels in YCrCb colorspace</span>
  <span class="k">auto</span> <span class="n">m</span> <span class="o">=</span> <span class="n">maskedMean</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>

  <span class="c1">// STEP 3: apply alpha blending to pixels with non-zero value in the mask</span>
  <span class="c1">// this alpha blending utilizes the following scheme:</span>
  <span class="c1">// - apply weight (equal to the mask pixel value) to the desired YCrCb lip color + a translation that incorporates variation in the source image</span>
  <span class="c1">// - apply weight (equal to 1 - mask pixel value) to the original pixel in the source image transformed to YCrCb colorspace</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">cols</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">auto</span> <span class="n">mpxl</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">mpxl</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="o">&amp;</span><span class="n">srcPxlClr</span> <span class="o">=</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">;</span> <span class="o">++</span><span class="n">idx</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mpxl</span> <span class="o">*</span> <span class="p">(</span> <span class="n">lipstickYCrCb</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">m</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">mpxl</span><span class="p">)</span> <span class="o">*</span> <span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// STEP 4: convert transformed image back to BGR and change depth to 8-bit unsigned int</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imFlt</span><span class="p">;</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">imFlt</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">COLOR_YCrCb2BGR</span><span class="p">);</span>
  <span class="n">imFlt</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">,</span> <span class="mi">255</span><span class="p">);</span>
  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Step 1 is pretty trivial: using OpenCV’s built-in colorspace conversion routines, I was able to efficiently convert the source image and the target lip color to Y*Cr*Cb*. The only thing worth noting here is the <code class="language-plaintext highlighter-rouge">convertColor</code> lambda created to convert a single <code class="language-plaintext highlighter-rouge">cv::Scalar</code>. From some StackOverflow searches, this seemed the best way to accomplish the desired conversion, but it still seems a little inefficient having to create a 1x1 image, transform it to the desired colorspace, and then return the first pixel channel values for the transformed color. <em>Why choose Y*Cr*Cb* you might ask?</em> Simple: the hint from the first reference I found suggested that the AutoRetouch approach might have used this colorspace to achieve its impressive results.</p> <p>Step 2 requires some discussion. I wanted to match the underlying distribution of lip pixels in the test image <em>exactly</em> in the output image: i.e. if a pixel is 2 standard deviations from the mean value for lip pixels in the source image, I want that same pixel in the output image to be 2 standard deviations from the now <em>new</em> mean value (determined by the desired lip color). As you’ll see above, there is no standard deviation being calculated or used. <em>Don’t we need the standard deviation?</em> The answer is “no”; <em>because I am targeting the same standard deviation over lip pixels in the output image as for the test image, the standard deviation is not used at-all by this approach.</em> For some justification about why this should work, you can check out Steps 6 and 7 from the <a href="https://www.pyimagesearch.com/2014/06/30/super-fast-color-transfer-images/">source</a> that I referenced above. Because the test and output image standard deviations are the same, the scaling to be applied is unity, so the standard deviation does not need to be computed. To compute the mean, I implemented the <code class="language-plaintext highlighter-rouge">maskedMean</code> function below:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">maskedMean</span> <span class="o">=</span> <span class="p">[](</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">img</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span> <span class="n">out</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="kt">float</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">img</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">img</span><span class="p">.</span><span class="n">cols</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">auto</span> <span class="n">mpxl</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">mpxl</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">N</span> <span class="o">+=</span> <span class="n">mpxl</span><span class="p">;</span>
        <span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span> <span class="n">pxl</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">;</span> <span class="o">++</span><span class="n">idx</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mpxl</span> <span class="o">*</span> <span class="n">pxl</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">out</span> <span class="o">/=</span> <span class="n">N</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div> <p>Looking at the implementation, you can see that this is not a standard mean calculation but rather a <a href="https://stats.stackexchange.com/a/6536"><em>weighted</em> mean</a>. A weighted mean is appropriate in this context because of the choice of blurred mask to smooth the transition from non-lip to lip pixels.</p> <p>Step 3 is the crucial step as I actually transform the pixels here. I apply a simple alpha blending scheme with a twist in the way that the alpha-part is computed. The alpha-part in the update comes from the mask weight times the mean-shifted test image lip pixel translated by the desired lip color. This is a bit of a mouthful, I know, but the gist is that I am trying to maintain the statistical distributions of all of the Y*Cr*Cb* channels in the test image, but just translated to the new desired lipstick color. The (1-alpha)-part in the alpha-blending comes from original test image pixel, itself. Note that when the mask gives weight near 1, nearly all of the pixel’s channel values will come from the translated lipstick channel values, whereas when the weight is near 0, nearly all of the values will come directly from the unaltered test image pixel.</p> <p>Step 4 just does the transformation back to the BGR colorspace and rescales the image to a 3-channel image with unsigned 8-bit depth in each channel.</p> <h3 id="discussion">Discussion</h3> <p>To see how this approach works in practice, just look at the image shared just before the solution discussion. For that image, a lipstick shade of (B,G,R) = (0, 0, 155) was chosen. The solution looks very natural; lower luminance values from the original image and preserved in the output image (see the creases in the lips, for one, as well as the corners). The transition from non-lip to lip looks very smooth; there is no hard line present.</p> <p>What I found while tuning the blur kernel size and evaluating the effect of the weighted vs. non-weighted mean approach, I found that both blurring and the kernel size were crucial in making the final image look as natural as possible. Once I had the blur, the weighted mean allowed me to smooth the transition in a way that resulted in a nearly-seamless application of lipstick to the original image. In my opinion, compared to AutoRetouch, the results shown compare quite favorably.</p> <h2 id="feature-2-virtual-blush">Feature 2: Virtual Blush</h2> <p>As in the case of the Virtual Lipstick feature implementation, the object of the Virtual Blush feature is to naturally apply blush to a face in an input image.</p> <p>The virtual lipstick feature implementation worked suprisingly well, so I wanted to use the same core approach for blending a target color over a masked region in the image. The problem then became: <em>how to construct the region-of-interest (ROI) for the mask?</em></p> <p>I know next-to-nothing about makeup, in general. Before diving too deep, I wanted to gain some insights about blush application. I went through some articles on websites for popular magazines and lifestyle companies. One article I found interesting (and humbling) was <a href="https://www.goodhousekeeping.com/beauty/makeup/how-to/a37479/best-blush-tips/">this one</a>. Step 5 in the article showed women with multiple different face shapes and, for each face shape, there was a different (and nonlinear) strategy for blush application! It was at this point that I realized that the likelihood of coming up with a one-size-fits-all approach was small. Rather than trying to find such a solution, I resolved to create a well-reasoned, generic approach to solving the problem. I discuss my solution below.</p> <h3 id="solution-1">Solution</h3> <p>I start by stating the following heuristics:</p> <ul> <li>(H1) The focal point of blush application is the cheek center</li> <li>(H2) The intensity of blush observed falls off proportionally with distance from cheek center <ul> <li>(H2.1) Moreover, there is an axis-of-symmetry about which that intensity falls off</li> </ul> </li> <li>(H3) As in the Virtual Lipstick case, the distribution of color around a mean should match between input and output images, with the output image’s color component being modified to a desired blush color</li> </ul> <p>I used the above heuristics to shape the following algorithm to solve the problem at-hand:</p> <ul> <li>For each of the right and left cheeks: <ul> <li>Identify an ROI using facial landmarks and compute its centroid (addresses H1)</li> <li>Create a Gaussian mask with size determined by some fraction of ROI from above (addresses H2)</li> <li>Project Gaussian mask onto ROI from above (also addresses H2)</li> </ul> </li> <li>To apply blush: <em>the approach that follows matches the Virtual Lipstick implementation closely</em> <ul> <li>Convert test image to alternate colorspace <ul> <li>For each cheek <ul> <li>compute statistics on cheek pixels, and then use those statistics to transform the desired blush color to a natural embedding for the test image (addresses H3)</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>The first major bullet of the solution is implemented in the function <code class="language-plaintext highlighter-rouge">computeCheekMasks</code> and the second major bullet is implemented in the function <code class="language-plaintext highlighter-rouge">applyBlush</code>. The source code for each function is included below for reference as you read through the remainder of the page.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">computeCheekMasks</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">im</span><span class="p">,</span> <span class="n">full_object_detection</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">landmarks</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">masks</span><span class="p">,</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">boxRatio</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">,</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">kernelRatio</span><span class="p">,</span> <span class="kt">float</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">maskThresh</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">masks</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>

  <span class="c1">// create points array with points from facial landmark detector</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span> <span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="n">points</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">landmarks</span><span class="p">.</span><span class="n">num_parts</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="p">{</span>
      <span class="n">points</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="p">(</span><span class="n">landmarks</span><span class="p">.</span><span class="n">part</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">x</span><span class="p">(),</span> <span class="n">landmarks</span><span class="p">.</span><span class="n">part</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">y</span><span class="p">()));</span>
  <span class="p">}</span>

  <span class="c1">// find centroid of each polygon in the mask</span>
  <span class="k">auto</span> <span class="n">findCentroid</span> <span class="o">=</span> <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">points</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">auto</span> <span class="n">m</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">moments</span><span class="p">(</span><span class="n">points</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">m10</span> <span class="o">/</span> <span class="n">m</span><span class="p">.</span><span class="n">m00</span><span class="p">,</span> <span class="n">m</span><span class="p">.</span><span class="n">m01</span> <span class="o">/</span> <span class="n">m</span><span class="p">.</span><span class="n">m00</span><span class="p">);</span>
  <span class="p">};</span>

  <span class="c1">// find dimensions (height, width) of rectangle containing input points</span>
  <span class="k">auto</span> <span class="n">heightWidth</span> <span class="o">=</span> <span class="p">[](</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">points</span><span class="p">,</span> <span class="kt">int</span> <span class="o">&amp;</span><span class="n">h</span><span class="p">,</span> <span class="kt">int</span> <span class="o">&amp;</span><span class="n">w</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">w</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">points</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">points</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="n">wc</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">x</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">x</span><span class="p">);</span>
        <span class="k">auto</span> <span class="n">hc</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">y</span> <span class="o">-</span> <span class="n">points</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">y</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">hc</span> <span class="o">&gt;</span> <span class="n">h</span><span class="p">)</span> <span class="n">h</span> <span class="o">=</span> <span class="n">hc</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">wc</span> <span class="o">&gt;</span> <span class="n">w</span><span class="p">)</span> <span class="n">w</span> <span class="o">=</span> <span class="n">wc</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">// right keypoint indices from landmark detector</span>
  <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span> <span class="n">indicesRight</span> <span class="o">=</span> <span class="p">{</span><span class="mi">35</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">};</span> 
  
  <span class="c1">// left keypoint indices from landmark detector</span>
  <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span> <span class="n">indicesLeft</span> <span class="o">=</span> <span class="p">{</span><span class="mi">31</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">};</span>

  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="n">indices</span> <span class="o">=</span> <span class="p">{</span> <span class="n">indicesRight</span><span class="p">,</span> <span class="n">indicesLeft</span> <span class="p">};</span>

  <span class="c1">// for each set of indices:</span>
  <span class="c1">//   1) create keypoints array (keypoints come from the facial landmark detector) </span>
  <span class="c1">//   2) compute centroid of polygon created in 1) and add it to the array</span>
  <span class="c1">//   3) compute height and width of ROI rectangle containing keypoints</span>
  <span class="c1">//   4) create a square region around polygon centroid with dimensions defined by input boxRatio - on interval (0, 1]</span>
  <span class="c1">//   5) create a Gaussian kernel over square created in 4) with input standard deviation defined by input kernelRatios</span>
  <span class="c1">//   6) normalize and apply input threshold to 5)</span>
  <span class="c1">//   7) setup source and target points for homography estimation</span>
  <span class="c1">//   8) compute homography</span>
  <span class="c1">//   9) apply homography to normalized kernel from 6)</span>
  <span class="c1">//   10) append mask to masks</span>

  <span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>  <span class="c1">// loop counter - 0: right, 1: left</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">ids</span> <span class="o">:</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1)</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point</span><span class="o">&gt;</span> <span class="n">pts</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">i</span> <span class="o">:</span> <span class="n">ids</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">pts</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    
    <span class="c1">// 2)</span>
    <span class="k">auto</span> <span class="n">centroid</span> <span class="o">=</span> <span class="n">findCentroid</span><span class="p">(</span><span class="n">pts</span><span class="p">);</span>
    <span class="n">pts</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span> <span class="n">centroid</span> <span class="p">);</span>
    
    <span class="c1">// 3)</span>
    <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">;</span>
    <span class="n">heightWidth</span><span class="p">(</span><span class="n">pts</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>

    <span class="c1">// 4)</span>
    <span class="kt">int</span> <span class="n">side</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">boxRatio</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">std</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">side</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">++</span><span class="n">side</span><span class="p">;</span>  <span class="c1">// make sure that side is odd for the kernel construction</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">side</span><span class="p">,</span> <span class="n">side</span><span class="p">,</span> <span class="n">CV_32F</span><span class="p">);</span>
    
    <span class="c1">// 5)</span>
    <span class="c1">// Note: the Gaussian kernel is constructed by applying a Gaussian blur to a 2D delta function (all zeros except at the center, which is 1)</span>
    <span class="kt">int</span> <span class="n">midpoint</span> <span class="o">=</span> <span class="p">(</span><span class="n">side</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">mask</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span> <span class="n">midpoint</span><span class="p">,</span> <span class="n">midpoint</span> <span class="p">)</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">;</span>

    <span class="c1">// see https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gauss#getgaussiankernel</span>
    <span class="c1">// - the function for computing the sigmas comes from there</span>
    <span class="kt">double</span> <span class="n">kernelSigmaX</span> <span class="o">=</span> <span class="n">kernelRatio</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">side</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span> <span class="p">)</span> <span class="o">+</span> <span class="mf">0.8</span><span class="p">;</span>
    <span class="kt">double</span> <span class="n">kernelSigmaY</span> <span class="o">=</span> <span class="n">kernelRatio</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">side</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span> <span class="p">)</span> <span class="o">+</span> <span class="mf">0.8</span><span class="p">;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">kernel</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">side</span><span class="p">,</span> <span class="n">side</span><span class="p">,</span> <span class="n">CV_32F</span><span class="p">);</span>

    <span class="c1">// compute the kernel</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Size</span><span class="p">(</span><span class="n">side</span><span class="p">,</span> <span class="n">side</span><span class="p">),</span> <span class="n">kernelSigmaX</span><span class="p">,</span> <span class="n">kernelSigmaY</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">BORDER_ISOLATED</span><span class="p">);</span>

    <span class="c1">// 6)</span>
    <span class="kt">double</span> <span class="n">maxVal</span><span class="p">,</span> <span class="n">minVal</span><span class="p">;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Point</span> <span class="n">maxLoc</span><span class="p">,</span> <span class="n">minLoc</span><span class="p">;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">minMaxLoc</span><span class="p">(</span> <span class="n">kernel</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">minVal</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">maxVal</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">minLoc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">maxLoc</span> <span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">normKernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span>
    <span class="n">kernel</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">normKernel</span><span class="p">,</span> <span class="n">CV_32F</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">maxVal</span><span class="p">,</span> <span class="o">-</span><span class="n">maskThresh</span><span class="p">);</span>

    <span class="c1">// the rationale here for the remainder of the loop iteration is to map 4 keypoints from the normed</span>
    <span class="c1">// kernel onto the 4 landmark points for the cheek</span>
    <span class="c1">// the 4 keypoints of the normed kernel image are</span>
    <span class="c1">//  * the top-left</span>
    <span class="c1">//  * the top-right</span>
    <span class="c1">//  * the center</span>
    <span class="c1">//  * the bottom-center</span>
    
    <span class="c1">// 7)</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="o">&gt;</span> <span class="n">srcPoints</span> <span class="o">=</span> <span class="p">{</span> <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="p">(</span><span class="n">midpoint</span><span class="p">,</span> <span class="n">side</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
      <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="p">(</span><span class="n">side</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="p">(</span><span class="n">midpoint</span><span class="p">,</span> <span class="n">midpoint</span><span class="p">)</span> <span class="p">};</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="o">&gt;</span> <span class="n">tgtPoints</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">p</span> <span class="o">:</span> <span class="n">pts</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">tgtPoints</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">y</span><span class="p">));</span>
    <span class="p">}</span>

    <span class="c1">// 8)</span>
    <span class="k">auto</span> <span class="n">homography</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">findHomography</span><span class="p">(</span><span class="n">srcPoints</span><span class="p">,</span> <span class="n">tgtPoints</span><span class="p">);</span>
    
    <span class="c1">// 9)</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">warpedMask</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">rows</span><span class="p">,</span> <span class="n">im</span><span class="p">.</span><span class="n">cols</span><span class="p">,</span> <span class="n">CV_32F</span><span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">normKernel</span><span class="p">,</span> <span class="n">warpedMask</span><span class="p">,</span> <span class="n">homography</span><span class="p">,</span> <span class="n">warpedMask</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>

    <span class="c1">// 10)</span>
    <span class="n">masks</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">warpedMask</span><span class="p">);</span>

    <span class="o">++</span><span class="n">i</span><span class="p">;</span>  <span class="c1">// increment the loop counter</span>
  <span class="p">}</span>

  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">applyBlush</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">im</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">masks</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Scalar</span> <span class="k">const</span> <span class="o">&amp;</span><span class="n">color</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">auto</span> <span class="n">fwd</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">COLOR_BGR2YCrCb</span><span class="p">;</span>
  <span class="k">auto</span> <span class="n">bkwd</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">COLOR_YCrCb2BGR</span><span class="p">;</span>

  <span class="c1">// "color" is the BGR value of the desired blush shade</span>
  <span class="c1">// STEP 1: get "fwd" decomposition of input image and desired blush color</span>
  <span class="c1">// STEP 1.1: input image</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imClr</span><span class="p">;</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">imClr</span><span class="p">,</span> <span class="n">fwd</span><span class="p">);</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imClrFlt</span><span class="p">;</span>
  <span class="n">imClr</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">CV_32FC3</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">255</span><span class="p">);</span>

  <span class="c1">// STEP 1.2: desired blush color</span>
  <span class="k">auto</span> <span class="n">convertColor</span> <span class="o">=</span> <span class="p">[</span><span class="o">&amp;</span><span class="p">]()</span> <span class="p">{</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">outClr</span><span class="p">;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">BGR</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">,</span> <span class="n">color</span><span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">BGR</span><span class="p">,</span> <span class="n">outClr</span><span class="p">,</span> <span class="n">fwd</span><span class="p">);</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">outClrFlt</span><span class="p">;</span>
    <span class="n">outClr</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">outClrFlt</span><span class="p">,</span> <span class="n">CV_32FC3</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">outClrFlt</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="p">};</span>
  <span class="k">auto</span> <span class="n">blushClr</span> <span class="o">=</span> <span class="n">convertColor</span><span class="p">();</span>

  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">mask</span> <span class="o">:</span> <span class="n">masks</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// for each mask in masks, execute the following steps</span>
    <span class="c1">// - this ensures that local statistics are used for each mask region instead of including both in a single mask</span>
    <span class="c1">// STEP 2: compute weighted mean of cheek pixels in HSV colorspace</span>
    <span class="k">auto</span> <span class="n">m</span> <span class="o">=</span> <span class="n">maskedMean</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>  <span class="c1">// SAME AS IMPLEMENTATION USED FOR VIRTUAL LIPSTICK FEATURE</span>

    <span class="c1">// STEP 3: apply alpha blending to pixels with non-zero value in the mask</span>
    <span class="c1">// this alpha blending utilizes the following scheme:</span>
    <span class="c1">// - apply weight (equal to the mask pixel value) to the desired YCrCb lip color + a translation that incorporates variation in the source image</span>
    <span class="c1">// - apply weight (equal to 1 - mask pixel value) to the original pixel in the source image transformed to YCrCb colorspace</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">cols</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="n">mpxl</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">mpxl</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">auto</span> <span class="o">&amp;</span><span class="n">srcPxlClr</span> <span class="o">=</span> <span class="n">imClrFlt</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Vec3f</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
          <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">;</span> <span class="o">++</span><span class="n">idx</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mpxl</span> <span class="o">*</span> <span class="p">(</span> <span class="n">blushClr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">m</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">mpxl</span><span class="p">)</span> <span class="o">*</span> <span class="n">srcPxlClr</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
          <span class="p">}</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// STEP 4: convert transformed image back to BGR and change depth to 8-bit unsigned int</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">imFlt</span><span class="p">;</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">imClrFlt</span><span class="p">,</span> <span class="n">imFlt</span><span class="p">,</span> <span class="n">bkwd</span><span class="p">);</span>
  <span class="n">imFlt</span><span class="p">.</span><span class="n">convertTo</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">,</span> <span class="mi">255</span><span class="p">);</span>

  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>I’ll now discuss the algorithm in more detail.</p> <h4 id="identify-an-roi">Identify an ROI</h4> <p>For the ROI construction, I referred back to the 68-point facial landmark detector from dlib. Unfortunately, there is no cheek center landmark. This presented a minor bump which I was able to overcome by observing the following: <em>the cheek region for both right and left cheeks can be approximated by a triangle whose vertices come from particular landmark points</em>.</p> <p>Once the triangle defined by these three points was constructed, it was really easy to find the centroid; it is just the arithmetic center of the triangle. The image with the triangle vertices and centroid highlighted for both the right and left cheek regions is shown below:</p> <p><img src="/assets/img/blush-keypoints.jpg" alt="test-image"/></p> <p>Using these keypoints, I then created a Gaussian mask that I could project onto the original image to define a region to apply the blush to. This is conceptually very similar to the approach taken for the Virtual Lipstick feature implementation, with the additional complexity that a circular (or elliptical) Gaussian kernel mask applied to either cheek would look really unnatural. The reason for this unfortunate fact is that naive application of a Gaussian mask around the cheek centers won’t match head pose or contour of the face in the original image. I still like the idea of a Gaussian - it gives me a mechanism for addressing heuristics H2 and H2.1 above about symmetry. This led me to the following idea: <em>the axis-of-symmetry for blush application can be naturally embedded onto the 2D projected face shape by means of a projective transformation (homography)</em>.</p> <p>The specifics of the homography are quite simple. The three vertices of the triangle plus the triangle center for each cheek region gives 4 points to match in the output image. The source points of the homography are: <em>the top-left, top-right, center, and the bottom-center</em>. These points can be seen to map quite naturally onto the keypoints in the image shown above. The result of this approach leads to the following <em>representative</em> set of masks for the original image:</p> <p><img src="/assets/img/blush-masks.jpg" alt="test-image"/></p> <p>I said <em>representative</em> in the previous sentence because the set of parameters used are just one of a continuum of possibilities. To add more flexibility to the approach, I added the following configurable parameters:</p> <ul> <li><em>Box ratio</em>: this ratio defines how big the rectangular ROI around each cheek center will be (compared to the minimum of height and width of the full cheek rectangular ROI)</li> <li><em>Kernel ratios</em>: these multipliers define the xy spread of the Gaussian kernel to be used as mask</li> <li><em>Mask threshold</em>: floating point threshold value below which to zero out values from the Gaussian mask</li> </ul> <p>At this point, I have a configurable approach to constructing masks for the right and left cheek regions. This is all I need to apply the method from the Virtual Lipstick feature implementation described above.</p> <h4 id="apply-blush">Apply blush</h4> <p>I won’t repeat verbatim the rationale for method chosen to apply the blush; you can go back to Step 3 from the Virtual Lipstick section of this page for a refresher. The only difference in this approach is that there are now 2 masked regions that need to be iterated over separately. In order to match statistics of the input and output images, each masked cheek region needs to be processed separately to give the most natural-looking output image. Moreover, because the face in the input image is not symmetric, some separate tuning of mask ROI size and Gaussian kernel spread was required.</p> <p>After a few rounds of tuning, here’s the resulting output image:</p> <p><img src="/assets/img/girl-blush.jpg" alt="test-image"/></p> <h3 id="discussion-1">Discussion</h3> <p>This feature implementation did not go as well as I would have hoped. In the resulting image, there are some visible artifacts of the mask application shown around the cheek contours. In hindsight, there are a lot of image-specific components (like head pose, lighting, skin tone, face shape, etc…) that make blush application quite difficult. The approach I came up with, though demonstrably imperfect, was a good attempt at a solution under the circumstances. I know that I could have tweaked the approach to gain some minor improvements on the input image provided however, in the broader scope of the task, this would not have necessarily led to general improvements in the algorithm’s performance when applied to new images.</p> <p>Some thoughts on tuning:</p> <ul> <li>Increasing the mask threshold made transitions less smooth, which makes sense intuitively. If there is a cutoff-value and an abrupt transition from 0 to that cutoff-value in the mask, there will be a step discontinuity in the target image. In practice, it seems best to just leave the mask threshold set to 0.</li> <li>The Gaussian mask width and height need to be chosen carefully to reflect the head pose in the image. When the aspect ratio (y/x) is high in the input image, the kernel height should be the same size or a little larger than the kernel width. When the aspect ratio is low, the opposite advice applies.</li> <li>It appears better to only tune the box ratio and to set the mask width and height based on the aspect ratio heuristic mentioned in the previous bullet point. The box ratio of less than 0.5 seems appropriate, with values closer to 0.5 being more applicable to smaller cheek ROI and smaller values being more applicable to larger cheek ROI.</li> </ul> <h2 id="final-remarks">Final Remarks</h2> <p>The Virtual Lipstick feature implementation went really well. The resulting image after applying the solution looks very natural.</p> <p>I am not so pleased with the Virtual Blush feature implementation. Not only was the solution for the Virtual Lipstick feature simpler, it seems to have performed significantly better with less configuration parameters to tune. The problems with Virtual Blush seem to have started from the very beginning with the ROI construction. I suppose I could have identified better heuristics for determining cheek center (including landmarks from the eyes or jaw, perhaps). The choice of Gaussian kernel for the mask, and the subsequent projection of those mask keypoints onto the facial landmarks, could also have been improved; the projection of this approach fails to capture the natural warping of the Gaussian mask around 3D contours of the cheek and face.</p> <p>All things considered, I think that the two approaches outlined in this post are pretty good in that they present well-reasoned and decently performant solutions to the problems presented. I learned a lot while doing this project. However, I’m hoping that future projects will be more focused on spatial reasoning about images (keypoints, 3D reconstruction, AR/VR) and less focused on cosmetics and Snapchat filters :grin:</p> <p>Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[OpenCV Computer Vision II Applications Project]]></summary></entry><entry><title type="html">Building a Docker image with OpenCV</title><link href="https://jwdinius.github.io/blog/2020/opencv-docker-setup/" rel="alternate" type="text/html" title="Building a Docker image with OpenCV"/><published>2020-09-13T11:30:00+00:00</published><updated>2020-09-13T11:30:00+00:00</updated><id>https://jwdinius.github.io/blog/2020/opencv-docker-setup</id><content type="html" xml:base="https://jwdinius.github.io/blog/2020/opencv-docker-setup/"><![CDATA[<p><img src="/assets/img/facial_landmark_det.gif" alt="Imgur"/> <em>Sample demonstration showing the development environment discussed below in action: A facial landmark detector is shown attempting to keep up with my face while I move it around and change orientation. The noisy red dots show the detector with no smoothing while the blue dots show the results of applying optical flow to smooth out the noise.</em></p> <h3 id="background">Background</h3> <p>Earlier this year, I completed the first in a <a href="https://www.kickstarter.com/projects/satyamallick/ai-courses-by-opencvorg">series AI courses from OpenCV</a>. Most of the course assignments were completed using Jupyter notebooks; all other assignments, including projects, were completed on my host machine. I was given the following two options for satisfying all of the dependencies for completing the course assignments on my host machine:</p> <ul> <li>Install OpenCV and its dependencies natively on my machine</li> <li>Pull a <a href="https://hub.docker.com/r/vishwesh5/opencv/tags">Docker image</a> from dockerhub</li> </ul> <p>The first option was not desirable for several reasons; not least of which is the potential for conflict with other versions of dependencies already installed on my machine. Option 2 was significantly better, and I have used Docker a lot over the last year-and-a-half, so this was the option I chose. Completion of all of the non-notebook assignments went well; primarily because all input data was read from a file.</p> <p>I recently enrolled in the second course in the series, which is focused on applications, and I wanted to see if I could create an environment - built with Docker, of course - that would be optimal for my hardware configuration: <em>workstation with a single 6-core CPU and a GTX-1080i Ti Founder’s Edition graphics card, running Ubuntu 18.04 as the OS and a Logitech C270 USB Webcam.</em></p> <h3 id="setting-up-docker">Setting up Docker</h3> <p>The first desirable optimization would be to get GPU acceleration for OpenCV inside of my container instances. My environment was already setup for this, but I’ll mention briefly here the steps I followed</p> <ul> <li><a href="https://linuxconfig.org/how-to-install-the-nvidia-drivers-on-ubuntu-18-04-bionic-beaver-linux">Install Nvidia driver (&gt; 430)</a></li> <li><a href="https://docs.docker.com/engine/install/">Install Docker</a>. <em>I also followed the</em> <a href="https://docs.docker.com/engine/install/linux-postinstall/">Post-installation steps for Linux</a><em>.</em></li> <li><a href="https://iamhow.com/How_To/Docker_How_To.html">Setup X-forwarding for GUI apps</a></li> <li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">Install Nvidia runtime</a></li> <li>Enable Nvidia runtime by default: add the following line to <code class="language-plaintext highlighter-rouge">/etc/docker/daemon.json</code> file <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s2">"default-runtime"</span>: <span class="s2">"nvidia"</span>
</code></pre></div> </div> <p><em>make sure the resulting</em> <code class="language-plaintext highlighter-rouge">daemon.json</code> <em>file is valid json, otherwise docker will fail upon attempting to restart!</em></p> </li> </ul> <p>Now, most of the infrastructure is in place for building our image. After identifying that dependencies for OpenCV - and OpenCV, itself - would result in intermediate containers that exceed the default Docker base device size while building my image, I followed <a href="https://www.projectatomic.io/blog/2016/03/daemon_option_basedevicesize/">this guidance</a> for increasing the base device size. <em>In practice, I found that a base device size of 30GB was sufficient for building the desired image.</em></p> <h3 id="building-the-docker-image">Building the Docker Image</h3> <p>I start from a base image from <a href="https://hub.docker.com/r/nvidia/cudagl/">here</a>. The CUDA runtime library, OpenGL implementation, and other dependencies are enabled immediately, which makes setting up the remainder of the image easier. <a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html">CuDNN</a> is not present, but is desirable for neural network inference. Before attempting to build the Docker image, download the CuDNN runtime and dev libraries - as debian packages - from the Nvidia developer site following <a href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn_751/cudnn-install/index.html#download">these steps</a> and move/copy them into the same folder as the <a href="/assets/txt/Dockerfile">Dockerfile</a>. Now, you are setup to build the docker image:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> <span class="o">{</span>dir-with-Dockerfile<span class="o">}</span>
docker build <span class="o">{</span><span class="nt">--network</span><span class="o">=</span>host<span class="o">}</span> <span class="nt">-t</span> <span class="o">{</span>name-of-image<span class="o">}</span> <span class="nb">.</span>
</code></pre></div></div> <p><em>The</em> <code class="language-plaintext highlighter-rouge">--network=host</code> <em>option allows using the host machine’s network interfaces directly. I usually disable the Docker bridge network and just use host networking for all of my containers.</em></p> <p>This will take awhile to build…</p> <p>In the meantime, you can consider the following things about the Docker image being built:</p> <ul> <li>Steps discussed <a href="https://www.pyimagesearch.com/2018/08/15/how-to-install-opencv-4-on-ubuntu/">here</a> were used as the basis for building OpenCV, with two exceptions: <ul> <li>CUDA acceleration flags are enabled for this environment</li> <li>No Python virtualenv is setup - <em>the Docker environment is already sufficiently isolated.</em></li> </ul> </li> <li>A user with passwordless login and sudo privileges is created. This allows for easily attaching additional terminals to a running container instance as well as adding desirable additional packages not included in the original image build.</li> <li>A user-defined entrypoint script</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">set</span> <span class="nt">-e</span>

<span class="c"># start jackd server to avoid webcam crash with guvcview</span>
jackd <span class="nt">-d</span> dummy &amp;
<span class="nb">exec</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
</code></pre></div></div> <p>is included to enable webcam streaming within the container <em>after correctly setting up the host environment</em>.</p> <h3 id="the-host-environment">The Host Environment</h3> <p>After digging into an issue with my webcam not properly streaming, it seemed I had a <a href="https://askubuntu.com/questions/457983/how-can-i-get-my-webcam-to-work-with-ubuntu-14-04">permissions issue</a> on <code class="language-plaintext highlighter-rouge">/dev/video*</code> in my host machine. This was easy enough to fix with a udev rule executed at startup:</p> <ul> <li>Create a file <code class="language-plaintext highlighter-rouge">/etc/udev/rules.d/99-webcam-rules</code></li> <li>Add the following line to the file: <code class="language-plaintext highlighter-rouge">KERNEL=="video[0-9]*",MODE="0666"</code> <em>assuming your webcam is discovered as /dev/video[0-9]</em></li> <li>Restart the host machine</li> </ul> <p>Non-root users -including our newly created Docker user - will have read-write access to the webcam now. Everything should now be in place to run and test the container.</p> <h3 id="launching-a-container-instance">Launching a Container Instance</h3> <p>We want our container to be able to do the following:</p> <ul> <li>Display GUI windows - from a webcam streaming app like <code class="language-plaintext highlighter-rouge">guvcview</code> or from OpenCV-based applications</li> <li>Ability to read from the webcam</li> <li>Enable non-volatile storage for intermediate work products - e.g. source code under development</li> </ul> <p>We can achieve all of these goals with the following run command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">--rm</span> <span class="nt">-it</span> <span class="se">\</span>
    <span class="nt">--name</span> opencv-course-c <span class="se">\</span>
    <span class="nt">--net</span> host <span class="se">\</span>
    <span class="nt">--privileged</span> <span class="se">\</span>
    <span class="nt">--ipc</span> host <span class="se">\</span>
    <span class="nt">--device</span> /dev/video0 <span class="se">\</span>
    <span class="nt">--device</span> /dev/video1 <span class="se">\</span>
    <span class="nt">-v</span> /tmp/.X11-unix:/tmp/.X11-unix <span class="se">\</span>
    <span class="nt">-v</span> <span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span>/course-materials:/home/opencv/course-materials <span class="se">\</span>
    <span class="nt">-e</span> <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$DISPLAY</span> <span class="se">\</span>
    opencv-nvidia <span class="se">\</span>
    /bin/bash

</code></pre></div></div> <p>This command, option-by-option, does the following:</p> <ul> <li>Tells the Docker runtime to cleanup the container environment when the user triggers exit - <code class="language-plaintext highlighter-rouge">--rm</code></li> <li>Creates an interactive container - <code class="language-plaintext highlighter-rouge">-it</code></li> <li>Gives the container instance the name <code class="language-plaintext highlighter-rouge">opencv-course-c</code></li> <li>Uses host networking - <code class="language-plaintext highlighter-rouge">--net host</code></li> <li>Gives the container privileged access - <em>required for x11 forwarding, apparently</em></li> <li>Uses host shared memory for interprocess communication - <code class="language-plaintext highlighter-rouge">--ipc host</code></li> <li>Gives access to <code class="language-plaintext highlighter-rouge">/dev/video*</code> devices</li> <li>Sets up X11 forwarding from host</li> <li>Mounts <code class="language-plaintext highlighter-rouge">./course-materials</code> folder as read-write volume inside of container at <code class="language-plaintext highlighter-rouge">/home/opencv/course-materials</code>. <em>This is the non-volatile storage</em></li> <li>Uses host display</li> <li>Uses <code class="language-plaintext highlighter-rouge">opencv-nvidia</code> image as container base</li> <li>Launches a bash shell for the user to interact with</li> </ul> <p>Now, you should be ready to experiment with this; add sample OpenCV source code, compile and run it, and see what happens. The gif of facial landmark tracking I share at the beginning of this blog post was generated using this environment, so I’m pretty confident it’ll work. I would share the facial landmark tracking app, but the code comes from the second OpenCV course, which is behind a paywall :disappointed:</p> <p>I’ve only just begun to use this environment, and I’m really looking forward to pushing further and doing more with it. I hope you’ll find this post and materials referenced useful in your own learning journey.</p> <p>Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[building your own Nvidia-powered instance of OpenCV deployed within a Docker container]]></summary></entry><entry><title type="html">How to Setup an Alternate CM Workflow when Constrained to Use Subversion</title><link href="https://jwdinius.github.io/blog/2020/git-svn/" rel="alternate" type="text/html" title="How to Setup an Alternate CM Workflow when Constrained to Use Subversion"/><published>2020-03-14T10:00:00+00:00</published><updated>2020-03-14T10:00:00+00:00</updated><id>https://jwdinius.github.io/blog/2020/git-svn</id><content type="html" xml:base="https://jwdinius.github.io/blog/2020/git-svn/"><![CDATA[<blockquote> <p><em>Background: I recently started work at a company that uses</em> subversion <em>for configuration management. It has been well over 5 years since I last used the tool, and I have no fond memories of it. I wanted to find a workaround that would allow me to work with</em> git <em>locally and then commit changes to the remote server when I was satisfied that my changes and supporting tests were ready for review. I’m not going to get in to centralized vs. decentralized CM strategies here; the purpose of this post is just to present the workflow I came across and how I verified that it works.</em></p> </blockquote> <p>All materials for reproducing the steps I discuss below can be downloaded from <a href="/assets/zip/git-svn-verified.zip">here</a>.</p> <h1 id="software-prerequisites">Software Prerequisites:</h1> <ul> <li>Ubuntu 16.04/18.04 - <em>you can probably run with Windows 10 + Docker Desktop but I have not verified</em></li> <li>a zip client - <em>to extract the archive</em></li> <li>docker - <em>I run with –network=host option enabled!</em></li> <li>git</li> <li>git-svn</li> <li>subversion</li> </ul> <p>In the shell snippets I show below, <code class="language-plaintext highlighter-rouge">host</code> means you should run your command on your host machine and <code class="language-plaintext highlighter-rouge">container</code> means you should run the command inside of the running docker container that hosts the running subversion server.</p> <h1 id="setting-up-the-mock-environment">Setting up the Mock Environment</h1> <h2 id="build-and-run-the-mock-server">Build and Run the Mock Server</h2> <p>Before getting into the workflow, I wanted to create a subversion server that would allow me to setup some dummy subverion repositories to play around with. If you, the reader, have read some of my previous blog posts, you’d now that I am a big Docker advocate, so I found a repo that could serve as a starting point for setting up a subversion server with a Docker container. <em>My apologies to the original author of the repo; I could not find the original repo that I cloned the Dockerfile and supporting files from before making my minor modifications. If you know who the author is, let me know and I will attribute the original work to you.</em> The basic steps for building an image from the Dockerfile, and launching a container based on that image, provided in the link above are:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span><span class="nb">cd</span> <span class="o">{</span>path-to-extracted-zip-contents<span class="o">}</span>
<span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>./cd svn-test/svn-server
<span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>./build-docker.sh <span class="o">{</span>username<span class="o">}</span> <span class="o">{</span>password<span class="o">}</span>  <span class="c"># provide desired username and password as command line args</span>
<span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>./run-docker.sh 
</code></pre></div></div> <h2 id="setting-up-the-mock-repositories">Setting Up the Mock Repositories</h2> <h3 id="server-side">Server-Side</h3> <p>Remember, I am approaching this post from the perspective of <em>my</em> particular problem: working with existing subversion repos. So, to test candidate workflows, I need representative repositories. We can create one or more such repositories by executing the three steps below:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> svn-server-c /bin/bash  <span class="c"># STEP 1: attach terminal to svn-server-c</span>
<span class="o">(</span>container<span class="o">)</span><span class="nv">$ </span>svnadmin create /home/svn/<span class="o">{</span>project-name<span class="o">}</span>  <span class="c"># STEP 2: create new repo using svnadmin</span>
<span class="o">(</span>container<span class="o">)</span><span class="nv">$ </span><span class="nb">chown</span> <span class="nt">-R</span> www-data:subversion /home/svn/<span class="o">{</span>project-name<span class="o">}</span> <span class="c"># STEP 3: change permissions so user={svn-username} can push/pull from svn server </span>
<span class="o">(</span>container<span class="o">)</span><span class="nv">$ </span><span class="nb">chmod</span> <span class="nt">-R</span> g+rws /home/svn/<span class="o">{</span>project-name<span class="o">}</span>  <span class="c"># STEP 3: (continued)</span>
</code></pre></div></div> <p>So far, only empty repositories have been created; they don’t even have the standard <code class="language-plaintext highlighter-rouge">branches/tags/trunk</code> layout common in subversion repos.</p> <h3 id="client-side">Client-Side</h3> <p>To create a repo with the standard <code class="language-plaintext highlighter-rouge">branches/tags/trunk</code> layout:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>svn co <span class="nt">--user</span> <span class="o">{</span>username<span class="o">}</span> http://localhost/svn/<span class="o">{</span>project-name<span class="o">}</span>  <span class="c"># STEP 1: checkout repo (you will be prompted for username's password)</span>
<span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span><span class="nb">cd</span> <span class="o">{</span>project-name<span class="o">}</span> <span class="o">&amp;&amp;</span> <span class="nb">mkdir </span>branches tags trunk  <span class="c"># STEP 2: create branches tags trunks</span>
<span class="o">(</span>host<span class="o">)</span><span class="nv">$ </span>svn add branches tags trunk <span class="o">&amp;&amp;</span> svn ci <span class="nt">-m</span> <span class="s2">"adding standard layout"</span>  <span class="c"># STEP 3: add and commit local changes to the server</span>
</code></pre></div></div> <p>Should you desire, you can also checkout trunk, add files, and create branches using the normal subversion commands, like <code class="language-plaintext highlighter-rouge">checkout</code>, <code class="language-plaintext highlighter-rouge">checkin</code>, <code class="language-plaintext highlighter-rouge">copy</code>, etc… I chose not to, but feel free to do so. I just wanted the standard layout for integration with <code class="language-plaintext highlighter-rouge">git-svn</code>.</p> <h1 id="simplifying-cm-with-git-svn">Simplifying CM with <code class="language-plaintext highlighter-rouge">git-svn</code></h1> <p>We are now ready to move on to the real objective of this post: <em>working locally with subversion repositories</em> without <em>using subversion</em>! What I am trying to achieve is the following:</p> <ul> <li>I want bi-directional communication; e.g. push <em>and</em> pull capability between my local working copy and the remote subversion server</li> <li>I want to be able to work locally with git to get all of its niceties: <code class="language-plaintext highlighter-rouge">squash</code>, <code class="language-plaintext highlighter-rouge">rebase</code>, <code class="language-plaintext highlighter-rouge">cherry-pick</code>, etc…</li> <li>The workflow should make it simple to keep my working copies up-to-date with the remote</li> </ul> <p>Since this is intended to be a how-to post at its core, I’m going to show what solutions I found for achieving the following with <code class="language-plaintext highlighter-rouge">git-svn</code> and <code class="language-plaintext highlighter-rouge">git</code> with the above criteria in mind. Specifically, I will show how to do the following:</p> <ul> <li>Clone an existing subversion repo</li> <li>Create a branch globally with subversion <em>and</em> track it locally with git</li> <li>Merge branches</li> <li>Ignore files</li> </ul> <p><em>Note: all commands from now on are to be run on your host machine, not inside the container!</em></p> <h2 id="clone-existing-subversion-repo">Clone Existing Subversion Repo</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd {desired-project-parent-dir}  # e.g. one level above where you want to clone the code to locally 
$ git svn clone http://localhost/svn/{repo-name} {repo-name} -s  # the command is "git svn" NOT "git-svn"!
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">s</code> is for standard layout; e.g. branches/tags/trunk</p> <p>This sets up a git-like local repo to work with. Quite handy!</p> <h2 id="create-and-track-a-branch">Create and Track a Branch</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd {local-repo-root-dir}  # make sure that you clone the repo into {local-repo-root-dir} first!
$ git svn branch -m "{your-branch-create-message-here}" {name-of-branch}  # create the branch on the remote server; complete with commit message
$ #git branch -a  # list remote branches that git knows about.  THIS COMMAND IS VERY USEFUL
$ git svn fetch  {name-of-branch}  # fetch newly-made branch.  Exclusion of {name-of-branch} fetches everything: all branches/tags/trunk, so use cautiously.  This step sets up {name-of-branch} as the remote branch for git to track
$ git checkout -b {name-of-branch}-local remotes/origin/{name-of-branch}  # This step creates a local working branch.  Note: adding `-local` removes git warning about ambiguity.
$ ... (do bunch of stuff locally, use git workflow to manage CM (squash/rebase/merge/etc...).
$ git svn dcommit  # commits to branch, updates the revision count (only once)
</code></pre></div></div> <h2 id="merge-branches">Merge branches</h2> <p>This includes merging from a branch into trunk. See this <a href="https://stackoverflow.com/questions/2835791/git-svn-reset-tracking-for-master">post</a>’s accepted answer.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git checkout {to-branch}  # if you have not created a local copy, use the "-b" flag with checkout here
$ git reset --hard {remote-to-to-branch}  # e.g. remotes/origin/trunk.  This sets up your local copy to match the remote AND to track the remote branch!
$ git merge --no-ff  {remote-to-from-branch}  # merge from "from" remote.  The "--no-ff" option is important; see post answer, brings up editor with a default merge message
$ git svn rebase {remote-to-to-branch}  # rebase is apparently required, but shouldn't change anything here
$ git svn dcommit # commits to branch, updates the revision count (only once) 
</code></pre></div></div> <h2 id="ignore-files">Ignore Files</h2> <p>For now, just add a <code class="language-plaintext highlighter-rouge">.gitignore</code> file before doing local git workflow stuff. Do <code class="language-plaintext highlighter-rouge">git svn dcommit</code> after satisfied with local git changes. Things you want to ignore won’t be committed to git and not committed to subversion either.</p> <p>There’s probably a more elegant solution, but this meets my need.</p> <h1 id="wrap-up">Wrap-Up</h1> <p>Hopefully, I’ve presented you with some new information that, should you choose, will empower you to confidently use git with legacy subversion repos! If you think of anything that could be modified or added to improve this post, I am receptive; let me know what you think in the comments. In conclusion, here are some links I distilled into aspects of this post:</p> <ul> <li><a href="https://git-scm.com/docs/git-svn/1.5.5">git-svn from git docs</a></li> <li><a href="http://trac.parrot.org/parrot/wiki/git-svn-tutorial">sample tutorial</a></li> <li><a href="https://objectpartners.com/2014/02/04/getting-started-with-git-svn/">getting started with git-svn</a></li> <li><a href="https://kapeli.com/cheat_sheets/Git_Subversion.docset/Contents/Resources/Documents/index">git-svn cheatsheet</a></li> <li><a href="https://mojodna.net/2009/02/24/my-work-git-workflow.html">sample workflow</a></li> </ul> <p>Hopefully, some of you out there will find this useful. Thanks for reading!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Some tips for using git and git-svn locally when working with legacy subversion repos]]></summary></entry><entry><title type="html">Point Cloud Registration as Optimization, Code Implementation</title><link href="https://jwdinius.github.io/blog/2020/point-match-sol/" rel="alternate" type="text/html" title="Point Cloud Registration as Optimization, Code Implementation"/><published>2020-03-01T10:00:00+00:00</published><updated>2020-03-01T10:00:00+00:00</updated><id>https://jwdinius.github.io/blog/2020/point-match-sol</id><content type="html" xml:base="https://jwdinius.github.io/blog/2020/point-match-sol/"><![CDATA[<p>tl; dr: Here’s a <a href="https://github.com/jwdinius/point-registration-with-relaxation">link</a> to the GitHub repo. The <code class="language-plaintext highlighter-rouge">README.md</code> is pretty descriptive. Clone it, fork it, whatever. You should be able to get up-and-running quickly.</p> <p>In previous posts, <a href="https://jwdinius.github.io/blog/2019/point-match/">this one</a> and <a href="https://jwdinius.github.io/blog/2019/point-match-cont/">this one</a>, I set up a quadratic optimization problem for finding the best correspondences between two point sets, also called <em>clouds</em>. If you haven’t already seen these, I recommend going back and looking at them before going through the this post. Your call.</p> <h2 id="a-bit-of-context">A bit of context</h2> <p>At last year’s CVPR, I sat through a really cool talk presenting the <a href="https://arxiv.org/abs/1904.03483">SDRSAC paper</a>. The results presented seemed really promising and I wanted to see if I could reproduce them. There were a lot of issues encountered along the way. In this post, I will highlight and dig deeper into some of these issues.</p> <h1 id="implementation">Implementation</h1> <h2 id="infrastructure">Infrastructure</h2> <p>At this point, I use <a href="www.docker.com">Docker</a> for all of my personal projects. I just find that it is a more flexible solution than requiring users to install a bunch of dependencies on their machine. There’s an added bonus as well: <em>new users can reproduce original results with little-to-no added friction</em>.</p> <h2 id="language">Language</h2> <p>I chose C++ because performance was a concern. I wanted to have the performance of a strongly-typed language combined with the large suite of supporting libraries written in it. To handle automatic resource management, I compiled using the C++-14 standard. This allowed transfer of ownership of resources to smart pointers through the use of the <code class="language-plaintext highlighter-rouge">std::make_unique</code> and <code class="language-plaintext highlighter-rouge">std::make_shared</code> functions introduced by the C++-14 standard.</p> <h3 id="linear-algebra-library">Linear algebra library</h3> <p>Despite <a href="http://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen</a>’s popularity over the last decade, I decided to go with <a href="http://arma.sourceforge.net/">Armadillo</a>. The reasons for my choice include:</p> <ul> <li>Documentation: <em>the wiki is great</em></li> <li><a href="http://nghiaho.com/?p=1726">Speed</a></li> <li>Matlab-like syntax: <em>though 0-based indexing of C++ is still used</em></li> <li>Functionality - <em>reshaping, resampling, and operations like singular-value decomposition come for free</em></li> </ul> <h3 id="optimization">Optimization</h3> <h4 id="nonlinear-optimization-framework">Nonlinear optimization framework</h4> <p>I had originally wanted to use a semidefinite solver, SDP, like the original SDRSAC work, but finding such a solver proved to be a major roadblock. My requirements for the solver were:</p> <ul> <li>It had to be free - <em>I wanted to be able to share this work with everyone</em></li> <li>It had to be well-supported - <em>I didn’t want to spend a lot of time debugging an external</em></li> <li>It had to have a simple interface - <em>I wanted to be able to define the optimization objective in a clear, intuitive format</em></li> </ul> <p>Some libraries considered were <a href="https://github.com/coin-or/Csdp/wiki">CSDP</a>, <a href="http://sdpa.sourceforge.net/">SDPA</a>, and <a href="http://ensmallen.org/">Ensmallen</a>, however <em>none</em> of these libraries, when evaluated, met the three criteria above.</p> <p>The choice of semidefinite solver was driven primarily by the structure of the optimization objective, however when looking into some comparisons, like in Section 5.4 of this <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.910&amp;rep=rep1&amp;type=pdf">paper</a>, I convinced myself that a more general optimization framework could be effective, so I decided to go with <a href="https://coin-or.github.io/Ipopt/">IPOPT</a>. IPOPT meets all of the above requirements and, as a bonus, I have used it before in other projects; see <a href="https://jwdinius.github.io/blog/2018/udacity_sdcnd/">this</a>.</p> <p>The translation of the optimization constraints was also <em>much</em> easier for the IPOPT formulation when compared to the SDP formulation. Don’t take my word for it, though: compare the constraints presented in the posts referenced above to the ones in the SDRSAC paper.</p> <h4 id="linear-correction">Linear correction</h4> <p>As in the SDRSAC paper, depending upon the convergence criteria imposed on the nonlinear optimizer, the resulting solution to the optimization objective <em>may not be a valid member of the desired solution space</em>! To fix this, I needed to find an implementation of something akin to the <a href="http://fourier.eng.hmc.edu/e176/lectures/NM/node32.html">simplex algorithm</a> for projecting the solution to the nonlinear problem onto the solution space: 0 for non-matches, 1 for matches. I was able to find an implementation in Google’s <a href="https://developers.google.com/optimization/lp/lp">ORTools</a> which meets the requirements I outlined above for the nonlinear optimizer above.</p> <h3 id="data-creation-and-performance-analysis">Data creation and performance analysis</h3> <p>I knew that I wanted to be able to easily create datasets, run the optimization, and quickly analyze the results graphically. The native C++ support for such capabilities is not very flexible, so I decided to wrap the main function call in a Pythonic wrapper using <a href="https://www.boost.org/doc/libs/1_70_0/libs/python/doc/html/index.html"><code class="language-plaintext highlighter-rouge">Boost::Python</code></a>. This allowed me to use the <a href="https://numpy.org/"><code class="language-plaintext highlighter-rouge">numpy</code></a> suite of tools for creating point clouds to be passed to the algorithm and the plotting capabilities of <a href="https://matplotlib.org/"><code class="language-plaintext highlighter-rouge">matplotlib</code></a> to visualize the output. I found that, by writing the wrapper, it was a lot easier to identify system-level issues while developing the algorithm.</p> <h2 id="testing">Testing</h2> <p>Testing is a big part of my approach to application development. Though I didn’t follow the full principles of TDD, I did try to capture test cases for all function calls under both nominal and off-nominal conditions. This approach gave me the confidence to try out things quickly and verify if the expected behavior was observed. As a follow-on, it allowed me to catch bugs and identify corner-cases much more quickly than traditional approaches; i.e. top-down development with little to no unit testing.</p> <p>To automatically execute and generate a test report, I built my unit tests using <a href="https://www.boost.org/doc/libs/1_45_0/libs/test/doc/html/utf.html">Boost’s unit test</a>. After building the shared library, the unit tests can be built with <code class="language-plaintext highlighter-rouge">make test</code> and the pass/fail data is reported automatically.</p> <h2 id="code-quality-and-standards-checking">Code quality and standards-checking</h2> <p>I have included a wrapper script in the GitHub repo that does a quick static code check using <a href="https://github.com/cpplint/cpplint"><code class="language-plaintext highlighter-rouge">cpplint</code></a>, which verifies that the code meets common style conventions for C++. This helps to keep the repo’s implementation consistent should additional features be added down the road.</p> <h1 id="summary-and-future-work">Summary and future work</h1> <p>In this post, I presented my design choices for the computational solution to the problem of point cloud matching, which I developed in pair of previous posts. I have made the work available for others to use and contribute to, should they wish to do so. Some things that I would like to add to the repo would be in no particular order:</p> <ul> <li>Continuous Integration, CI - <em>this way I can automatically check that all tests pass before merging new commits</em></li> <li>Code coverage tests - <em>I’d really like to make sure that there are no corner cases that I am neglecting in my test-suite</em></li> <li>Adding <a href="https://en.wikipedia.org/wiki/Clique_problem#Finding_maximum_cliques_in_arbitrary_graphs">maximum clique algorithm</a> correspondence solver - <em>more on this to come in a future post!</em></li> </ul> <p>Thanks for reading! Check out the link at the top of this post for the GitHub repo.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[C++ implementation of point cloud matching using convex relaxation.]]></summary></entry></feed>